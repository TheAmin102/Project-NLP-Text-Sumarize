{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB2JTFhwuv3r",
        "outputId": "59be1d2f-e6e2-48e4-8da0-1487e94aec6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences in the given text: 179\n",
            "['Extractive Text Summarization for Thai Travel News\\nBased on Keyword Scored in Thai Language\\nSarunya Nathonghor\\n\\nDuangdao Wichadakul\\n\\nDepartment of Computer Engineering\\nChulalongkorn University\\nBangkok, Thailand\\n\\nDepartment of Computer Engineering\\nChulalongkorn University\\nBangkok, Thailand\\n\\nSarunya.N@Student.Chula.ac.th\\nABSTRACT\\n\\nIn recent years, people are seeking for a solution to improve text\\nsummarization for Thai language.', 'Although several solutions such\\nas PageRank, Graph Rank, Latent Semantic Analysis (LSA)\\nmodels, etc., have been proposed, research results in Thai text\\nsummarization were restricted due to limited corpus in Thai\\nlanguage with complex grammar.', 'This paper applied a text\\nsummarization system for Thai travel news based on keyword\\nscored in Thai language by extracting the most relevant sentences\\nfrom the original document.', 'We compared LSA and Non-negative\\nMatrix Factorization (NMF) to find the algorithm that is suitable\\nwith Thai travel news.', 'The suitable compression rates for Generic\\nSentence Relevance score (GRS) and K-means clustering were also\\nevaluated.', 'From these experiments, we concluded that keyword\\nscored calculation by LSA with sentence selection by GRS is the\\nbest algorithm for summarizing Thai Travel News, compared with\\nhuman with the best compression rate of 20%.', 'CCS Concepts\\n\\n• Information systems ➝ Information retrieval ➝ Retrieval\\ntasks and goals➝ Summarization\\n\\nKeywords\\n\\nText summarization; extractive summarization; non-negative\\nmatrix factorization\\n\\n1.', 'INTRODUCTION\\n\\nDaily newspaper has abundant of data that users do not have\\nenough time for reading them.', 'It is difficult to identify the relevant\\ninformation to satisfy the information needed by users.', 'Automatic\\nsummarization can reduce the problem of information overloading\\nand it has been proposed previously in English and other languages.', 'However, there were only a few research results in Thai text\\nsummarization due to the lack of corpus in Thai language and the\\ncomplicated grammar.', 'Text Summarization [1] is a technique for summarizing the content\\nof the documents.', 'It consists of three steps: 1) create an\\nintermediate representation of the input text, 2) calculate score for\\nthe sentences based on the concepts, and 3) choose important\\nPermission to make digital or hard copies of all or part of this work for\\npersonal or classroom use is granted without fee provided that copies are\\nnot made or distributed for profit or commercial advantage and that copies\\nbear this notice and the full citation on the first page.', 'Copyrights for\\ncomponents of this work owned by others than ACM must be honored.', 'Abstracting with credit is permitted.', 'To copy otherwise, or republish, to\\npost on servers or to redistribute to lists, requires prior specific permission\\nand/or a fee.', 'Request permissions from Permissions@acm.org.', 'ITCC 2020, August 12–14, 2020, Kuala Lumpur, Malaysia\\n© 2020 Association for Computing Machinery.', 'ACM ISBN 978-1-4503-7539-9/20/08…$15.00\\n\\nDOI: https://doi.org/10.1145/3417473.3417479\\n\\nDuangdao.W@Chula.ac.th\\n\\nsentences to be included in the summary.', 'Text summarization can\\nbe divided into 2 approaches.', 'The first approach is the extractive\\nsummarization, which relies on a method for extracting words and\\nsearching for keywords from the original document.', 'The second\\napproach is the abstractive summarization, which analyzes words\\nby linguistic principles with transcription or interpretation from the\\noriginal document.', 'This approach implies more effective and\\naccurate summary than the extractive methods.', 'However, with the\\nlack of Thai corpus, we chose to apply an extractive summarization\\nmethod for Thai text summarization.', 'This research focused on the sentence extraction function based on\\nkeyword score calculation then selecting important sentences based\\non the Generic Sentence Relevance score (GRS), calculated from\\nLatent Semantic Analysis (LSA) and Non-negative Matrix\\nFactorization (NMF).', 'We also tried using K-means clustering for\\ndocument summarization.', 'In this experiment, we compared 5\\nmodels for 5 rounds with Thai travel news using the compression\\nrates of 20%, 30% and 40% and reported the rate and method that\\nproduced the best result from the experiment.', '2.', 'RELATED WORKS\\n\\nIn recent years, several models in Thai Text summarization have\\nbeen introduced.', 'Suwanno, N. et al.', '[2] proposed a Thai text\\nsummarization that extracted a paragraph from a document based\\non Thai compound nouns, term frequency method, and headline\\nscore for generating a summary.', 'Chongsuntornsri, A., et al.', '[3]\\nproposed a new approach for Text summarization in Thai based on\\ncontent- and graph-based with the use of Topic Sensitive PageRank\\nalgorithm for summarizing and ranking of text segments.', 'Jaruskulchai C., et al.', '[4] proposed a method to summarize\\ndocuments by extracting important sentences from combining the\\nspecific properties (Local Property) and the overall properties\\n(Global Property) of the sentences.', 'The overall properties were\\nbased on the relationship between sentences in the document.', 'From\\ntheir experiments, the summarization of the industrial news got\\n60% precision, 44% recall, and 50.9% F-measure, the general news\\ngot the 51.8% precision, 38.5% recall, and 43.1% F-measure while\\nthe fashion magazines got 53.0% precision, 33.0% recall, and\\n40.4% F-measure.', 'Mani, I., et al.', '[5] proposed techniques of text summarization by\\nusing word frequency in the document and calculated the weight of\\nword to create a keyword group.', 'They then calculated the cosine\\nsimilarity of sentences.', 'The researcher used A* search algorithm to\\nfind the shortest sequence of sentences from keyword group by\\ntopic calculation, sentence segmentation and word grouping.', 'The\\nsequence of sentences that were in the main group were selected as\\nimportant sentences.', 'Their summarization of the agricultural news\\ngot 68.57% precision, 51.95% recall and 56.72% F-measure.', 'Lee, J., et al.', '[6] proposed a document summarization method using\\nNon-negative Matrix Factorization (NMF).', 'They compared\\n\\n\\x0cbetween Latent Semantic Analysis (LSA) and NMF to find the\\nweight of each word and calculated the summation of weights.', 'The\\nimportant sentences were ranked and selected into the summary\\nbased on their summed weight.', 'Based on LSA, they found many\\nweights with zero and negative values.', 'However, when applied\\nNMF, they found only the positive values and the scope of the\\nsemantic features’ meaning was narrow.', 'Therefore, they proposed\\nthat NMF provided a greater possibility for extracting important\\nsentences.', '3.', 'PREPROCESSING FOR THAI TEXT\\n\\nThe first step for working with Thai Text is word tokenization.', 'Even\\nthough Thai writing system has no delimiters to indicate word\\nboundaries together with many rules for word segmentation, several\\nThai word tokenization programs have been proposed.', 'Table 1\\nshows F1 score of the recent programs trained and tested by one of\\nour laboratory members with the data from BEST2010 corpus [7].', 'Cutkum [8] got the highest F1 score, hence, we used Cutkum for this\\nstep.', 'Table 1.', 'Comparison of Thai word tokenization programs\\nTools\\n\\nF1 Score\\n\\nValidate\\nPyICU [9]\\n\\nArticle\\n100\\n0.6155\\n\\nEncyclopedia\\n100\\n0.6932\\n\\nNews\\n100\\n0.5987\\n\\nNovel\\n100\\n0.6800\\n\\nLexto [10]\\n\\n0.7267\\n\\n0.7709\\n\\n0.6994\\n\\n0.7701\\n\\nCutkum\\nwordcutpy [11]\\n\\n0.9322\\n0.6212\\n\\n0.9299\\n0.6286\\n\\n0.8987\\n0.6571\\n\\n0.7140\\n0.6247\\n\\ncunlp [12]\\n\\n0.6910\\n\\n0.6172\\n\\n0.5748\\n\\n0.0000\\n\\nSWATH [13]\\n\\n0.6347\\n\\n0.6858\\n\\n0.6200\\n\\n0.6867\\n\\n3.1\\n\\nLatent Semantic Analysis\\n\\nLatent Semantic Analysis (LSA) [14] is the algorithm, which\\nreduces the dimensionality of term document.', 'The algorithm\\ncreates a matrix by using word frequency, applies the singular value\\ndecomposition (SVD) [15], and then finds closely related terms and\\ndocuments.', 'The original matrix A can be separated into three\\nmatrices, where U is the m x r (words x extracted concept) matrix,\\nV is the n x r (sentences x extracted concepts) matrix, and Σ is the\\nr x r diagonal matrix, which can be reconstructed to find the original\\nmatrix A.', 'The SVD can be represented in Eq.', '(1).', '3.2\\n\\nA ≈ 𝑈𝑈𝑈𝑈𝑉𝑉 𝑇𝑇\\n\\nof the related singular value over the sum of all singular values, for\\neach concept.', '3.3\\n\\n(2)\\n\\nA = 𝑊𝑊𝑊𝑊\\n\\nFactors W and H can be found by solving the optimization problem\\nas follows, where𝑊𝑊𝑗𝑗𝑗𝑗 ≥ 0, 𝐻𝐻𝑖𝑖𝑖𝑖 ≥ 0.\\n𝑚𝑚\\n\\n𝑛𝑛\\n\\n𝑟𝑟\\n\\n𝑗𝑗=1 𝑖𝑖=1\\n\\n𝑙𝑙=1\\n\\n2\\n\\n𝑚𝑚𝑚𝑚𝑚𝑚 𝐹𝐹(𝑊𝑊, 𝐻𝐻) = || 𝐴𝐴 − 𝑊𝑊𝑊𝑊 ||2𝐹𝐹 = � � �𝐴𝐴𝑖𝑖𝑖𝑖 − � 𝑊𝑊𝑖𝑖𝑖𝑖 𝐻𝐻𝑖𝑖𝑖𝑖 �\\n\\n(3)\\n\\nNMF and LSA are both matrix factorization algorithms.', 'However,\\nwhen using NMF to find keywords, NMF will return the keywords\\nthat are closely related because its components have only nonnegative values.', 'As LSA has both positive and negative values as\\nwell as some zeroes, it gets a wider distribution.', 'The semantic\\nfeature represents a concept of meaning for root of words that have\\na relationship.', 'For example, man, human, male and adult have the\\nsame semantic, hence their semantic values are close.', 'In this paper, we applied LSA and NMF on the Thai Travel News\\ndataset for calculating the semantic weights, which represented the\\nrelationship between sentences and words in order to select the\\nrepresentative sentences for summarization.', '3.4 Generic document summarization by\\nNMF\\n\\nLee, J., et al.', 'proposed Eq.', '(4) and Eq.', '(5) to select a number of\\nsentences based on NMF, which got the highest semantic weight\\nvalues, where 𝐻𝐻𝑖𝑖𝑖𝑖 is the weight of the topic 𝑖𝑖 in the sentence 𝑗𝑗.', 'Generic Relevance of jth sentence\\n𝑟𝑟\\n\\n(1)\\n\\n= � 𝐻𝐻𝑖𝑖𝑖𝑖 𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡(𝐻𝐻𝑖𝑖 )\\n\\nDocument summarization using LSA\\n\\nGong, Y. et al.', '[16] proposed a document summarization based on\\nSVD matrices.', 'In our work, after applying SVD to matrix A, 𝑉𝑉 𝑇𝑇\\nmatrix used for selecting the important sentences.', 'The cell value of\\nthe matrix shows the relationship between sentence and extracted\\nconcepts.', 'A sentence with the highest cell value of each concept\\nwill be selected into the summary starting from the most important\\nconcept.', 'The total number of sentences in the summary will be\\nequal to the number all detected concepts.', 'Murray, G. et al.', '[17] proposed a document summarization based\\non SVD matrices using 𝑉𝑉 𝑇𝑇 and Σ matrices for sentence selection.', 'The authors proposed that more than one sentence could be\\ncollected from the more important concepts.', 'The decision of how\\nmany sentences would be collected from each concept depending\\non the Σ matrix.', 'The value was decided by getting the percentage\\n\\nNon-negative Matrix Factorization\\n\\nNon-negative Matrix Factorization (NMF) is a method of matrix\\nfactorization subject to the non-negative constraint.', 'Lee, J., et al.', 'proposed the model based on NMF for document summarization.', 'NMF decomposes a non-negative matrix 𝐴𝐴 ∈ 𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚 into two nonnegative matrices.', 'The first matrix 𝑚𝑚 x 𝑟𝑟 is a non-negative semantic\\nfeature matrix (NSFM), 𝑊𝑊 .', 'The second matrix 𝑟𝑟 x 𝑛𝑛 is a nonnegative semantic variable matrix (NSVM), 𝐻𝐻.', 'So, we have 𝑊𝑊 ∈\\n𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚 and 𝐻𝐻 ∈ 𝑅𝑅𝑟𝑟𝑟𝑟𝑟𝑟 and both terms are non-negative as shown in\\nEq.', '(2) and Eq.', '(3).', '(4)\\n\\n𝑖𝑖=1\\n\\n𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡(𝐻𝐻𝑖𝑖 ) =\\n\\n∑𝑛𝑛𝑞𝑞=1 𝐻𝐻𝑖𝑖𝑖𝑖\\n𝑟𝑟\\n∑𝑝𝑝=1 ∑𝑛𝑛𝑞𝑞=1 𝐻𝐻𝑝𝑝𝑝𝑝\\n\\n(5)\\n\\nThe 𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡(𝐻𝐻𝑖𝑖 ) is the relative relevance of the ith semantic feature\\n(𝑊𝑊𝑖𝑖 ), where 𝐻𝐻𝑖𝑖𝑖𝑖 is the weight of the topic 𝑖𝑖 in the sentence 𝑞𝑞 and\\n𝐻𝐻𝑝𝑝𝑝𝑝 is the weight of the topic 𝑝𝑝 in the sentence 𝑞𝑞.', 'The sentences\\ncan be ranked by Generic Relevance Sentence scores.', 'Sentences\\nwith the maximum score will be selected into the summary.', '3.5\\n\\nCosine Similarity\\n\\nCosine similarity [18] is a widely used method to measure the\\nsimilarity between vectors representing the documents.', 'The result of\\ncosine similarity is ranging from 0 to 1.', 'If it is closer to 1, that means\\nboth vectors are similar.', 'Eq.', '(6) and Eq.', \"(7) represents the cosine\\n\\n\\x0csimilarity equation, where cos(θ) is the dot product between vectors\\nof sentences A and B and divided by the product of the two vectors'\\nlengths.\", 'In this paper, we deployed cosine similarity to measure the similarity\\nof sentences in K-means clustering.', 'A∙B\\n||A|| ||B||\\n∑ni=1 Ai Bi\\n\\nSimilarity(A, B) = cos(θ) =\\n\\n(7)\\n\\nK-means Clustering\\n\\n15\\n\\n67\\n\\n7\\n7\\n\\n13\\n13\\n\\n55\\n38\\n\\nTable 2 shows the overall number of sentences of news within each\\ndataset.', 'The average numbers of sentences per news of the 5 sets\\nwere 21, 16, 15, 13 and 13 sentences, respectively.', '5.', 'PIPELINE FOR GENERATING\\nSUMMARIES\\nIn this section, we demonstrate our pipeline (Figure 1) used for text\\nsummarization to generate a summary for a Thai travel news.', 'Word\\n\\nS9\\n\\n6\\n\\nRound 4\\nRound 5\\n\\nTable 3.', 'Example of Word by Sentence Matrix A\\nS8\\n\\nRound 3\\n\\nAvg.', 'Number\\nof Sentences\\n\\nS7\\n\\n21\\n16\\n\\nRound 1\\nRound 2\\n\\nMin.', 'Number of\\nSentences\\n\\nS6\\n\\n7\\n7\\n\\nMax.', 'Number of\\nSentences\\n58\\n58\\n\\nDataset\\n\\nS5\\n\\nTable 2.', 'Overall Sentence Language of each Dataset\\n\\nS4\\n\\nDATA PREPARATION\\n\\nThe standard data sets in Thai language are unavailable for\\nevaluating text summarization system.', 'Therefore, we collected 400\\nThai travel news from Thairath and Manager online newspapers to\\nbe used as datasets for our experiments.', 'We split 400 travel news\\ninto 5 sets of 80 news each.', 'We then evaluated the performance of\\ntext summarization methods which were LSA and NMF by\\ncomparing their results with the summaries manually curated by\\ntwo experts from the Faculty of Liberal Arts, Ubon Ratchathani\\nUniversity.', 'The open-source python libraries such as numpy [19] and sklearn\\n[20] were used in our system.', 'We converted the Thai travel news\\nobtained from Thairath and Manager online newspapers to plain\\ntext.', 'Then, the sentences of each news were segmented by human\\nwith the following format: Si = ‘xxx’, where Si represents the order\\nof the sentence in the original document and ‘xxx’ represents the\\ncontent of that sentence.', 'After removing stop words and duplicate\\nwords, we built a document term matrix or matrix A then applied\\nSVD and NMF to the matrix.', 'Then, we used python modules\\nnumpy.linalg.svd to calculate SVD and sklearn.decomposition to\\ncalculate NMF.', 'For sentence selection, we used Gong, Y. et al.', 'and\\nMurray, G. et al.', 'approaches for calculating weight of the sentence\\nscores then selected sentences with the highest scores into the\\nsummary.', 'For keyword score calculation of NMF, we calculated\\nthe keyword score from Eq.', '(5) and then selected the sentence with\\nthe highest score from each concept.', 'The python module\\nsklearn.cluster was used for K-means clustering.', 'The selected\\nsentences from all approaches were in the same order as the original\\ndocument.', 'In this paper, we performed the 20%, 30% and 40%\\ndocument compression.', 'This meant 80%, 70% and 60% of the\\nsentences will be selected into the summary.', 'S3\\n\\n4.', 'Figure 1.', 'Document summarization pipeline based on LSA\\nand NMF\\n\\nS2\\n\\nFor sentence selection by K-means clustering, we grouped similar\\nsentences into the same cluster using the following steps:\\n1.', 'Randomly select K sentences as the representative of K\\ngroups.', 'K in this paper is the number of sentences that\\nwill be selected into the summary.', '2.', 'Calculate centroid of each group by using the value of\\nsentence vector from V matrix for LSA and 𝐻𝐻𝑇𝑇 matrix\\nfor NMF.', '3.', 'Use cosine similarity to calculate sentence similarity\\nbetween a sentence and the centroid of each group.', 'Then\\nassign that sentence to the group with the highest\\nsimilarity.', '4.', 'Repeat steps 2-3 until all sentences are assigned to a\\ngroup, no sentences change the group, or the similarity\\nbetween sentences and their centroid is close.', '5.', 'Select a sentence with the maximum similarity score with\\nthe centroid of the group and add it into the summary.', 'S1\\n\\n3.6\\n\\nA∙B\\n=\\nn\\nn\\n||A|| ||B||\\n�∑i=1\\nA2i �∑i=1\\nBi2\\n\\n(6)\\n\\nMr.Yontas\\nak\\n\\n1\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\nSupason\\n\\n1\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\nTourism\\nAuthority\\nof Thailand\\n\\n1\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n…\\n\\n…\\n\\n…\\n\\n…\\n\\n…\\n\\n…\\n\\n…\\n\\n…\\n\\n…\\n\\n…\\n\\n\\x0cTable 3 demonstrates an example of a matrix 𝐴𝐴, constructed from\\nword count by sentence of a Thai travel news.', 'It was composed of\\n98 words and 9 sentences.', 'This matrix 𝐴𝐴 was then applied with the\\nLSA and NMF.', 'The sentence vectors were calculated from the term\\nweight and the semantic feature vectors from Eq.', '(1) for LSA and\\nEq.', '(2) for NMF.', 'sentences from all concepts.', 'The Generic Sentence Relevance score\\nfor NMF also collected one sentence for each concept, the same as\\nGong, Y. et al.', 'but with the highest score calculated by Eq.', '(5).', 'As\\nmultiple important sentences could be selected from a more\\nimportant concept, Murray, G. et al.', 'outperformed both Gong, Y. et\\nal.', 'and the GRS method.', '6.', 'EXPERIMENT AND RESULTS\\n6.1 Performance Evaluations Measure\\n\\n7.', 'We evaluated the results of the summarization by using standard\\naccuracy, precision, recall, and F1 score [21].', 'These measurements\\nquantify the differences between the summary from human and the\\nexperimental methods.', 'The precision shows the correctness of the\\nextracted sentences and the recall reflects the number of good\\nsentences missed by the method.', '6.', '2 Experiment Results\\n\\nIn this experimental set, we would like to explore how the different\\nsentence selection methods: the Generic Sentence Relevance score\\nand K-means clustering, affected the text summarization result.', 'For K-means clustering, both SVD and NMF had similar\\nsummarization efficiency.', 'The F1 score of SVD with K-means\\nclustering was 0.83, 0.72, and 0.62 for the compression rate of 20%,\\n30%, and 40%.', 'For the NMF with K-means clustering, the F1 score\\nfor the three compression rates was 0.83, 0.74 and 0.64.', 'For the Generic Sentence Relevance score, the best F1 score for the\\ncompression rate of 20%, 30%, and 40% was 0.86, 0.78 and 0.68\\nrespectively and the best F1 scores for all compression rates were\\nfrom the approach of Murray, G. et al.', 'Figure 2.', 'Thai text summarization efficiency of 5 models\\nFigure 2 shows the Thai text summarization efficiency of 5 models:\\n(1) NMF with GRS, (2) NMF with K-means, (3) SVD with sentence\\nscore by Gong, Y. et al., (4) SVD with K-means, and (5) SVD with\\nsentence score by Murray, G. et al.', 'applied to 400 Thai travel news,\\ndivided into 5 sets of 80 news each, with the varied compression\\nrates of 20%, 30% and 40%.', 'From this experiment, the best model based on keyword score for\\nThai travel news summarization was SVD with sentence selection\\nby Murray, G. et al.', 'This model with the compression rate of 20%\\ngot the highest score because Murray G. et al.', 'method determined\\nthe number of sentences to be extracted from each concept based on\\nthe importance of that concept.', 'The method of Gong, Y. et al., on\\nthe other hand was proposed to select only one sentence with the\\nhighest score from each concept so that the summary would include\\n\\nCONCLUSIONS\\n\\nIn this paper, we applied several text summarization methods to\\nThai Travel News based on keyword scored in Thai language by\\nextracting the most relevant sentences from the original document.', \"We compared LSA and NMF together with different sentence\\nselection methods, to find the algorithm suitable with this paper's\\ndata source.\", 'We concluded that keyword scored calculation by LSA\\nwith sentence selection by Generic Sentence Relevance score by\\nMurray, G. et al.', 'was the best algorithm while the best compression\\nrate of all models was 20%, for summarizing Thai Travel News\\ncompared with humans.', 'In future work, we plan to perform the experiments with different\\ntypes of documents and improve word segmentation of compound\\nnouns that was not handled by Cutkum.', '8.', 'ACKNOWLEDGMENTS\\n\\nWe would like to thank the department of computer engineering,\\nfaculty of engineering, Chulalongkorn University for providing\\ncomputing facilities.']\n",
            "Total words in the given text: 3674\n",
            "['Extractive', 'Text', 'Summarization', 'for', 'Thai', 'Travel', 'News', 'Based', 'on', 'Keyword', 'Scored', 'in', 'Thai', 'Language', 'Sarunya', 'Nathonghor', 'Duangdao', 'Wichadakul', 'Department', 'of', 'Computer', 'Engineering', 'Chulalongkorn', 'University', 'Bangkok', ',', 'Thailand', 'Department', 'of', 'Computer', 'Engineering', 'Chulalongkorn', 'University', 'Bangkok', ',', 'Thailand', 'Sarunya.N', '@', 'Student.Chula.ac.th', 'ABSTRACT', 'In', 'recent', 'years', ',', 'people', 'are', 'seeking', 'for', 'a', 'solution', 'to', 'improve', 'text', 'summarization', 'for', 'Thai', 'language', '.', 'Although', 'several', 'solutions', 'such', 'as', 'PageRank', ',', 'Graph', 'Rank', ',', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'models', ',', 'etc.', ',', 'have', 'been', 'proposed', ',', 'research', 'results', 'in', 'Thai', 'text', 'summarization', 'were', 'restricted', 'due', 'to', 'limited', 'corpus', 'in', 'Thai', 'language', 'with', 'complex', 'grammar', '.', 'This', 'paper', 'applied', 'a', 'text', 'summarization', 'system', 'for', 'Thai', 'travel', 'news', 'based', 'on', 'keyword', 'scored', 'in', 'Thai', 'language', 'by', 'extracting', 'the', 'most', 'relevant', 'sentences', 'from', 'the', 'original', 'document', '.', 'We', 'compared', 'LSA', 'and', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'to', 'find', 'the', 'algorithm', 'that', 'is', 'suitable', 'with', 'Thai', 'travel', 'news', '.', 'The', 'suitable', 'compression', 'rates', 'for', 'Generic', 'Sentence', 'Relevance', 'score', '(', 'GRS', ')', 'and', 'K-means', 'clustering', 'were', 'also', 'evaluated', '.', 'From', 'these', 'experiments', ',', 'we', 'concluded', 'that', 'keyword', 'scored', 'calculation', 'by', 'LSA', 'with', 'sentence', 'selection', 'by', 'GRS', 'is', 'the', 'best', 'algorithm', 'for', 'summarizing', 'Thai', 'Travel', 'News', ',', 'compared', 'with', 'human', 'with', 'the', 'best', 'compression', 'rate', 'of', '20', '%', '.', 'CCS', 'Concepts', '•', 'Information', 'systems', '➝', 'Information', 'retrieval', '➝', 'Retrieval', 'tasks', 'and', 'goals➝', 'Summarization', 'Keywords', 'Text', 'summarization', ';', 'extractive', 'summarization', ';', 'non-negative', 'matrix', 'factorization', '1', '.', 'INTRODUCTION', 'Daily', 'newspaper', 'has', 'abundant', 'of', 'data', 'that', 'users', 'do', 'not', 'have', 'enough', 'time', 'for', 'reading', 'them', '.', 'It', 'is', 'difficult', 'to', 'identify', 'the', 'relevant', 'information', 'to', 'satisfy', 'the', 'information', 'needed', 'by', 'users', '.', 'Automatic', 'summarization', 'can', 'reduce', 'the', 'problem', 'of', 'information', 'overloading', 'and', 'it', 'has', 'been', 'proposed', 'previously', 'in', 'English', 'and', 'other', 'languages', '.', 'However', ',', 'there', 'were', 'only', 'a', 'few', 'research', 'results', 'in', 'Thai', 'text', 'summarization', 'due', 'to', 'the', 'lack', 'of', 'corpus', 'in', 'Thai', 'language', 'and', 'the', 'complicated', 'grammar', '.', 'Text', 'Summarization', '[', '1', ']', 'is', 'a', 'technique', 'for', 'summarizing', 'the', 'content', 'of', 'the', 'documents', '.', 'It', 'consists', 'of', 'three', 'steps', ':', '1', ')', 'create', 'an', 'intermediate', 'representation', 'of', 'the', 'input', 'text', ',', '2', ')', 'calculate', 'score', 'for', 'the', 'sentences', 'based', 'on', 'the', 'concepts', ',', 'and', '3', ')', 'choose', 'important', 'Permission', 'to', 'make', 'digital', 'or', 'hard', 'copies', 'of', 'all', 'or', 'part', 'of', 'this', 'work', 'for', 'personal', 'or', 'classroom', 'use', 'is', 'granted', 'without', 'fee', 'provided', 'that', 'copies', 'are', 'not', 'made', 'or', 'distributed', 'for', 'profit', 'or', 'commercial', 'advantage', 'and', 'that', 'copies', 'bear', 'this', 'notice', 'and', 'the', 'full', 'citation', 'on', 'the', 'first', 'page', '.', 'Copyrights', 'for', 'components', 'of', 'this', 'work', 'owned', 'by', 'others', 'than', 'ACM', 'must', 'be', 'honored', '.', 'Abstracting', 'with', 'credit', 'is', 'permitted', '.', 'To', 'copy', 'otherwise', ',', 'or', 'republish', ',', 'to', 'post', 'on', 'servers', 'or', 'to', 'redistribute', 'to', 'lists', ',', 'requires', 'prior', 'specific', 'permission', 'and/or', 'a', 'fee', '.', 'Request', 'permissions', 'from', 'Permissions', '@', 'acm.org', '.', 'ITCC', '2020', ',', 'August', '12–14', ',', '2020', ',', 'Kuala', 'Lumpur', ',', 'Malaysia', '©', '2020', 'Association', 'for', 'Computing', 'Machinery', '.', 'ACM', 'ISBN', '978-1-4503-7539-9/20/08…', '$', '15.00', 'DOI', ':', 'https', ':', '//doi.org/10.1145/3417473.3417479', 'Duangdao.W', '@', 'Chula.ac.th', 'sentences', 'to', 'be', 'included', 'in', 'the', 'summary', '.', 'Text', 'summarization', 'can', 'be', 'divided', 'into', '2', 'approaches', '.', 'The', 'first', 'approach', 'is', 'the', 'extractive', 'summarization', ',', 'which', 'relies', 'on', 'a', 'method', 'for', 'extracting', 'words', 'and', 'searching', 'for', 'keywords', 'from', 'the', 'original', 'document', '.', 'The', 'second', 'approach', 'is', 'the', 'abstractive', 'summarization', ',', 'which', 'analyzes', 'words', 'by', 'linguistic', 'principles', 'with', 'transcription', 'or', 'interpretation', 'from', 'the', 'original', 'document', '.', 'This', 'approach', 'implies', 'more', 'effective', 'and', 'accurate', 'summary', 'than', 'the', 'extractive', 'methods', '.', 'However', ',', 'with', 'the', 'lack', 'of', 'Thai', 'corpus', ',', 'we', 'chose', 'to', 'apply', 'an', 'extractive', 'summarization', 'method', 'for', 'Thai', 'text', 'summarization', '.', 'This', 'research', 'focused', 'on', 'the', 'sentence', 'extraction', 'function', 'based', 'on', 'keyword', 'score', 'calculation', 'then', 'selecting', 'important', 'sentences', 'based', 'on', 'the', 'Generic', 'Sentence', 'Relevance', 'score', '(', 'GRS', ')', ',', 'calculated', 'from', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'and', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', '.', 'We', 'also', 'tried', 'using', 'K-means', 'clustering', 'for', 'document', 'summarization', '.', 'In', 'this', 'experiment', ',', 'we', 'compared', '5', 'models', 'for', '5', 'rounds', 'with', 'Thai', 'travel', 'news', 'using', 'the', 'compression', 'rates', 'of', '20', '%', ',', '30', '%', 'and', '40', '%', 'and', 'reported', 'the', 'rate', 'and', 'method', 'that', 'produced', 'the', 'best', 'result', 'from', 'the', 'experiment', '.', '2', '.', 'RELATED', 'WORKS', 'In', 'recent', 'years', ',', 'several', 'models', 'in', 'Thai', 'Text', 'summarization', 'have', 'been', 'introduced', '.', 'Suwanno', ',', 'N.', 'et', 'al', '.', '[', '2', ']', 'proposed', 'a', 'Thai', 'text', 'summarization', 'that', 'extracted', 'a', 'paragraph', 'from', 'a', 'document', 'based', 'on', 'Thai', 'compound', 'nouns', ',', 'term', 'frequency', 'method', ',', 'and', 'headline', 'score', 'for', 'generating', 'a', 'summary', '.', 'Chongsuntornsri', ',', 'A.', ',', 'et', 'al', '.', '[', '3', ']', 'proposed', 'a', 'new', 'approach', 'for', 'Text', 'summarization', 'in', 'Thai', 'based', 'on', 'content-', 'and', 'graph-based', 'with', 'the', 'use', 'of', 'Topic', 'Sensitive', 'PageRank', 'algorithm', 'for', 'summarizing', 'and', 'ranking', 'of', 'text', 'segments', '.', 'Jaruskulchai', 'C.', ',', 'et', 'al', '.', '[', '4', ']', 'proposed', 'a', 'method', 'to', 'summarize', 'documents', 'by', 'extracting', 'important', 'sentences', 'from', 'combining', 'the', 'specific', 'properties', '(', 'Local', 'Property', ')', 'and', 'the', 'overall', 'properties', '(', 'Global', 'Property', ')', 'of', 'the', 'sentences', '.', 'The', 'overall', 'properties', 'were', 'based', 'on', 'the', 'relationship', 'between', 'sentences', 'in', 'the', 'document', '.', 'From', 'their', 'experiments', ',', 'the', 'summarization', 'of', 'the', 'industrial', 'news', 'got', '60', '%', 'precision', ',', '44', '%', 'recall', ',', 'and', '50.9', '%', 'F-measure', ',', 'the', 'general', 'news', 'got', 'the', '51.8', '%', 'precision', ',', '38.5', '%', 'recall', ',', 'and', '43.1', '%', 'F-measure', 'while', 'the', 'fashion', 'magazines', 'got', '53.0', '%', 'precision', ',', '33.0', '%', 'recall', ',', 'and', '40.4', '%', 'F-measure', '.', 'Mani', ',', 'I.', ',', 'et', 'al', '.', '[', '5', ']', 'proposed', 'techniques', 'of', 'text', 'summarization', 'by', 'using', 'word', 'frequency', 'in', 'the', 'document', 'and', 'calculated', 'the', 'weight', 'of', 'word', 'to', 'create', 'a', 'keyword', 'group', '.', 'They', 'then', 'calculated', 'the', 'cosine', 'similarity', 'of', 'sentences', '.', 'The', 'researcher', 'used', 'A', '*', 'search', 'algorithm', 'to', 'find', 'the', 'shortest', 'sequence', 'of', 'sentences', 'from', 'keyword', 'group', 'by', 'topic', 'calculation', ',', 'sentence', 'segmentation', 'and', 'word', 'grouping', '.', 'The', 'sequence', 'of', 'sentences', 'that', 'were', 'in', 'the', 'main', 'group', 'were', 'selected', 'as', 'important', 'sentences', '.', 'Their', 'summarization', 'of', 'the', 'agricultural', 'news', 'got', '68.57', '%', 'precision', ',', '51.95', '%', 'recall', 'and', '56.72', '%', 'F-measure', '.', 'Lee', ',', 'J.', ',', 'et', 'al', '.', '[', '6', ']', 'proposed', 'a', 'document', 'summarization', 'method', 'using', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', '.', 'They', 'compared', 'between', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'and', 'NMF', 'to', 'find', 'the', 'weight', 'of', 'each', 'word', 'and', 'calculated', 'the', 'summation', 'of', 'weights', '.', 'The', 'important', 'sentences', 'were', 'ranked', 'and', 'selected', 'into', 'the', 'summary', 'based', 'on', 'their', 'summed', 'weight', '.', 'Based', 'on', 'LSA', ',', 'they', 'found', 'many', 'weights', 'with', 'zero', 'and', 'negative', 'values', '.', 'However', ',', 'when', 'applied', 'NMF', ',', 'they', 'found', 'only', 'the', 'positive', 'values', 'and', 'the', 'scope', 'of', 'the', 'semantic', 'features', '’', 'meaning', 'was', 'narrow', '.', 'Therefore', ',', 'they', 'proposed', 'that', 'NMF', 'provided', 'a', 'greater', 'possibility', 'for', 'extracting', 'important', 'sentences', '.', '3', '.', 'PREPROCESSING', 'FOR', 'THAI', 'TEXT', 'The', 'first', 'step', 'for', 'working', 'with', 'Thai', 'Text', 'is', 'word', 'tokenization', '.', 'Even', 'though', 'Thai', 'writing', 'system', 'has', 'no', 'delimiters', 'to', 'indicate', 'word', 'boundaries', 'together', 'with', 'many', 'rules', 'for', 'word', 'segmentation', ',', 'several', 'Thai', 'word', 'tokenization', 'programs', 'have', 'been', 'proposed', '.', 'Table', '1', 'shows', 'F1', 'score', 'of', 'the', 'recent', 'programs', 'trained', 'and', 'tested', 'by', 'one', 'of', 'our', 'laboratory', 'members', 'with', 'the', 'data', 'from', 'BEST2010', 'corpus', '[', '7', ']', '.', 'Cutkum', '[', '8', ']', 'got', 'the', 'highest', 'F1', 'score', ',', 'hence', ',', 'we', 'used', 'Cutkum', 'for', 'this', 'step', '.', 'Table', '1', '.', 'Comparison', 'of', 'Thai', 'word', 'tokenization', 'programs', 'Tools', 'F1', 'Score', 'Validate', 'PyICU', '[', '9', ']', 'Article', '100', '0.6155', 'Encyclopedia', '100', '0.6932', 'News', '100', '0.5987', 'Novel', '100', '0.6800', 'Lexto', '[', '10', ']', '0.7267', '0.7709', '0.6994', '0.7701', 'Cutkum', 'wordcutpy', '[', '11', ']', '0.9322', '0.6212', '0.9299', '0.6286', '0.8987', '0.6571', '0.7140', '0.6247', 'cunlp', '[', '12', ']', '0.6910', '0.6172', '0.5748', '0.0000', 'SWATH', '[', '13', ']', '0.6347', '0.6858', '0.6200', '0.6867', '3.1', 'Latent', 'Semantic', 'Analysis', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', '[', '14', ']', 'is', 'the', 'algorithm', ',', 'which', 'reduces', 'the', 'dimensionality', 'of', 'term', 'document', '.', 'The', 'algorithm', 'creates', 'a', 'matrix', 'by', 'using', 'word', 'frequency', ',', 'applies', 'the', 'singular', 'value', 'decomposition', '(', 'SVD', ')', '[', '15', ']', ',', 'and', 'then', 'finds', 'closely', 'related', 'terms', 'and', 'documents', '.', 'The', 'original', 'matrix', 'A', 'can', 'be', 'separated', 'into', 'three', 'matrices', ',', 'where', 'U', 'is', 'the', 'm', 'x', 'r', '(', 'words', 'x', 'extracted', 'concept', ')', 'matrix', ',', 'V', 'is', 'the', 'n', 'x', 'r', '(', 'sentences', 'x', 'extracted', 'concepts', ')', 'matrix', ',', 'and', 'Σ', 'is', 'the', 'r', 'x', 'r', 'diagonal', 'matrix', ',', 'which', 'can', 'be', 'reconstructed', 'to', 'find', 'the', 'original', 'matrix', 'A', '.', 'The', 'SVD', 'can', 'be', 'represented', 'in', 'Eq', '.', '(', '1', ')', '.', '3.2', 'A', '≈', '𝑈𝑈𝑈𝑈𝑉𝑉', '𝑇𝑇', 'of', 'the', 'related', 'singular', 'value', 'over', 'the', 'sum', 'of', 'all', 'singular', 'values', ',', 'for', 'each', 'concept', '.', '3.3', '(', '2', ')', 'A', '=', '𝑊𝑊𝑊𝑊', 'Factors', 'W', 'and', 'H', 'can', 'be', 'found', 'by', 'solving', 'the', 'optimization', 'problem', 'as', 'follows', ',', 'where𝑊𝑊𝑗𝑗𝑗𝑗', '≥', '0', ',', '𝐻𝐻𝑖𝑖𝑖𝑖', '≥', '0.', '𝑚𝑚', '𝑛𝑛', '𝑟𝑟', '𝑗𝑗=1', '𝑖𝑖=1', '𝑙𝑙=1', '2', '𝑚𝑚𝑚𝑚𝑚𝑚', '𝐹𝐹', '(', '𝑊𝑊', ',', '𝐻𝐻', ')', '=', '||', '𝐴𝐴', '−', '𝑊𝑊𝑊𝑊', '||2𝐹𝐹', '=', '�', '�', '�𝐴𝐴𝑖𝑖𝑖𝑖', '−', '�', '𝑊𝑊𝑖𝑖𝑖𝑖', '𝐻𝐻𝑖𝑖𝑖𝑖', '�', '(', '3', ')', 'NMF', 'and', 'LSA', 'are', 'both', 'matrix', 'factorization', 'algorithms', '.', 'However', ',', 'when', 'using', 'NMF', 'to', 'find', 'keywords', ',', 'NMF', 'will', 'return', 'the', 'keywords', 'that', 'are', 'closely', 'related', 'because', 'its', 'components', 'have', 'only', 'nonnegative', 'values', '.', 'As', 'LSA', 'has', 'both', 'positive', 'and', 'negative', 'values', 'as', 'well', 'as', 'some', 'zeroes', ',', 'it', 'gets', 'a', 'wider', 'distribution', '.', 'The', 'semantic', 'feature', 'represents', 'a', 'concept', 'of', 'meaning', 'for', 'root', 'of', 'words', 'that', 'have', 'a', 'relationship', '.', 'For', 'example', ',', 'man', ',', 'human', ',', 'male', 'and', 'adult', 'have', 'the', 'same', 'semantic', ',', 'hence', 'their', 'semantic', 'values', 'are', 'close', '.', 'In', 'this', 'paper', ',', 'we', 'applied', 'LSA', 'and', 'NMF', 'on', 'the', 'Thai', 'Travel', 'News', 'dataset', 'for', 'calculating', 'the', 'semantic', 'weights', ',', 'which', 'represented', 'the', 'relationship', 'between', 'sentences', 'and', 'words', 'in', 'order', 'to', 'select', 'the', 'representative', 'sentences', 'for', 'summarization', '.', '3.4', 'Generic', 'document', 'summarization', 'by', 'NMF', 'Lee', ',', 'J.', ',', 'et', 'al', '.', 'proposed', 'Eq', '.', '(', '4', ')', 'and', 'Eq', '.', '(', '5', ')', 'to', 'select', 'a', 'number', 'of', 'sentences', 'based', 'on', 'NMF', ',', 'which', 'got', 'the', 'highest', 'semantic', 'weight', 'values', ',', 'where', '𝐻𝐻𝑖𝑖𝑖𝑖', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑖𝑖', 'in', 'the', 'sentence', '𝑗𝑗', '.', 'Generic', 'Relevance', 'of', 'jth', 'sentence', '𝑟𝑟', '(', '1', ')', '=', '�', '𝐻𝐻𝑖𝑖𝑖𝑖', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', 'Document', 'summarization', 'using', 'LSA', 'Gong', ',', 'Y.', 'et', 'al', '.', '[', '16', ']', 'proposed', 'a', 'document', 'summarization', 'based', 'on', 'SVD', 'matrices', '.', 'In', 'our', 'work', ',', 'after', 'applying', 'SVD', 'to', 'matrix', 'A', ',', '𝑉𝑉', '𝑇𝑇', 'matrix', 'used', 'for', 'selecting', 'the', 'important', 'sentences', '.', 'The', 'cell', 'value', 'of', 'the', 'matrix', 'shows', 'the', 'relationship', 'between', 'sentence', 'and', 'extracted', 'concepts', '.', 'A', 'sentence', 'with', 'the', 'highest', 'cell', 'value', 'of', 'each', 'concept', 'will', 'be', 'selected', 'into', 'the', 'summary', 'starting', 'from', 'the', 'most', 'important', 'concept', '.', 'The', 'total', 'number', 'of', 'sentences', 'in', 'the', 'summary', 'will', 'be', 'equal', 'to', 'the', 'number', 'all', 'detected', 'concepts', '.', 'Murray', ',', 'G.', 'et', 'al', '.', '[', '17', ']', 'proposed', 'a', 'document', 'summarization', 'based', 'on', 'SVD', 'matrices', 'using', '𝑉𝑉', '𝑇𝑇', 'and', 'Σ', 'matrices', 'for', 'sentence', 'selection', '.', 'The', 'authors', 'proposed', 'that', 'more', 'than', 'one', 'sentence', 'could', 'be', 'collected', 'from', 'the', 'more', 'important', 'concepts', '.', 'The', 'decision', 'of', 'how', 'many', 'sentences', 'would', 'be', 'collected', 'from', 'each', 'concept', 'depending', 'on', 'the', 'Σ', 'matrix', '.', 'The', 'value', 'was', 'decided', 'by', 'getting', 'the', 'percentage', 'Non-negative', 'Matrix', 'Factorization', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'is', 'a', 'method', 'of', 'matrix', 'factorization', 'subject', 'to', 'the', 'non-negative', 'constraint', '.', 'Lee', ',', 'J.', ',', 'et', 'al', '.', 'proposed', 'the', 'model', 'based', 'on', 'NMF', 'for', 'document', 'summarization', '.', 'NMF', 'decomposes', 'a', 'non-negative', 'matrix', '𝐴𝐴', '∈', '𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'into', 'two', 'nonnegative', 'matrices', '.', 'The', 'first', 'matrix', '𝑚𝑚', 'x', '𝑟𝑟', 'is', 'a', 'non-negative', 'semantic', 'feature', 'matrix', '(', 'NSFM', ')', ',', '𝑊𝑊', '.', 'The', 'second', 'matrix', '𝑟𝑟', 'x', '𝑛𝑛', 'is', 'a', 'nonnegative', 'semantic', 'variable', 'matrix', '(', 'NSVM', ')', ',', '𝐻𝐻', '.', 'So', ',', 'we', 'have', '𝑊𝑊', '∈', '𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'and', '𝐻𝐻', '∈', '𝑅𝑅𝑟𝑟𝑟𝑟𝑟𝑟', 'and', 'both', 'terms', 'are', 'non-negative', 'as', 'shown', 'in', 'Eq', '.', '(', '2', ')', 'and', 'Eq', '.', '(', '3', ')', '.', '(', '4', ')', '𝑖𝑖=1', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', '=', '∑𝑛𝑛𝑞𝑞=1', '𝐻𝐻𝑖𝑖𝑖𝑖', '𝑟𝑟', '∑𝑝𝑝=1', '∑𝑛𝑛𝑞𝑞=1', '𝐻𝐻𝑝𝑝𝑝𝑝', '(', '5', ')', 'The', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', 'is', 'the', 'relative', 'relevance', 'of', 'the', 'ith', 'semantic', 'feature', '(', '𝑊𝑊𝑖𝑖', ')', ',', 'where', '𝐻𝐻𝑖𝑖𝑖𝑖', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑖𝑖', 'in', 'the', 'sentence', '𝑞𝑞', 'and', '𝐻𝐻𝑝𝑝𝑝𝑝', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑝𝑝', 'in', 'the', 'sentence', '𝑞𝑞', '.', 'The', 'sentences', 'can', 'be', 'ranked', 'by', 'Generic', 'Relevance', 'Sentence', 'scores', '.', 'Sentences', 'with', 'the', 'maximum', 'score', 'will', 'be', 'selected', 'into', 'the', 'summary', '.', '3.5', 'Cosine', 'Similarity', 'Cosine', 'similarity', '[', '18', ']', 'is', 'a', 'widely', 'used', 'method', 'to', 'measure', 'the', 'similarity', 'between', 'vectors', 'representing', 'the', 'documents', '.', 'The', 'result', 'of', 'cosine', 'similarity', 'is', 'ranging', 'from', '0', 'to', '1', '.', 'If', 'it', 'is', 'closer', 'to', '1', ',', 'that', 'means', 'both', 'vectors', 'are', 'similar', '.', 'Eq', '.', '(', '6', ')', 'and', 'Eq', '.', '(', '7', ')', 'represents', 'the', 'cosine', 'similarity', 'equation', ',', 'where', 'cos', '(', 'θ', ')', 'is', 'the', 'dot', 'product', 'between', 'vectors', 'of', 'sentences', 'A', 'and', 'B', 'and', 'divided', 'by', 'the', 'product', 'of', 'the', 'two', \"vectors'\", 'lengths', '.', 'In', 'this', 'paper', ',', 'we', 'deployed', 'cosine', 'similarity', 'to', 'measure', 'the', 'similarity', 'of', 'sentences', 'in', 'K-means', 'clustering', '.', 'A∙B', '||A||', '||B||', '∑ni=1', 'Ai', 'Bi', 'Similarity', '(', 'A', ',', 'B', ')', '=', 'cos', '(', 'θ', ')', '=', '(', '7', ')', 'K-means', 'Clustering', '15', '67', '7', '7', '13', '13', '55', '38', 'Table', '2', 'shows', 'the', 'overall', 'number', 'of', 'sentences', 'of', 'news', 'within', 'each', 'dataset', '.', 'The', 'average', 'numbers', 'of', 'sentences', 'per', 'news', 'of', 'the', '5', 'sets', 'were', '21', ',', '16', ',', '15', ',', '13', 'and', '13', 'sentences', ',', 'respectively', '.', '5', '.', 'PIPELINE', 'FOR', 'GENERATING', 'SUMMARIES', 'In', 'this', 'section', ',', 'we', 'demonstrate', 'our', 'pipeline', '(', 'Figure', '1', ')', 'used', 'for', 'text', 'summarization', 'to', 'generate', 'a', 'summary', 'for', 'a', 'Thai', 'travel', 'news', '.', 'Word', 'S9', '6', 'Round', '4', 'Round', '5', 'Table', '3', '.', 'Example', 'of', 'Word', 'by', 'Sentence', 'Matrix', 'A', 'S8', 'Round', '3', 'Avg', '.', 'Number', 'of', 'Sentences', 'S7', '21', '16', 'Round', '1', 'Round', '2', 'Min', '.', 'Number', 'of', 'Sentences', 'S6', '7', '7', 'Max', '.', 'Number', 'of', 'Sentences', '58', '58', 'Dataset', 'S5', 'Table', '2', '.', 'Overall', 'Sentence', 'Language', 'of', 'each', 'Dataset', 'S4', 'DATA', 'PREPARATION', 'The', 'standard', 'data', 'sets', 'in', 'Thai', 'language', 'are', 'unavailable', 'for', 'evaluating', 'text', 'summarization', 'system', '.', 'Therefore', ',', 'we', 'collected', '400', 'Thai', 'travel', 'news', 'from', 'Thairath', 'and', 'Manager', 'online', 'newspapers', 'to', 'be', 'used', 'as', 'datasets', 'for', 'our', 'experiments', '.', 'We', 'split', '400', 'travel', 'news', 'into', '5', 'sets', 'of', '80', 'news', 'each', '.', 'We', 'then', 'evaluated', 'the', 'performance', 'of', 'text', 'summarization', 'methods', 'which', 'were', 'LSA', 'and', 'NMF', 'by', 'comparing', 'their', 'results', 'with', 'the', 'summaries', 'manually', 'curated', 'by', 'two', 'experts', 'from', 'the', 'Faculty', 'of', 'Liberal', 'Arts', ',', 'Ubon', 'Ratchathani', 'University', '.', 'The', 'open-source', 'python', 'libraries', 'such', 'as', 'numpy', '[', '19', ']', 'and', 'sklearn', '[', '20', ']', 'were', 'used', 'in', 'our', 'system', '.', 'We', 'converted', 'the', 'Thai', 'travel', 'news', 'obtained', 'from', 'Thairath', 'and', 'Manager', 'online', 'newspapers', 'to', 'plain', 'text', '.', 'Then', ',', 'the', 'sentences', 'of', 'each', 'news', 'were', 'segmented', 'by', 'human', 'with', 'the', 'following', 'format', ':', 'Si', '=', '‘', 'xxx', '’', ',', 'where', 'Si', 'represents', 'the', 'order', 'of', 'the', 'sentence', 'in', 'the', 'original', 'document', 'and', '‘', 'xxx', '’', 'represents', 'the', 'content', 'of', 'that', 'sentence', '.', 'After', 'removing', 'stop', 'words', 'and', 'duplicate', 'words', ',', 'we', 'built', 'a', 'document', 'term', 'matrix', 'or', 'matrix', 'A', 'then', 'applied', 'SVD', 'and', 'NMF', 'to', 'the', 'matrix', '.', 'Then', ',', 'we', 'used', 'python', 'modules', 'numpy.linalg.svd', 'to', 'calculate', 'SVD', 'and', 'sklearn.decomposition', 'to', 'calculate', 'NMF', '.', 'For', 'sentence', 'selection', ',', 'we', 'used', 'Gong', ',', 'Y.', 'et', 'al', '.', 'and', 'Murray', ',', 'G.', 'et', 'al', '.', 'approaches', 'for', 'calculating', 'weight', 'of', 'the', 'sentence', 'scores', 'then', 'selected', 'sentences', 'with', 'the', 'highest', 'scores', 'into', 'the', 'summary', '.', 'For', 'keyword', 'score', 'calculation', 'of', 'NMF', ',', 'we', 'calculated', 'the', 'keyword', 'score', 'from', 'Eq', '.', '(', '5', ')', 'and', 'then', 'selected', 'the', 'sentence', 'with', 'the', 'highest', 'score', 'from', 'each', 'concept', '.', 'The', 'python', 'module', 'sklearn.cluster', 'was', 'used', 'for', 'K-means', 'clustering', '.', 'The', 'selected', 'sentences', 'from', 'all', 'approaches', 'were', 'in', 'the', 'same', 'order', 'as', 'the', 'original', 'document', '.', 'In', 'this', 'paper', ',', 'we', 'performed', 'the', '20', '%', ',', '30', '%', 'and', '40', '%', 'document', 'compression', '.', 'This', 'meant', '80', '%', ',', '70', '%', 'and', '60', '%', 'of', 'the', 'sentences', 'will', 'be', 'selected', 'into', 'the', 'summary', '.', 'S3', '4', '.', 'Figure', '1', '.', 'Document', 'summarization', 'pipeline', 'based', 'on', 'LSA', 'and', 'NMF', 'S2', 'For', 'sentence', 'selection', 'by', 'K-means', 'clustering', ',', 'we', 'grouped', 'similar', 'sentences', 'into', 'the', 'same', 'cluster', 'using', 'the', 'following', 'steps', ':', '1', '.', 'Randomly', 'select', 'K', 'sentences', 'as', 'the', 'representative', 'of', 'K', 'groups', '.', 'K', 'in', 'this', 'paper', 'is', 'the', 'number', 'of', 'sentences', 'that', 'will', 'be', 'selected', 'into', 'the', 'summary', '.', '2', '.', 'Calculate', 'centroid', 'of', 'each', 'group', 'by', 'using', 'the', 'value', 'of', 'sentence', 'vector', 'from', 'V', 'matrix', 'for', 'LSA', 'and', '𝐻𝐻𝑇𝑇', 'matrix', 'for', 'NMF', '.', '3', '.', 'Use', 'cosine', 'similarity', 'to', 'calculate', 'sentence', 'similarity', 'between', 'a', 'sentence', 'and', 'the', 'centroid', 'of', 'each', 'group', '.', 'Then', 'assign', 'that', 'sentence', 'to', 'the', 'group', 'with', 'the', 'highest', 'similarity', '.', '4', '.', 'Repeat', 'steps', '2-3', 'until', 'all', 'sentences', 'are', 'assigned', 'to', 'a', 'group', ',', 'no', 'sentences', 'change', 'the', 'group', ',', 'or', 'the', 'similarity', 'between', 'sentences', 'and', 'their', 'centroid', 'is', 'close', '.', '5', '.', 'Select', 'a', 'sentence', 'with', 'the', 'maximum', 'similarity', 'score', 'with', 'the', 'centroid', 'of', 'the', 'group', 'and', 'add', 'it', 'into', 'the', 'summary', '.', 'S1', '3.6', 'A∙B', '=', 'n', 'n', '||A||', '||B||', '�∑i=1', 'A2i', '�∑i=1', 'Bi2', '(', '6', ')', 'Mr.Yontas', 'ak', '1', '0', '0', '0', '0', '0', '0', '0', '0', 'Supason', '1', '0', '0', '0', '0', '0', '0', '0', '0', 'Tourism', 'Authority', 'of', 'Thailand', '1', '0', '0', '0', '0', '0', '0', '0', '0', '…', '…', '…', '…', '…', '…', '…', '…', '…', '…', 'Table', '3', 'demonstrates', 'an', 'example', 'of', 'a', 'matrix', '𝐴𝐴', ',', 'constructed', 'from', 'word', 'count', 'by', 'sentence', 'of', 'a', 'Thai', 'travel', 'news', '.', 'It', 'was', 'composed', 'of', '98', 'words', 'and', '9', 'sentences', '.', 'This', 'matrix', '𝐴𝐴', 'was', 'then', 'applied', 'with', 'the', 'LSA', 'and', 'NMF', '.', 'The', 'sentence', 'vectors', 'were', 'calculated', 'from', 'the', 'term', 'weight', 'and', 'the', 'semantic', 'feature', 'vectors', 'from', 'Eq', '.', '(', '1', ')', 'for', 'LSA', 'and', 'Eq', '.', '(', '2', ')', 'for', 'NMF', '.', 'sentences', 'from', 'all', 'concepts', '.', 'The', 'Generic', 'Sentence', 'Relevance', 'score', 'for', 'NMF', 'also', 'collected', 'one', 'sentence', 'for', 'each', 'concept', ',', 'the', 'same', 'as', 'Gong', ',', 'Y.', 'et', 'al', '.', 'but', 'with', 'the', 'highest', 'score', 'calculated', 'by', 'Eq', '.', '(', '5', ')', '.', 'As', 'multiple', 'important', 'sentences', 'could', 'be', 'selected', 'from', 'a', 'more', 'important', 'concept', ',', 'Murray', ',', 'G.', 'et', 'al', '.', 'outperformed', 'both', 'Gong', ',', 'Y.', 'et', 'al', '.', 'and', 'the', 'GRS', 'method', '.', '6', '.', 'EXPERIMENT', 'AND', 'RESULTS', '6.1', 'Performance', 'Evaluations', 'Measure', '7', '.', 'We', 'evaluated', 'the', 'results', 'of', 'the', 'summarization', 'by', 'using', 'standard', 'accuracy', ',', 'precision', ',', 'recall', ',', 'and', 'F1', 'score', '[', '21', ']', '.', 'These', 'measurements', 'quantify', 'the', 'differences', 'between', 'the', 'summary', 'from', 'human', 'and', 'the', 'experimental', 'methods', '.', 'The', 'precision', 'shows', 'the', 'correctness', 'of', 'the', 'extracted', 'sentences', 'and', 'the', 'recall', 'reflects', 'the', 'number', 'of', 'good', 'sentences', 'missed', 'by', 'the', 'method', '.', '6', '.', '2', 'Experiment', 'Results', 'In', 'this', 'experimental', 'set', ',', 'we', 'would', 'like', 'to', 'explore', 'how', 'the', 'different', 'sentence', 'selection', 'methods', ':', 'the', 'Generic', 'Sentence', 'Relevance', 'score', 'and', 'K-means', 'clustering', ',', 'affected', 'the', 'text', 'summarization', 'result', '.', 'For', 'K-means', 'clustering', ',', 'both', 'SVD', 'and', 'NMF', 'had', 'similar', 'summarization', 'efficiency', '.', 'The', 'F1', 'score', 'of', 'SVD', 'with', 'K-means', 'clustering', 'was', '0.83', ',', '0.72', ',', 'and', '0.62', 'for', 'the', 'compression', 'rate', 'of', '20', '%', ',', '30', '%', ',', 'and', '40', '%', '.', 'For', 'the', 'NMF', 'with', 'K-means', 'clustering', ',', 'the', 'F1', 'score', 'for', 'the', 'three', 'compression', 'rates', 'was', '0.83', ',', '0.74', 'and', '0.64', '.', 'For', 'the', 'Generic', 'Sentence', 'Relevance', 'score', ',', 'the', 'best', 'F1', 'score', 'for', 'the', 'compression', 'rate', 'of', '20', '%', ',', '30', '%', ',', 'and', '40', '%', 'was', '0.86', ',', '0.78', 'and', '0.68', 'respectively', 'and', 'the', 'best', 'F1', 'scores', 'for', 'all', 'compression', 'rates', 'were', 'from', 'the', 'approach', 'of', 'Murray', ',', 'G.', 'et', 'al', '.', 'Figure', '2', '.', 'Thai', 'text', 'summarization', 'efficiency', 'of', '5', 'models', 'Figure', '2', 'shows', 'the', 'Thai', 'text', 'summarization', 'efficiency', 'of', '5', 'models', ':', '(', '1', ')', 'NMF', 'with', 'GRS', ',', '(', '2', ')', 'NMF', 'with', 'K-means', ',', '(', '3', ')', 'SVD', 'with', 'sentence', 'score', 'by', 'Gong', ',', 'Y.', 'et', 'al.', ',', '(', '4', ')', 'SVD', 'with', 'K-means', ',', 'and', '(', '5', ')', 'SVD', 'with', 'sentence', 'score', 'by', 'Murray', ',', 'G.', 'et', 'al', '.', 'applied', 'to', '400', 'Thai', 'travel', 'news', ',', 'divided', 'into', '5', 'sets', 'of', '80', 'news', 'each', ',', 'with', 'the', 'varied', 'compression', 'rates', 'of', '20', '%', ',', '30', '%', 'and', '40', '%', '.', 'From', 'this', 'experiment', ',', 'the', 'best', 'model', 'based', 'on', 'keyword', 'score', 'for', 'Thai', 'travel', 'news', 'summarization', 'was', 'SVD', 'with', 'sentence', 'selection', 'by', 'Murray', ',', 'G.', 'et', 'al', '.', 'This', 'model', 'with', 'the', 'compression', 'rate', 'of', '20', '%', 'got', 'the', 'highest', 'score', 'because', 'Murray', 'G.', 'et', 'al', '.', 'method', 'determined', 'the', 'number', 'of', 'sentences', 'to', 'be', 'extracted', 'from', 'each', 'concept', 'based', 'on', 'the', 'importance', 'of', 'that', 'concept', '.', 'The', 'method', 'of', 'Gong', ',', 'Y.', 'et', 'al.', ',', 'on', 'the', 'other', 'hand', 'was', 'proposed', 'to', 'select', 'only', 'one', 'sentence', 'with', 'the', 'highest', 'score', 'from', 'each', 'concept', 'so', 'that', 'the', 'summary', 'would', 'include', 'CONCLUSIONS', 'In', 'this', 'paper', ',', 'we', 'applied', 'several', 'text', 'summarization', 'methods', 'to', 'Thai', 'Travel', 'News', 'based', 'on', 'keyword', 'scored', 'in', 'Thai', 'language', 'by', 'extracting', 'the', 'most', 'relevant', 'sentences', 'from', 'the', 'original', 'document', '.', 'We', 'compared', 'LSA', 'and', 'NMF', 'together', 'with', 'different', 'sentence', 'selection', 'methods', ',', 'to', 'find', 'the', 'algorithm', 'suitable', 'with', 'this', \"paper's\", 'data', 'source', '.', 'We', 'concluded', 'that', 'keyword', 'scored', 'calculation', 'by', 'LSA', 'with', 'sentence', 'selection', 'by', 'Generic', 'Sentence', 'Relevance', 'score', 'by', 'Murray', ',', 'G.', 'et', 'al', '.', 'was', 'the', 'best', 'algorithm', 'while', 'the', 'best', 'compression', 'rate', 'of', 'all', 'models', 'was', '20', '%', ',', 'for', 'summarizing', 'Thai', 'Travel', 'News', 'compared', 'with', 'humans', '.', 'In', 'future', 'work', ',', 'we', 'plan', 'to', 'perform', 'the', 'experiments', 'with', 'different', 'types', 'of', 'documents', 'and', 'improve', 'word', 'segmentation', 'of', 'compound', 'nouns', 'that', 'was', 'not', 'handled', 'by', 'Cutkum', '.', '8', '.', 'ACKNOWLEDGMENTS', 'We', 'would', 'like', 'to', 'thank', 'the', 'department', 'of', 'computer', 'engineering', ',', 'faculty', 'of', 'engineering', ',', 'Chulalongkorn', 'University', 'for', 'providing', 'computing', 'facilities', '.']\n",
            "After stemming: ['extract', 'text', 'summar', 'for', 'thai', 'travel', 'new', 'base', 'on', 'keyword', 'score', 'in', 'thai', 'languag', 'sarunya', 'nathonghor', 'duangdao', 'wichadakul', 'depart', 'of', 'comput', 'engin', 'chulalongkorn', 'univers', 'bangkok', ',', 'thailand', 'depart', 'of', 'comput', 'engin', 'chulalongkorn', 'univers', 'bangkok', ',', 'thailand', 'sarunya.n', '@', 'student.chula.ac.th', 'abstract', 'in', 'recent', 'year', ',', 'peopl', 'are', 'seek', 'for', 'a', 'solut', 'to', 'improv', 'text', 'summar', 'for', 'thai', 'languag', '.', 'although', 'sever', 'solut', 'such', 'as', 'pagerank', ',', 'graph', 'rank', ',', 'latent', 'semant', 'analysi', '(', 'lsa', ')', 'model', ',', 'etc.', ',', 'have', 'been', 'propos', ',', 'research', 'result', 'in', 'thai', 'text', 'summar', 'were', 'restrict', 'due', 'to', 'limit', 'corpu', 'in', 'thai', 'languag', 'with', 'complex', 'grammar', '.', 'thi', 'paper', 'appli', 'a', 'text', 'summar', 'system', 'for', 'thai', 'travel', 'news', 'base', 'on', 'keyword', 'score', 'in', 'thai', 'languag', 'by', 'extract', 'the', 'most', 'relev', 'sentenc', 'from', 'the', 'origin', 'document', '.', 'we', 'compar', 'lsa', 'and', 'non-neg', 'matrix', 'factor', '(', 'nmf', ')', 'to', 'find', 'the', 'algorithm', 'that', 'is', 'suitabl', 'with', 'thai', 'travel', 'news', '.', 'the', 'suitabl', 'compress', 'rate', 'for', 'gener', 'sentenc', 'relev', 'score', '(', 'gr', ')', 'and', 'k-mean', 'cluster', 'were', 'also', 'evalu', '.', 'from', 'these', 'experi', ',', 'we', 'conclud', 'that', 'keyword', 'score', 'calcul', 'by', 'lsa', 'with', 'sentenc', 'select', 'by', 'gr', 'is', 'the', 'best', 'algorithm', 'for', 'summar', 'thai', 'travel', 'new', ',', 'compar', 'with', 'human', 'with', 'the', 'best', 'compress', 'rate', 'of', '20', '%', '.', 'cc', 'concept', '•', 'inform', 'system', '➝', 'inform', 'retriev', '➝', 'retriev', 'task', 'and', 'goals➝', 'summar', 'keyword', 'text', 'summar', ';', 'extract', 'summar', ';', 'non-neg', 'matrix', 'factor', '1', '.', 'introduct', 'daili', 'newspap', 'ha', 'abund', 'of', 'data', 'that', 'user', 'do', 'not', 'have', 'enough', 'time', 'for', 'read', 'them', '.', 'it', 'is', 'difficult', 'to', 'identifi', 'the', 'relev', 'inform', 'to', 'satisfi', 'the', 'inform', 'need', 'by', 'user', '.', 'automat', 'summar', 'can', 'reduc', 'the', 'problem', 'of', 'inform', 'overload', 'and', 'it', 'ha', 'been', 'propos', 'previous', 'in', 'english', 'and', 'other', 'languag', '.', 'howev', ',', 'there', 'were', 'onli', 'a', 'few', 'research', 'result', 'in', 'thai', 'text', 'summar', 'due', 'to', 'the', 'lack', 'of', 'corpu', 'in', 'thai', 'languag', 'and', 'the', 'complic', 'grammar', '.', 'text', 'summar', '[', '1', ']', 'is', 'a', 'techniqu', 'for', 'summar', 'the', 'content', 'of', 'the', 'document', '.', 'it', 'consist', 'of', 'three', 'step', ':', '1', ')', 'creat', 'an', 'intermedi', 'represent', 'of', 'the', 'input', 'text', ',', '2', ')', 'calcul', 'score', 'for', 'the', 'sentenc', 'base', 'on', 'the', 'concept', ',', 'and', '3', ')', 'choos', 'import', 'permiss', 'to', 'make', 'digit', 'or', 'hard', 'copi', 'of', 'all', 'or', 'part', 'of', 'thi', 'work', 'for', 'person', 'or', 'classroom', 'use', 'is', 'grant', 'without', 'fee', 'provid', 'that', 'copi', 'are', 'not', 'made', 'or', 'distribut', 'for', 'profit', 'or', 'commerci', 'advantag', 'and', 'that', 'copi', 'bear', 'thi', 'notic', 'and', 'the', 'full', 'citat', 'on', 'the', 'first', 'page', '.', 'copyright', 'for', 'compon', 'of', 'thi', 'work', 'own', 'by', 'other', 'than', 'acm', 'must', 'be', 'honor', '.', 'abstract', 'with', 'credit', 'is', 'permit', '.', 'to', 'copi', 'otherwis', ',', 'or', 'republish', ',', 'to', 'post', 'on', 'server', 'or', 'to', 'redistribut', 'to', 'list', ',', 'requir', 'prior', 'specif', 'permiss', 'and/or', 'a', 'fee', '.', 'request', 'permiss', 'from', 'permiss', '@', 'acm.org', '.', 'itcc', '2020', ',', 'august', '12–14', ',', '2020', ',', 'kuala', 'lumpur', ',', 'malaysia', '©', '2020', 'associ', 'for', 'comput', 'machineri', '.', 'acm', 'isbn', '978-1-4503-7539-9/20/08…', '$', '15.00', 'doi', ':', 'http', ':', '//doi.org/10.1145/3417473.3417479', 'duangdao.w', '@', 'chula.ac.th', 'sentenc', 'to', 'be', 'includ', 'in', 'the', 'summari', '.', 'text', 'summar', 'can', 'be', 'divid', 'into', '2', 'approach', '.', 'the', 'first', 'approach', 'is', 'the', 'extract', 'summar', ',', 'which', 'reli', 'on', 'a', 'method', 'for', 'extract', 'word', 'and', 'search', 'for', 'keyword', 'from', 'the', 'origin', 'document', '.', 'the', 'second', 'approach', 'is', 'the', 'abstract', 'summar', ',', 'which', 'analyz', 'word', 'by', 'linguist', 'principl', 'with', 'transcript', 'or', 'interpret', 'from', 'the', 'origin', 'document', '.', 'thi', 'approach', 'impli', 'more', 'effect', 'and', 'accur', 'summari', 'than', 'the', 'extract', 'method', '.', 'howev', ',', 'with', 'the', 'lack', 'of', 'thai', 'corpu', ',', 'we', 'chose', 'to', 'appli', 'an', 'extract', 'summar', 'method', 'for', 'thai', 'text', 'summar', '.', 'thi', 'research', 'focus', 'on', 'the', 'sentenc', 'extract', 'function', 'base', 'on', 'keyword', 'score', 'calcul', 'then', 'select', 'import', 'sentenc', 'base', 'on', 'the', 'gener', 'sentenc', 'relev', 'score', '(', 'gr', ')', ',', 'calcul', 'from', 'latent', 'semant', 'analysi', '(', 'lsa', ')', 'and', 'non-neg', 'matrix', 'factor', '(', 'nmf', ')', '.', 'we', 'also', 'tri', 'use', 'k-mean', 'cluster', 'for', 'document', 'summar', '.', 'in', 'thi', 'experi', ',', 'we', 'compar', '5', 'model', 'for', '5', 'round', 'with', 'thai', 'travel', 'news', 'use', 'the', 'compress', 'rate', 'of', '20', '%', ',', '30', '%', 'and', '40', '%', 'and', 'report', 'the', 'rate', 'and', 'method', 'that', 'produc', 'the', 'best', 'result', 'from', 'the', 'experi', '.', '2', '.', 'relat', 'work', 'in', 'recent', 'year', ',', 'sever', 'model', 'in', 'thai', 'text', 'summar', 'have', 'been', 'introduc', '.', 'suwanno', ',', 'n.', 'et', 'al', '.', '[', '2', ']', 'propos', 'a', 'thai', 'text', 'summar', 'that', 'extract', 'a', 'paragraph', 'from', 'a', 'document', 'base', 'on', 'thai', 'compound', 'noun', ',', 'term', 'frequenc', 'method', ',', 'and', 'headlin', 'score', 'for', 'gener', 'a', 'summari', '.', 'chongsuntornsri', ',', 'a.', ',', 'et', 'al', '.', '[', '3', ']', 'propos', 'a', 'new', 'approach', 'for', 'text', 'summar', 'in', 'thai', 'base', 'on', 'content-', 'and', 'graph-bas', 'with', 'the', 'use', 'of', 'topic', 'sensit', 'pagerank', 'algorithm', 'for', 'summar', 'and', 'rank', 'of', 'text', 'segment', '.', 'jaruskulchai', 'c.', ',', 'et', 'al', '.', '[', '4', ']', 'propos', 'a', 'method', 'to', 'summar', 'document', 'by', 'extract', 'import', 'sentenc', 'from', 'combin', 'the', 'specif', 'properti', '(', 'local', 'properti', ')', 'and', 'the', 'overal', 'properti', '(', 'global', 'properti', ')', 'of', 'the', 'sentenc', '.', 'the', 'overal', 'properti', 'were', 'base', 'on', 'the', 'relationship', 'between', 'sentenc', 'in', 'the', 'document', '.', 'from', 'their', 'experi', ',', 'the', 'summar', 'of', 'the', 'industri', 'news', 'got', '60', '%', 'precis', ',', '44', '%', 'recal', ',', 'and', '50.9', '%', 'f-measur', ',', 'the', 'gener', 'news', 'got', 'the', '51.8', '%', 'precis', ',', '38.5', '%', 'recal', ',', 'and', '43.1', '%', 'f-measur', 'while', 'the', 'fashion', 'magazin', 'got', '53.0', '%', 'precis', ',', '33.0', '%', 'recal', ',', 'and', '40.4', '%', 'f-measur', '.', 'mani', ',', 'i.', ',', 'et', 'al', '.', '[', '5', ']', 'propos', 'techniqu', 'of', 'text', 'summar', 'by', 'use', 'word', 'frequenc', 'in', 'the', 'document', 'and', 'calcul', 'the', 'weight', 'of', 'word', 'to', 'creat', 'a', 'keyword', 'group', '.', 'they', 'then', 'calcul', 'the', 'cosin', 'similar', 'of', 'sentenc', '.', 'the', 'research', 'use', 'a', '*', 'search', 'algorithm', 'to', 'find', 'the', 'shortest', 'sequenc', 'of', 'sentenc', 'from', 'keyword', 'group', 'by', 'topic', 'calcul', ',', 'sentenc', 'segment', 'and', 'word', 'group', '.', 'the', 'sequenc', 'of', 'sentenc', 'that', 'were', 'in', 'the', 'main', 'group', 'were', 'select', 'as', 'import', 'sentenc', '.', 'their', 'summar', 'of', 'the', 'agricultur', 'news', 'got', '68.57', '%', 'precis', ',', '51.95', '%', 'recal', 'and', '56.72', '%', 'f-measur', '.', 'lee', ',', 'j.', ',', 'et', 'al', '.', '[', '6', ']', 'propos', 'a', 'document', 'summar', 'method', 'use', 'non-neg', 'matrix', 'factor', '(', 'nmf', ')', '.', 'they', 'compar', 'between', 'latent', 'semant', 'analysi', '(', 'lsa', ')', 'and', 'nmf', 'to', 'find', 'the', 'weight', 'of', 'each', 'word', 'and', 'calcul', 'the', 'summat', 'of', 'weight', '.', 'the', 'import', 'sentenc', 'were', 'rank', 'and', 'select', 'into', 'the', 'summari', 'base', 'on', 'their', 'sum', 'weight', '.', 'base', 'on', 'lsa', ',', 'they', 'found', 'mani', 'weight', 'with', 'zero', 'and', 'neg', 'valu', '.', 'howev', ',', 'when', 'appli', 'nmf', ',', 'they', 'found', 'onli', 'the', 'posit', 'valu', 'and', 'the', 'scope', 'of', 'the', 'semant', 'featur', '’', 'mean', 'wa', 'narrow', '.', 'therefor', ',', 'they', 'propos', 'that', 'nmf', 'provid', 'a', 'greater', 'possibl', 'for', 'extract', 'import', 'sentenc', '.', '3', '.', 'preprocess', 'for', 'thai', 'text', 'the', 'first', 'step', 'for', 'work', 'with', 'thai', 'text', 'is', 'word', 'token', '.', 'even', 'though', 'thai', 'write', 'system', 'ha', 'no', 'delimit', 'to', 'indic', 'word', 'boundari', 'togeth', 'with', 'mani', 'rule', 'for', 'word', 'segment', ',', 'sever', 'thai', 'word', 'token', 'program', 'have', 'been', 'propos', '.', 'tabl', '1', 'show', 'f1', 'score', 'of', 'the', 'recent', 'program', 'train', 'and', 'test', 'by', 'one', 'of', 'our', 'laboratori', 'member', 'with', 'the', 'data', 'from', 'best2010', 'corpu', '[', '7', ']', '.', 'cutkum', '[', '8', ']', 'got', 'the', 'highest', 'f1', 'score', ',', 'henc', ',', 'we', 'use', 'cutkum', 'for', 'thi', 'step', '.', 'tabl', '1', '.', 'comparison', 'of', 'thai', 'word', 'token', 'program', 'tool', 'f1', 'score', 'valid', 'pyicu', '[', '9', ']', 'articl', '100', '0.6155', 'encyclopedia', '100', '0.6932', 'new', '100', '0.5987', 'novel', '100', '0.6800', 'lexto', '[', '10', ']', '0.7267', '0.7709', '0.6994', '0.7701', 'cutkum', 'wordcutpi', '[', '11', ']', '0.9322', '0.6212', '0.9299', '0.6286', '0.8987', '0.6571', '0.7140', '0.6247', 'cunlp', '[', '12', ']', '0.6910', '0.6172', '0.5748', '0.0000', 'swath', '[', '13', ']', '0.6347', '0.6858', '0.6200', '0.6867', '3.1', 'latent', 'semant', 'analysi', 'latent', 'semant', 'analysi', '(', 'lsa', ')', '[', '14', ']', 'is', 'the', 'algorithm', ',', 'which', 'reduc', 'the', 'dimension', 'of', 'term', 'document', '.', 'the', 'algorithm', 'creat', 'a', 'matrix', 'by', 'use', 'word', 'frequenc', ',', 'appli', 'the', 'singular', 'valu', 'decomposit', '(', 'svd', ')', '[', '15', ']', ',', 'and', 'then', 'find', 'close', 'relat', 'term', 'and', 'document', '.', 'the', 'origin', 'matrix', 'a', 'can', 'be', 'separ', 'into', 'three', 'matric', ',', 'where', 'u', 'is', 'the', 'm', 'x', 'r', '(', 'word', 'x', 'extract', 'concept', ')', 'matrix', ',', 'v', 'is', 'the', 'n', 'x', 'r', '(', 'sentenc', 'x', 'extract', 'concept', ')', 'matrix', ',', 'and', 'σ', 'is', 'the', 'r', 'x', 'r', 'diagon', 'matrix', ',', 'which', 'can', 'be', 'reconstruct', 'to', 'find', 'the', 'origin', 'matrix', 'a', '.', 'the', 'svd', 'can', 'be', 'repres', 'in', 'eq', '.', '(', '1', ')', '.', '3.2', 'a', '≈', '𝑈𝑈𝑈𝑈𝑉𝑉', '𝑇𝑇', 'of', 'the', 'relat', 'singular', 'valu', 'over', 'the', 'sum', 'of', 'all', 'singular', 'valu', ',', 'for', 'each', 'concept', '.', '3.3', '(', '2', ')', 'a', '=', '𝑊𝑊𝑊𝑊', 'factor', 'w', 'and', 'h', 'can', 'be', 'found', 'by', 'solv', 'the', 'optim', 'problem', 'as', 'follow', ',', 'where𝑊𝑊𝑗𝑗𝑗𝑗', '≥', '0', ',', '𝐻𝐻𝑖𝑖𝑖𝑖', '≥', '0.', '𝑚𝑚', '𝑛𝑛', '𝑟𝑟', '𝑗𝑗=1', '𝑖𝑖=1', '𝑙𝑙=1', '2', '𝑚𝑚𝑚𝑚𝑚𝑚', '𝐹𝐹', '(', '𝑊𝑊', ',', '𝐻𝐻', ')', '=', '||', '𝐴𝐴', '−', '𝑊𝑊𝑊𝑊', '||2𝐹𝐹', '=', '�', '�', '�𝐴𝐴𝑖𝑖𝑖𝑖', '−', '�', '𝑊𝑊𝑖𝑖𝑖𝑖', '𝐻𝐻𝑖𝑖𝑖𝑖', '�', '(', '3', ')', 'nmf', 'and', 'lsa', 'are', 'both', 'matrix', 'factor', 'algorithm', '.', 'howev', ',', 'when', 'use', 'nmf', 'to', 'find', 'keyword', ',', 'nmf', 'will', 'return', 'the', 'keyword', 'that', 'are', 'close', 'relat', 'becaus', 'it', 'compon', 'have', 'onli', 'nonneg', 'valu', '.', 'as', 'lsa', 'ha', 'both', 'posit', 'and', 'neg', 'valu', 'as', 'well', 'as', 'some', 'zero', ',', 'it', 'get', 'a', 'wider', 'distribut', '.', 'the', 'semant', 'featur', 'repres', 'a', 'concept', 'of', 'mean', 'for', 'root', 'of', 'word', 'that', 'have', 'a', 'relationship', '.', 'for', 'exampl', ',', 'man', ',', 'human', ',', 'male', 'and', 'adult', 'have', 'the', 'same', 'semant', ',', 'henc', 'their', 'semant', 'valu', 'are', 'close', '.', 'in', 'thi', 'paper', ',', 'we', 'appli', 'lsa', 'and', 'nmf', 'on', 'the', 'thai', 'travel', 'new', 'dataset', 'for', 'calcul', 'the', 'semant', 'weight', ',', 'which', 'repres', 'the', 'relationship', 'between', 'sentenc', 'and', 'word', 'in', 'order', 'to', 'select', 'the', 'repres', 'sentenc', 'for', 'summar', '.', '3.4', 'gener', 'document', 'summar', 'by', 'nmf', 'lee', ',', 'j.', ',', 'et', 'al', '.', 'propos', 'eq', '.', '(', '4', ')', 'and', 'eq', '.', '(', '5', ')', 'to', 'select', 'a', 'number', 'of', 'sentenc', 'base', 'on', 'nmf', ',', 'which', 'got', 'the', 'highest', 'semant', 'weight', 'valu', ',', 'where', '𝐻𝐻𝑖𝑖𝑖𝑖', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑖𝑖', 'in', 'the', 'sentenc', '𝑗𝑗', '.', 'gener', 'relev', 'of', 'jth', 'sentenc', '𝑟𝑟', '(', '1', ')', '=', '�', '𝐻𝐻𝑖𝑖𝑖𝑖', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', 'document', 'summar', 'use', 'lsa', 'gong', ',', 'y.', 'et', 'al', '.', '[', '16', ']', 'propos', 'a', 'document', 'summar', 'base', 'on', 'svd', 'matric', '.', 'in', 'our', 'work', ',', 'after', 'appli', 'svd', 'to', 'matrix', 'a', ',', '𝑉𝑉', '𝑇𝑇', 'matrix', 'use', 'for', 'select', 'the', 'import', 'sentenc', '.', 'the', 'cell', 'valu', 'of', 'the', 'matrix', 'show', 'the', 'relationship', 'between', 'sentenc', 'and', 'extract', 'concept', '.', 'a', 'sentenc', 'with', 'the', 'highest', 'cell', 'valu', 'of', 'each', 'concept', 'will', 'be', 'select', 'into', 'the', 'summari', 'start', 'from', 'the', 'most', 'import', 'concept', '.', 'the', 'total', 'number', 'of', 'sentenc', 'in', 'the', 'summari', 'will', 'be', 'equal', 'to', 'the', 'number', 'all', 'detect', 'concept', '.', 'murray', ',', 'g.', 'et', 'al', '.', '[', '17', ']', 'propos', 'a', 'document', 'summar', 'base', 'on', 'svd', 'matric', 'use', '𝑉𝑉', '𝑇𝑇', 'and', 'σ', 'matric', 'for', 'sentenc', 'select', '.', 'the', 'author', 'propos', 'that', 'more', 'than', 'one', 'sentenc', 'could', 'be', 'collect', 'from', 'the', 'more', 'import', 'concept', '.', 'the', 'decis', 'of', 'how', 'mani', 'sentenc', 'would', 'be', 'collect', 'from', 'each', 'concept', 'depend', 'on', 'the', 'σ', 'matrix', '.', 'the', 'valu', 'wa', 'decid', 'by', 'get', 'the', 'percentag', 'non-neg', 'matrix', 'factor', 'non-neg', 'matrix', 'factor', '(', 'nmf', ')', 'is', 'a', 'method', 'of', 'matrix', 'factor', 'subject', 'to', 'the', 'non-neg', 'constraint', '.', 'lee', ',', 'j.', ',', 'et', 'al', '.', 'propos', 'the', 'model', 'base', 'on', 'nmf', 'for', 'document', 'summar', '.', 'nmf', 'decompos', 'a', 'non-neg', 'matrix', '𝐴𝐴', '∈', '𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'into', 'two', 'nonneg', 'matric', '.', 'the', 'first', 'matrix', '𝑚𝑚', 'x', '𝑟𝑟', 'is', 'a', 'non-neg', 'semant', 'featur', 'matrix', '(', 'nsfm', ')', ',', '𝑊𝑊', '.', 'the', 'second', 'matrix', '𝑟𝑟', 'x', '𝑛𝑛', 'is', 'a', 'nonneg', 'semant', 'variabl', 'matrix', '(', 'nsvm', ')', ',', '𝐻𝐻', '.', 'so', ',', 'we', 'have', '𝑊𝑊', '∈', '𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'and', '𝐻𝐻', '∈', '𝑅𝑅𝑟𝑟𝑟𝑟𝑟𝑟', 'and', 'both', 'term', 'are', 'non-neg', 'as', 'shown', 'in', 'eq', '.', '(', '2', ')', 'and', 'eq', '.', '(', '3', ')', '.', '(', '4', ')', '𝑖𝑖=1', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', '=', '∑𝑛𝑛𝑞𝑞=1', '𝐻𝐻𝑖𝑖𝑖𝑖', '𝑟𝑟', '∑𝑝𝑝=1', '∑𝑛𝑛𝑞𝑞=1', '𝐻𝐻𝑝𝑝𝑝𝑝', '(', '5', ')', 'the', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', 'is', 'the', 'rel', 'relev', 'of', 'the', 'ith', 'semant', 'featur', '(', '𝑊𝑊𝑖𝑖', ')', ',', 'where', '𝐻𝐻𝑖𝑖𝑖𝑖', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑖𝑖', 'in', 'the', 'sentenc', '𝑞𝑞', 'and', '𝐻𝐻𝑝𝑝𝑝𝑝', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑝𝑝', 'in', 'the', 'sentenc', '𝑞𝑞', '.', 'the', 'sentenc', 'can', 'be', 'rank', 'by', 'gener', 'relev', 'sentenc', 'score', '.', 'sentenc', 'with', 'the', 'maximum', 'score', 'will', 'be', 'select', 'into', 'the', 'summari', '.', '3.5', 'cosin', 'similar', 'cosin', 'similar', '[', '18', ']', 'is', 'a', 'wide', 'use', 'method', 'to', 'measur', 'the', 'similar', 'between', 'vector', 'repres', 'the', 'document', '.', 'the', 'result', 'of', 'cosin', 'similar', 'is', 'rang', 'from', '0', 'to', '1', '.', 'if', 'it', 'is', 'closer', 'to', '1', ',', 'that', 'mean', 'both', 'vector', 'are', 'similar', '.', 'eq', '.', '(', '6', ')', 'and', 'eq', '.', '(', '7', ')', 'repres', 'the', 'cosin', 'similar', 'equat', ',', 'where', 'co', '(', 'θ', ')', 'is', 'the', 'dot', 'product', 'between', 'vector', 'of', 'sentenc', 'a', 'and', 'b', 'and', 'divid', 'by', 'the', 'product', 'of', 'the', 'two', \"vectors'\", 'length', '.', 'in', 'thi', 'paper', ',', 'we', 'deploy', 'cosin', 'similar', 'to', 'measur', 'the', 'similar', 'of', 'sentenc', 'in', 'k-mean', 'cluster', '.', 'a∙b', '||a||', '||b||', '∑ni=1', 'ai', 'bi', 'similar', '(', 'a', ',', 'b', ')', '=', 'co', '(', 'θ', ')', '=', '(', '7', ')', 'k-mean', 'cluster', '15', '67', '7', '7', '13', '13', '55', '38', 'tabl', '2', 'show', 'the', 'overal', 'number', 'of', 'sentenc', 'of', 'news', 'within', 'each', 'dataset', '.', 'the', 'averag', 'number', 'of', 'sentenc', 'per', 'news', 'of', 'the', '5', 'set', 'were', '21', ',', '16', ',', '15', ',', '13', 'and', '13', 'sentenc', ',', 'respect', '.', '5', '.', 'pipelin', 'for', 'gener', 'summari', 'in', 'thi', 'section', ',', 'we', 'demonstr', 'our', 'pipelin', '(', 'figur', '1', ')', 'use', 'for', 'text', 'summar', 'to', 'gener', 'a', 'summari', 'for', 'a', 'thai', 'travel', 'news', '.', 'word', 's9', '6', 'round', '4', 'round', '5', 'tabl', '3', '.', 'exampl', 'of', 'word', 'by', 'sentenc', 'matrix', 'a', 's8', 'round', '3', 'avg', '.', 'number', 'of', 'sentenc', 's7', '21', '16', 'round', '1', 'round', '2', 'min', '.', 'number', 'of', 'sentenc', 's6', '7', '7', 'max', '.', 'number', 'of', 'sentenc', '58', '58', 'dataset', 's5', 'tabl', '2', '.', 'overal', 'sentenc', 'languag', 'of', 'each', 'dataset', 's4', 'data', 'prepar', 'the', 'standard', 'data', 'set', 'in', 'thai', 'languag', 'are', 'unavail', 'for', 'evalu', 'text', 'summar', 'system', '.', 'therefor', ',', 'we', 'collect', '400', 'thai', 'travel', 'news', 'from', 'thairath', 'and', 'manag', 'onlin', 'newspap', 'to', 'be', 'use', 'as', 'dataset', 'for', 'our', 'experi', '.', 'we', 'split', '400', 'travel', 'news', 'into', '5', 'set', 'of', '80', 'news', 'each', '.', 'we', 'then', 'evalu', 'the', 'perform', 'of', 'text', 'summar', 'method', 'which', 'were', 'lsa', 'and', 'nmf', 'by', 'compar', 'their', 'result', 'with', 'the', 'summari', 'manual', 'curat', 'by', 'two', 'expert', 'from', 'the', 'faculti', 'of', 'liber', 'art', ',', 'ubon', 'ratchathani', 'univers', '.', 'the', 'open-sourc', 'python', 'librari', 'such', 'as', 'numpi', '[', '19', ']', 'and', 'sklearn', '[', '20', ']', 'were', 'use', 'in', 'our', 'system', '.', 'we', 'convert', 'the', 'thai', 'travel', 'news', 'obtain', 'from', 'thairath', 'and', 'manag', 'onlin', 'newspap', 'to', 'plain', 'text', '.', 'then', ',', 'the', 'sentenc', 'of', 'each', 'news', 'were', 'segment', 'by', 'human', 'with', 'the', 'follow', 'format', ':', 'si', '=', '‘', 'xxx', '’', ',', 'where', 'si', 'repres', 'the', 'order', 'of', 'the', 'sentenc', 'in', 'the', 'origin', 'document', 'and', '‘', 'xxx', '’', 'repres', 'the', 'content', 'of', 'that', 'sentenc', '.', 'after', 'remov', 'stop', 'word', 'and', 'duplic', 'word', ',', 'we', 'built', 'a', 'document', 'term', 'matrix', 'or', 'matrix', 'a', 'then', 'appli', 'svd', 'and', 'nmf', 'to', 'the', 'matrix', '.', 'then', ',', 'we', 'use', 'python', 'modul', 'numpy.linalg.svd', 'to', 'calcul', 'svd', 'and', 'sklearn.decomposit', 'to', 'calcul', 'nmf', '.', 'for', 'sentenc', 'select', ',', 'we', 'use', 'gong', ',', 'y.', 'et', 'al', '.', 'and', 'murray', ',', 'g.', 'et', 'al', '.', 'approach', 'for', 'calcul', 'weight', 'of', 'the', 'sentenc', 'score', 'then', 'select', 'sentenc', 'with', 'the', 'highest', 'score', 'into', 'the', 'summari', '.', 'for', 'keyword', 'score', 'calcul', 'of', 'nmf', ',', 'we', 'calcul', 'the', 'keyword', 'score', 'from', 'eq', '.', '(', '5', ')', 'and', 'then', 'select', 'the', 'sentenc', 'with', 'the', 'highest', 'score', 'from', 'each', 'concept', '.', 'the', 'python', 'modul', 'sklearn.clust', 'wa', 'use', 'for', 'k-mean', 'cluster', '.', 'the', 'select', 'sentenc', 'from', 'all', 'approach', 'were', 'in', 'the', 'same', 'order', 'as', 'the', 'origin', 'document', '.', 'in', 'thi', 'paper', ',', 'we', 'perform', 'the', '20', '%', ',', '30', '%', 'and', '40', '%', 'document', 'compress', '.', 'thi', 'meant', '80', '%', ',', '70', '%', 'and', '60', '%', 'of', 'the', 'sentenc', 'will', 'be', 'select', 'into', 'the', 'summari', '.', 's3', '4', '.', 'figur', '1', '.', 'document', 'summar', 'pipelin', 'base', 'on', 'lsa', 'and', 'nmf', 's2', 'for', 'sentenc', 'select', 'by', 'k-mean', 'cluster', ',', 'we', 'group', 'similar', 'sentenc', 'into', 'the', 'same', 'cluster', 'use', 'the', 'follow', 'step', ':', '1', '.', 'randomli', 'select', 'k', 'sentenc', 'as', 'the', 'repres', 'of', 'k', 'group', '.', 'k', 'in', 'thi', 'paper', 'is', 'the', 'number', 'of', 'sentenc', 'that', 'will', 'be', 'select', 'into', 'the', 'summari', '.', '2', '.', 'calcul', 'centroid', 'of', 'each', 'group', 'by', 'use', 'the', 'valu', 'of', 'sentenc', 'vector', 'from', 'v', 'matrix', 'for', 'lsa', 'and', '𝐻𝐻𝑇𝑇', 'matrix', 'for', 'nmf', '.', '3', '.', 'use', 'cosin', 'similar', 'to', 'calcul', 'sentenc', 'similar', 'between', 'a', 'sentenc', 'and', 'the', 'centroid', 'of', 'each', 'group', '.', 'then', 'assign', 'that', 'sentenc', 'to', 'the', 'group', 'with', 'the', 'highest', 'similar', '.', '4', '.', 'repeat', 'step', '2-3', 'until', 'all', 'sentenc', 'are', 'assign', 'to', 'a', 'group', ',', 'no', 'sentenc', 'chang', 'the', 'group', ',', 'or', 'the', 'similar', 'between', 'sentenc', 'and', 'their', 'centroid', 'is', 'close', '.', '5', '.', 'select', 'a', 'sentenc', 'with', 'the', 'maximum', 'similar', 'score', 'with', 'the', 'centroid', 'of', 'the', 'group', 'and', 'add', 'it', 'into', 'the', 'summari', '.', 's1', '3.6', 'a∙b', '=', 'n', 'n', '||a||', '||b||', '�∑i=1', 'a2i', '�∑i=1', 'bi2', '(', '6', ')', 'mr.yonta', 'ak', '1', '0', '0', '0', '0', '0', '0', '0', '0', 'supason', '1', '0', '0', '0', '0', '0', '0', '0', '0', 'tourism', 'author', 'of', 'thailand', '1', '0', '0', '0', '0', '0', '0', '0', '0', '…', '…', '…', '…', '…', '…', '…', '…', '…', '…', 'tabl', '3', 'demonstr', 'an', 'exampl', 'of', 'a', 'matrix', '𝐴𝐴', ',', 'construct', 'from', 'word', 'count', 'by', 'sentenc', 'of', 'a', 'thai', 'travel', 'news', '.', 'it', 'wa', 'compos', 'of', '98', 'word', 'and', '9', 'sentenc', '.', 'thi', 'matrix', '𝐴𝐴', 'wa', 'then', 'appli', 'with', 'the', 'lsa', 'and', 'nmf', '.', 'the', 'sentenc', 'vector', 'were', 'calcul', 'from', 'the', 'term', 'weight', 'and', 'the', 'semant', 'featur', 'vector', 'from', 'eq', '.', '(', '1', ')', 'for', 'lsa', 'and', 'eq', '.', '(', '2', ')', 'for', 'nmf', '.', 'sentenc', 'from', 'all', 'concept', '.', 'the', 'gener', 'sentenc', 'relev', 'score', 'for', 'nmf', 'also', 'collect', 'one', 'sentenc', 'for', 'each', 'concept', ',', 'the', 'same', 'as', 'gong', ',', 'y.', 'et', 'al', '.', 'but', 'with', 'the', 'highest', 'score', 'calcul', 'by', 'eq', '.', '(', '5', ')', '.', 'as', 'multipl', 'import', 'sentenc', 'could', 'be', 'select', 'from', 'a', 'more', 'import', 'concept', ',', 'murray', ',', 'g.', 'et', 'al', '.', 'outperform', 'both', 'gong', ',', 'y.', 'et', 'al', '.', 'and', 'the', 'gr', 'method', '.', '6', '.', 'experi', 'and', 'result', '6.1', 'perform', 'evalu', 'measur', '7', '.', 'we', 'evalu', 'the', 'result', 'of', 'the', 'summar', 'by', 'use', 'standard', 'accuraci', ',', 'precis', ',', 'recal', ',', 'and', 'f1', 'score', '[', '21', ']', '.', 'these', 'measur', 'quantifi', 'the', 'differ', 'between', 'the', 'summari', 'from', 'human', 'and', 'the', 'experiment', 'method', '.', 'the', 'precis', 'show', 'the', 'correct', 'of', 'the', 'extract', 'sentenc', 'and', 'the', 'recal', 'reflect', 'the', 'number', 'of', 'good', 'sentenc', 'miss', 'by', 'the', 'method', '.', '6', '.', '2', 'experi', 'result', 'in', 'thi', 'experiment', 'set', ',', 'we', 'would', 'like', 'to', 'explor', 'how', 'the', 'differ', 'sentenc', 'select', 'method', ':', 'the', 'gener', 'sentenc', 'relev', 'score', 'and', 'k-mean', 'cluster', ',', 'affect', 'the', 'text', 'summar', 'result', '.', 'for', 'k-mean', 'cluster', ',', 'both', 'svd', 'and', 'nmf', 'had', 'similar', 'summar', 'effici', '.', 'the', 'f1', 'score', 'of', 'svd', 'with', 'k-mean', 'cluster', 'wa', '0.83', ',', '0.72', ',', 'and', '0.62', 'for', 'the', 'compress', 'rate', 'of', '20', '%', ',', '30', '%', ',', 'and', '40', '%', '.', 'for', 'the', 'nmf', 'with', 'k-mean', 'cluster', ',', 'the', 'f1', 'score', 'for', 'the', 'three', 'compress', 'rate', 'wa', '0.83', ',', '0.74', 'and', '0.64', '.', 'for', 'the', 'gener', 'sentenc', 'relev', 'score', ',', 'the', 'best', 'f1', 'score', 'for', 'the', 'compress', 'rate', 'of', '20', '%', ',', '30', '%', ',', 'and', '40', '%', 'wa', '0.86', ',', '0.78', 'and', '0.68', 'respect', 'and', 'the', 'best', 'f1', 'score', 'for', 'all', 'compress', 'rate', 'were', 'from', 'the', 'approach', 'of', 'murray', ',', 'g.', 'et', 'al', '.', 'figur', '2', '.', 'thai', 'text', 'summar', 'effici', 'of', '5', 'model', 'figur', '2', 'show', 'the', 'thai', 'text', 'summar', 'effici', 'of', '5', 'model', ':', '(', '1', ')', 'nmf', 'with', 'gr', ',', '(', '2', ')', 'nmf', 'with', 'k-mean', ',', '(', '3', ')', 'svd', 'with', 'sentenc', 'score', 'by', 'gong', ',', 'y.', 'et', 'al.', ',', '(', '4', ')', 'svd', 'with', 'k-mean', ',', 'and', '(', '5', ')', 'svd', 'with', 'sentenc', 'score', 'by', 'murray', ',', 'g.', 'et', 'al', '.', 'appli', 'to', '400', 'thai', 'travel', 'news', ',', 'divid', 'into', '5', 'set', 'of', '80', 'news', 'each', ',', 'with', 'the', 'vari', 'compress', 'rate', 'of', '20', '%', ',', '30', '%', 'and', '40', '%', '.', 'from', 'thi', 'experi', ',', 'the', 'best', 'model', 'base', 'on', 'keyword', 'score', 'for', 'thai', 'travel', 'news', 'summar', 'wa', 'svd', 'with', 'sentenc', 'select', 'by', 'murray', ',', 'g.', 'et', 'al', '.', 'thi', 'model', 'with', 'the', 'compress', 'rate', 'of', '20', '%', 'got', 'the', 'highest', 'score', 'becaus', 'murray', 'g.', 'et', 'al', '.', 'method', 'determin', 'the', 'number', 'of', 'sentenc', 'to', 'be', 'extract', 'from', 'each', 'concept', 'base', 'on', 'the', 'import', 'of', 'that', 'concept', '.', 'the', 'method', 'of', 'gong', ',', 'y.', 'et', 'al.', ',', 'on', 'the', 'other', 'hand', 'wa', 'propos', 'to', 'select', 'onli', 'one', 'sentenc', 'with', 'the', 'highest', 'score', 'from', 'each', 'concept', 'so', 'that', 'the', 'summari', 'would', 'includ', 'conclus', 'in', 'thi', 'paper', ',', 'we', 'appli', 'sever', 'text', 'summar', 'method', 'to', 'thai', 'travel', 'new', 'base', 'on', 'keyword', 'score', 'in', 'thai', 'languag', 'by', 'extract', 'the', 'most', 'relev', 'sentenc', 'from', 'the', 'origin', 'document', '.', 'we', 'compar', 'lsa', 'and', 'nmf', 'togeth', 'with', 'differ', 'sentenc', 'select', 'method', ',', 'to', 'find', 'the', 'algorithm', 'suitabl', 'with', 'thi', \"paper'\", 'data', 'sourc', '.', 'we', 'conclud', 'that', 'keyword', 'score', 'calcul', 'by', 'lsa', 'with', 'sentenc', 'select', 'by', 'gener', 'sentenc', 'relev', 'score', 'by', 'murray', ',', 'g.', 'et', 'al', '.', 'wa', 'the', 'best', 'algorithm', 'while', 'the', 'best', 'compress', 'rate', 'of', 'all', 'model', 'wa', '20', '%', ',', 'for', 'summar', 'thai', 'travel', 'new', 'compar', 'with', 'human', '.', 'in', 'futur', 'work', ',', 'we', 'plan', 'to', 'perform', 'the', 'experi', 'with', 'differ', 'type', 'of', 'document', 'and', 'improv', 'word', 'segment', 'of', 'compound', 'noun', 'that', 'wa', 'not', 'handl', 'by', 'cutkum', '.', '8', '.', 'acknowledg', 'we', 'would', 'like', 'to', 'thank', 'the', 'depart', 'of', 'comput', 'engin', ',', 'faculti', 'of', 'engin', ',', 'chulalongkorn', 'univers', 'for', 'provid', 'comput', 'facil', '.']\n",
            "After lemmatization: ['Extractive', 'Text', 'Summarization', 'for', 'Thai', 'Travel', 'News', 'Based', 'on', 'Keyword', 'Scored', 'in', 'Thai', 'Language', 'Sarunya', 'Nathonghor', 'Duangdao', 'Wichadakul', 'Department', 'of', 'Computer', 'Engineering', 'Chulalongkorn', 'University', 'Bangkok', ',', 'Thailand', 'Department', 'of', 'Computer', 'Engineering', 'Chulalongkorn', 'University', 'Bangkok', ',', 'Thailand', 'Sarunya.N', '@', 'Student.Chula.ac.th', 'ABSTRACT', 'In', 'recent', 'year', ',', 'people', 'are', 'seeking', 'for', 'a', 'solution', 'to', 'improve', 'text', 'summarization', 'for', 'Thai', 'language', '.', 'Although', 'several', 'solution', 'such', 'a', 'PageRank', ',', 'Graph', 'Rank', ',', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'model', ',', 'etc.', ',', 'have', 'been', 'proposed', ',', 'research', 'result', 'in', 'Thai', 'text', 'summarization', 'were', 'restricted', 'due', 'to', 'limited', 'corpus', 'in', 'Thai', 'language', 'with', 'complex', 'grammar', '.', 'This', 'paper', 'applied', 'a', 'text', 'summarization', 'system', 'for', 'Thai', 'travel', 'news', 'based', 'on', 'keyword', 'scored', 'in', 'Thai', 'language', 'by', 'extracting', 'the', 'most', 'relevant', 'sentence', 'from', 'the', 'original', 'document', '.', 'We', 'compared', 'LSA', 'and', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'to', 'find', 'the', 'algorithm', 'that', 'is', 'suitable', 'with', 'Thai', 'travel', 'news', '.', 'The', 'suitable', 'compression', 'rate', 'for', 'Generic', 'Sentence', 'Relevance', 'score', '(', 'GRS', ')', 'and', 'K-means', 'clustering', 'were', 'also', 'evaluated', '.', 'From', 'these', 'experiment', ',', 'we', 'concluded', 'that', 'keyword', 'scored', 'calculation', 'by', 'LSA', 'with', 'sentence', 'selection', 'by', 'GRS', 'is', 'the', 'best', 'algorithm', 'for', 'summarizing', 'Thai', 'Travel', 'News', ',', 'compared', 'with', 'human', 'with', 'the', 'best', 'compression', 'rate', 'of', '20', '%', '.', 'CCS', 'Concepts', '•', 'Information', 'system', '➝', 'Information', 'retrieval', '➝', 'Retrieval', 'task', 'and', 'goals➝', 'Summarization', 'Keywords', 'Text', 'summarization', ';', 'extractive', 'summarization', ';', 'non-negative', 'matrix', 'factorization', '1', '.', 'INTRODUCTION', 'Daily', 'newspaper', 'ha', 'abundant', 'of', 'data', 'that', 'user', 'do', 'not', 'have', 'enough', 'time', 'for', 'reading', 'them', '.', 'It', 'is', 'difficult', 'to', 'identify', 'the', 'relevant', 'information', 'to', 'satisfy', 'the', 'information', 'needed', 'by', 'user', '.', 'Automatic', 'summarization', 'can', 'reduce', 'the', 'problem', 'of', 'information', 'overloading', 'and', 'it', 'ha', 'been', 'proposed', 'previously', 'in', 'English', 'and', 'other', 'language', '.', 'However', ',', 'there', 'were', 'only', 'a', 'few', 'research', 'result', 'in', 'Thai', 'text', 'summarization', 'due', 'to', 'the', 'lack', 'of', 'corpus', 'in', 'Thai', 'language', 'and', 'the', 'complicated', 'grammar', '.', 'Text', 'Summarization', '[', '1', ']', 'is', 'a', 'technique', 'for', 'summarizing', 'the', 'content', 'of', 'the', 'document', '.', 'It', 'consists', 'of', 'three', 'step', ':', '1', ')', 'create', 'an', 'intermediate', 'representation', 'of', 'the', 'input', 'text', ',', '2', ')', 'calculate', 'score', 'for', 'the', 'sentence', 'based', 'on', 'the', 'concept', ',', 'and', '3', ')', 'choose', 'important', 'Permission', 'to', 'make', 'digital', 'or', 'hard', 'copy', 'of', 'all', 'or', 'part', 'of', 'this', 'work', 'for', 'personal', 'or', 'classroom', 'use', 'is', 'granted', 'without', 'fee', 'provided', 'that', 'copy', 'are', 'not', 'made', 'or', 'distributed', 'for', 'profit', 'or', 'commercial', 'advantage', 'and', 'that', 'copy', 'bear', 'this', 'notice', 'and', 'the', 'full', 'citation', 'on', 'the', 'first', 'page', '.', 'Copyrights', 'for', 'component', 'of', 'this', 'work', 'owned', 'by', 'others', 'than', 'ACM', 'must', 'be', 'honored', '.', 'Abstracting', 'with', 'credit', 'is', 'permitted', '.', 'To', 'copy', 'otherwise', ',', 'or', 'republish', ',', 'to', 'post', 'on', 'server', 'or', 'to', 'redistribute', 'to', 'list', ',', 'requires', 'prior', 'specific', 'permission', 'and/or', 'a', 'fee', '.', 'Request', 'permission', 'from', 'Permissions', '@', 'acm.org', '.', 'ITCC', '2020', ',', 'August', '12–14', ',', '2020', ',', 'Kuala', 'Lumpur', ',', 'Malaysia', '©', '2020', 'Association', 'for', 'Computing', 'Machinery', '.', 'ACM', 'ISBN', '978-1-4503-7539-9/20/08…', '$', '15.00', 'DOI', ':', 'http', ':', '//doi.org/10.1145/3417473.3417479', 'Duangdao.W', '@', 'Chula.ac.th', 'sentence', 'to', 'be', 'included', 'in', 'the', 'summary', '.', 'Text', 'summarization', 'can', 'be', 'divided', 'into', '2', 'approach', '.', 'The', 'first', 'approach', 'is', 'the', 'extractive', 'summarization', ',', 'which', 'relies', 'on', 'a', 'method', 'for', 'extracting', 'word', 'and', 'searching', 'for', 'keywords', 'from', 'the', 'original', 'document', '.', 'The', 'second', 'approach', 'is', 'the', 'abstractive', 'summarization', ',', 'which', 'analyzes', 'word', 'by', 'linguistic', 'principle', 'with', 'transcription', 'or', 'interpretation', 'from', 'the', 'original', 'document', '.', 'This', 'approach', 'implies', 'more', 'effective', 'and', 'accurate', 'summary', 'than', 'the', 'extractive', 'method', '.', 'However', ',', 'with', 'the', 'lack', 'of', 'Thai', 'corpus', ',', 'we', 'chose', 'to', 'apply', 'an', 'extractive', 'summarization', 'method', 'for', 'Thai', 'text', 'summarization', '.', 'This', 'research', 'focused', 'on', 'the', 'sentence', 'extraction', 'function', 'based', 'on', 'keyword', 'score', 'calculation', 'then', 'selecting', 'important', 'sentence', 'based', 'on', 'the', 'Generic', 'Sentence', 'Relevance', 'score', '(', 'GRS', ')', ',', 'calculated', 'from', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'and', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', '.', 'We', 'also', 'tried', 'using', 'K-means', 'clustering', 'for', 'document', 'summarization', '.', 'In', 'this', 'experiment', ',', 'we', 'compared', '5', 'model', 'for', '5', 'round', 'with', 'Thai', 'travel', 'news', 'using', 'the', 'compression', 'rate', 'of', '20', '%', ',', '30', '%', 'and', '40', '%', 'and', 'reported', 'the', 'rate', 'and', 'method', 'that', 'produced', 'the', 'best', 'result', 'from', 'the', 'experiment', '.', '2', '.', 'RELATED', 'WORKS', 'In', 'recent', 'year', ',', 'several', 'model', 'in', 'Thai', 'Text', 'summarization', 'have', 'been', 'introduced', '.', 'Suwanno', ',', 'N.', 'et', 'al', '.', '[', '2', ']', 'proposed', 'a', 'Thai', 'text', 'summarization', 'that', 'extracted', 'a', 'paragraph', 'from', 'a', 'document', 'based', 'on', 'Thai', 'compound', 'noun', ',', 'term', 'frequency', 'method', ',', 'and', 'headline', 'score', 'for', 'generating', 'a', 'summary', '.', 'Chongsuntornsri', ',', 'A.', ',', 'et', 'al', '.', '[', '3', ']', 'proposed', 'a', 'new', 'approach', 'for', 'Text', 'summarization', 'in', 'Thai', 'based', 'on', 'content-', 'and', 'graph-based', 'with', 'the', 'use', 'of', 'Topic', 'Sensitive', 'PageRank', 'algorithm', 'for', 'summarizing', 'and', 'ranking', 'of', 'text', 'segment', '.', 'Jaruskulchai', 'C.', ',', 'et', 'al', '.', '[', '4', ']', 'proposed', 'a', 'method', 'to', 'summarize', 'document', 'by', 'extracting', 'important', 'sentence', 'from', 'combining', 'the', 'specific', 'property', '(', 'Local', 'Property', ')', 'and', 'the', 'overall', 'property', '(', 'Global', 'Property', ')', 'of', 'the', 'sentence', '.', 'The', 'overall', 'property', 'were', 'based', 'on', 'the', 'relationship', 'between', 'sentence', 'in', 'the', 'document', '.', 'From', 'their', 'experiment', ',', 'the', 'summarization', 'of', 'the', 'industrial', 'news', 'got', '60', '%', 'precision', ',', '44', '%', 'recall', ',', 'and', '50.9', '%', 'F-measure', ',', 'the', 'general', 'news', 'got', 'the', '51.8', '%', 'precision', ',', '38.5', '%', 'recall', ',', 'and', '43.1', '%', 'F-measure', 'while', 'the', 'fashion', 'magazine', 'got', '53.0', '%', 'precision', ',', '33.0', '%', 'recall', ',', 'and', '40.4', '%', 'F-measure', '.', 'Mani', ',', 'I.', ',', 'et', 'al', '.', '[', '5', ']', 'proposed', 'technique', 'of', 'text', 'summarization', 'by', 'using', 'word', 'frequency', 'in', 'the', 'document', 'and', 'calculated', 'the', 'weight', 'of', 'word', 'to', 'create', 'a', 'keyword', 'group', '.', 'They', 'then', 'calculated', 'the', 'cosine', 'similarity', 'of', 'sentence', '.', 'The', 'researcher', 'used', 'A', '*', 'search', 'algorithm', 'to', 'find', 'the', 'shortest', 'sequence', 'of', 'sentence', 'from', 'keyword', 'group', 'by', 'topic', 'calculation', ',', 'sentence', 'segmentation', 'and', 'word', 'grouping', '.', 'The', 'sequence', 'of', 'sentence', 'that', 'were', 'in', 'the', 'main', 'group', 'were', 'selected', 'a', 'important', 'sentence', '.', 'Their', 'summarization', 'of', 'the', 'agricultural', 'news', 'got', '68.57', '%', 'precision', ',', '51.95', '%', 'recall', 'and', '56.72', '%', 'F-measure', '.', 'Lee', ',', 'J.', ',', 'et', 'al', '.', '[', '6', ']', 'proposed', 'a', 'document', 'summarization', 'method', 'using', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', '.', 'They', 'compared', 'between', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'and', 'NMF', 'to', 'find', 'the', 'weight', 'of', 'each', 'word', 'and', 'calculated', 'the', 'summation', 'of', 'weight', '.', 'The', 'important', 'sentence', 'were', 'ranked', 'and', 'selected', 'into', 'the', 'summary', 'based', 'on', 'their', 'summed', 'weight', '.', 'Based', 'on', 'LSA', ',', 'they', 'found', 'many', 'weight', 'with', 'zero', 'and', 'negative', 'value', '.', 'However', ',', 'when', 'applied', 'NMF', ',', 'they', 'found', 'only', 'the', 'positive', 'value', 'and', 'the', 'scope', 'of', 'the', 'semantic', 'feature', '’', 'meaning', 'wa', 'narrow', '.', 'Therefore', ',', 'they', 'proposed', 'that', 'NMF', 'provided', 'a', 'greater', 'possibility', 'for', 'extracting', 'important', 'sentence', '.', '3', '.', 'PREPROCESSING', 'FOR', 'THAI', 'TEXT', 'The', 'first', 'step', 'for', 'working', 'with', 'Thai', 'Text', 'is', 'word', 'tokenization', '.', 'Even', 'though', 'Thai', 'writing', 'system', 'ha', 'no', 'delimiters', 'to', 'indicate', 'word', 'boundary', 'together', 'with', 'many', 'rule', 'for', 'word', 'segmentation', ',', 'several', 'Thai', 'word', 'tokenization', 'program', 'have', 'been', 'proposed', '.', 'Table', '1', 'show', 'F1', 'score', 'of', 'the', 'recent', 'program', 'trained', 'and', 'tested', 'by', 'one', 'of', 'our', 'laboratory', 'member', 'with', 'the', 'data', 'from', 'BEST2010', 'corpus', '[', '7', ']', '.', 'Cutkum', '[', '8', ']', 'got', 'the', 'highest', 'F1', 'score', ',', 'hence', ',', 'we', 'used', 'Cutkum', 'for', 'this', 'step', '.', 'Table', '1', '.', 'Comparison', 'of', 'Thai', 'word', 'tokenization', 'program', 'Tools', 'F1', 'Score', 'Validate', 'PyICU', '[', '9', ']', 'Article', '100', '0.6155', 'Encyclopedia', '100', '0.6932', 'News', '100', '0.5987', 'Novel', '100', '0.6800', 'Lexto', '[', '10', ']', '0.7267', '0.7709', '0.6994', '0.7701', 'Cutkum', 'wordcutpy', '[', '11', ']', '0.9322', '0.6212', '0.9299', '0.6286', '0.8987', '0.6571', '0.7140', '0.6247', 'cunlp', '[', '12', ']', '0.6910', '0.6172', '0.5748', '0.0000', 'SWATH', '[', '13', ']', '0.6347', '0.6858', '0.6200', '0.6867', '3.1', 'Latent', 'Semantic', 'Analysis', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', '[', '14', ']', 'is', 'the', 'algorithm', ',', 'which', 'reduces', 'the', 'dimensionality', 'of', 'term', 'document', '.', 'The', 'algorithm', 'creates', 'a', 'matrix', 'by', 'using', 'word', 'frequency', ',', 'applies', 'the', 'singular', 'value', 'decomposition', '(', 'SVD', ')', '[', '15', ']', ',', 'and', 'then', 'find', 'closely', 'related', 'term', 'and', 'document', '.', 'The', 'original', 'matrix', 'A', 'can', 'be', 'separated', 'into', 'three', 'matrix', ',', 'where', 'U', 'is', 'the', 'm', 'x', 'r', '(', 'word', 'x', 'extracted', 'concept', ')', 'matrix', ',', 'V', 'is', 'the', 'n', 'x', 'r', '(', 'sentence', 'x', 'extracted', 'concept', ')', 'matrix', ',', 'and', 'Σ', 'is', 'the', 'r', 'x', 'r', 'diagonal', 'matrix', ',', 'which', 'can', 'be', 'reconstructed', 'to', 'find', 'the', 'original', 'matrix', 'A', '.', 'The', 'SVD', 'can', 'be', 'represented', 'in', 'Eq', '.', '(', '1', ')', '.', '3.2', 'A', '≈', '𝑈𝑈𝑈𝑈𝑉𝑉', '𝑇𝑇', 'of', 'the', 'related', 'singular', 'value', 'over', 'the', 'sum', 'of', 'all', 'singular', 'value', ',', 'for', 'each', 'concept', '.', '3.3', '(', '2', ')', 'A', '=', '𝑊𝑊𝑊𝑊', 'Factors', 'W', 'and', 'H', 'can', 'be', 'found', 'by', 'solving', 'the', 'optimization', 'problem', 'a', 'follows', ',', 'where𝑊𝑊𝑗𝑗𝑗𝑗', '≥', '0', ',', '𝐻𝐻𝑖𝑖𝑖𝑖', '≥', '0.', '𝑚𝑚', '𝑛𝑛', '𝑟𝑟', '𝑗𝑗=1', '𝑖𝑖=1', '𝑙𝑙=1', '2', '𝑚𝑚𝑚𝑚𝑚𝑚', '𝐹𝐹', '(', '𝑊𝑊', ',', '𝐻𝐻', ')', '=', '||', '𝐴𝐴', '−', '𝑊𝑊𝑊𝑊', '||2𝐹𝐹', '=', '�', '�', '�𝐴𝐴𝑖𝑖𝑖𝑖', '−', '�', '𝑊𝑊𝑖𝑖𝑖𝑖', '𝐻𝐻𝑖𝑖𝑖𝑖', '�', '(', '3', ')', 'NMF', 'and', 'LSA', 'are', 'both', 'matrix', 'factorization', 'algorithm', '.', 'However', ',', 'when', 'using', 'NMF', 'to', 'find', 'keywords', ',', 'NMF', 'will', 'return', 'the', 'keywords', 'that', 'are', 'closely', 'related', 'because', 'it', 'component', 'have', 'only', 'nonnegative', 'value', '.', 'As', 'LSA', 'ha', 'both', 'positive', 'and', 'negative', 'value', 'a', 'well', 'a', 'some', 'zero', ',', 'it', 'get', 'a', 'wider', 'distribution', '.', 'The', 'semantic', 'feature', 'represents', 'a', 'concept', 'of', 'meaning', 'for', 'root', 'of', 'word', 'that', 'have', 'a', 'relationship', '.', 'For', 'example', ',', 'man', ',', 'human', ',', 'male', 'and', 'adult', 'have', 'the', 'same', 'semantic', ',', 'hence', 'their', 'semantic', 'value', 'are', 'close', '.', 'In', 'this', 'paper', ',', 'we', 'applied', 'LSA', 'and', 'NMF', 'on', 'the', 'Thai', 'Travel', 'News', 'dataset', 'for', 'calculating', 'the', 'semantic', 'weight', ',', 'which', 'represented', 'the', 'relationship', 'between', 'sentence', 'and', 'word', 'in', 'order', 'to', 'select', 'the', 'representative', 'sentence', 'for', 'summarization', '.', '3.4', 'Generic', 'document', 'summarization', 'by', 'NMF', 'Lee', ',', 'J.', ',', 'et', 'al', '.', 'proposed', 'Eq', '.', '(', '4', ')', 'and', 'Eq', '.', '(', '5', ')', 'to', 'select', 'a', 'number', 'of', 'sentence', 'based', 'on', 'NMF', ',', 'which', 'got', 'the', 'highest', 'semantic', 'weight', 'value', ',', 'where', '𝐻𝐻𝑖𝑖𝑖𝑖', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑖𝑖', 'in', 'the', 'sentence', '𝑗𝑗', '.', 'Generic', 'Relevance', 'of', 'jth', 'sentence', '𝑟𝑟', '(', '1', ')', '=', '�', '𝐻𝐻𝑖𝑖𝑖𝑖', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', 'Document', 'summarization', 'using', 'LSA', 'Gong', ',', 'Y.', 'et', 'al', '.', '[', '16', ']', 'proposed', 'a', 'document', 'summarization', 'based', 'on', 'SVD', 'matrix', '.', 'In', 'our', 'work', ',', 'after', 'applying', 'SVD', 'to', 'matrix', 'A', ',', '𝑉𝑉', '𝑇𝑇', 'matrix', 'used', 'for', 'selecting', 'the', 'important', 'sentence', '.', 'The', 'cell', 'value', 'of', 'the', 'matrix', 'show', 'the', 'relationship', 'between', 'sentence', 'and', 'extracted', 'concept', '.', 'A', 'sentence', 'with', 'the', 'highest', 'cell', 'value', 'of', 'each', 'concept', 'will', 'be', 'selected', 'into', 'the', 'summary', 'starting', 'from', 'the', 'most', 'important', 'concept', '.', 'The', 'total', 'number', 'of', 'sentence', 'in', 'the', 'summary', 'will', 'be', 'equal', 'to', 'the', 'number', 'all', 'detected', 'concept', '.', 'Murray', ',', 'G.', 'et', 'al', '.', '[', '17', ']', 'proposed', 'a', 'document', 'summarization', 'based', 'on', 'SVD', 'matrix', 'using', '𝑉𝑉', '𝑇𝑇', 'and', 'Σ', 'matrix', 'for', 'sentence', 'selection', '.', 'The', 'author', 'proposed', 'that', 'more', 'than', 'one', 'sentence', 'could', 'be', 'collected', 'from', 'the', 'more', 'important', 'concept', '.', 'The', 'decision', 'of', 'how', 'many', 'sentence', 'would', 'be', 'collected', 'from', 'each', 'concept', 'depending', 'on', 'the', 'Σ', 'matrix', '.', 'The', 'value', 'wa', 'decided', 'by', 'getting', 'the', 'percentage', 'Non-negative', 'Matrix', 'Factorization', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'is', 'a', 'method', 'of', 'matrix', 'factorization', 'subject', 'to', 'the', 'non-negative', 'constraint', '.', 'Lee', ',', 'J.', ',', 'et', 'al', '.', 'proposed', 'the', 'model', 'based', 'on', 'NMF', 'for', 'document', 'summarization', '.', 'NMF', 'decomposes', 'a', 'non-negative', 'matrix', '𝐴𝐴', '∈', '𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'into', 'two', 'nonnegative', 'matrix', '.', 'The', 'first', 'matrix', '𝑚𝑚', 'x', '𝑟𝑟', 'is', 'a', 'non-negative', 'semantic', 'feature', 'matrix', '(', 'NSFM', ')', ',', '𝑊𝑊', '.', 'The', 'second', 'matrix', '𝑟𝑟', 'x', '𝑛𝑛', 'is', 'a', 'nonnegative', 'semantic', 'variable', 'matrix', '(', 'NSVM', ')', ',', '𝐻𝐻', '.', 'So', ',', 'we', 'have', '𝑊𝑊', '∈', '𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'and', '𝐻𝐻', '∈', '𝑅𝑅𝑟𝑟𝑟𝑟𝑟𝑟', 'and', 'both', 'term', 'are', 'non-negative', 'a', 'shown', 'in', 'Eq', '.', '(', '2', ')', 'and', 'Eq', '.', '(', '3', ')', '.', '(', '4', ')', '𝑖𝑖=1', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', '=', '∑𝑛𝑛𝑞𝑞=1', '𝐻𝐻𝑖𝑖𝑖𝑖', '𝑟𝑟', '∑𝑝𝑝=1', '∑𝑛𝑛𝑞𝑞=1', '𝐻𝐻𝑝𝑝𝑝𝑝', '(', '5', ')', 'The', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', 'is', 'the', 'relative', 'relevance', 'of', 'the', 'ith', 'semantic', 'feature', '(', '𝑊𝑊𝑖𝑖', ')', ',', 'where', '𝐻𝐻𝑖𝑖𝑖𝑖', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑖𝑖', 'in', 'the', 'sentence', '𝑞𝑞', 'and', '𝐻𝐻𝑝𝑝𝑝𝑝', 'is', 'the', 'weight', 'of', 'the', 'topic', '𝑝𝑝', 'in', 'the', 'sentence', '𝑞𝑞', '.', 'The', 'sentence', 'can', 'be', 'ranked', 'by', 'Generic', 'Relevance', 'Sentence', 'score', '.', 'Sentences', 'with', 'the', 'maximum', 'score', 'will', 'be', 'selected', 'into', 'the', 'summary', '.', '3.5', 'Cosine', 'Similarity', 'Cosine', 'similarity', '[', '18', ']', 'is', 'a', 'widely', 'used', 'method', 'to', 'measure', 'the', 'similarity', 'between', 'vector', 'representing', 'the', 'document', '.', 'The', 'result', 'of', 'cosine', 'similarity', 'is', 'ranging', 'from', '0', 'to', '1', '.', 'If', 'it', 'is', 'closer', 'to', '1', ',', 'that', 'mean', 'both', 'vector', 'are', 'similar', '.', 'Eq', '.', '(', '6', ')', 'and', 'Eq', '.', '(', '7', ')', 'represents', 'the', 'cosine', 'similarity', 'equation', ',', 'where', 'co', '(', 'θ', ')', 'is', 'the', 'dot', 'product', 'between', 'vector', 'of', 'sentence', 'A', 'and', 'B', 'and', 'divided', 'by', 'the', 'product', 'of', 'the', 'two', \"vectors'\", 'length', '.', 'In', 'this', 'paper', ',', 'we', 'deployed', 'cosine', 'similarity', 'to', 'measure', 'the', 'similarity', 'of', 'sentence', 'in', 'K-means', 'clustering', '.', 'A∙B', '||A||', '||B||', '∑ni=1', 'Ai', 'Bi', 'Similarity', '(', 'A', ',', 'B', ')', '=', 'co', '(', 'θ', ')', '=', '(', '7', ')', 'K-means', 'Clustering', '15', '67', '7', '7', '13', '13', '55', '38', 'Table', '2', 'show', 'the', 'overall', 'number', 'of', 'sentence', 'of', 'news', 'within', 'each', 'dataset', '.', 'The', 'average', 'number', 'of', 'sentence', 'per', 'news', 'of', 'the', '5', 'set', 'were', '21', ',', '16', ',', '15', ',', '13', 'and', '13', 'sentence', ',', 'respectively', '.', '5', '.', 'PIPELINE', 'FOR', 'GENERATING', 'SUMMARIES', 'In', 'this', 'section', ',', 'we', 'demonstrate', 'our', 'pipeline', '(', 'Figure', '1', ')', 'used', 'for', 'text', 'summarization', 'to', 'generate', 'a', 'summary', 'for', 'a', 'Thai', 'travel', 'news', '.', 'Word', 'S9', '6', 'Round', '4', 'Round', '5', 'Table', '3', '.', 'Example', 'of', 'Word', 'by', 'Sentence', 'Matrix', 'A', 'S8', 'Round', '3', 'Avg', '.', 'Number', 'of', 'Sentences', 'S7', '21', '16', 'Round', '1', 'Round', '2', 'Min', '.', 'Number', 'of', 'Sentences', 'S6', '7', '7', 'Max', '.', 'Number', 'of', 'Sentences', '58', '58', 'Dataset', 'S5', 'Table', '2', '.', 'Overall', 'Sentence', 'Language', 'of', 'each', 'Dataset', 'S4', 'DATA', 'PREPARATION', 'The', 'standard', 'data', 'set', 'in', 'Thai', 'language', 'are', 'unavailable', 'for', 'evaluating', 'text', 'summarization', 'system', '.', 'Therefore', ',', 'we', 'collected', '400', 'Thai', 'travel', 'news', 'from', 'Thairath', 'and', 'Manager', 'online', 'newspaper', 'to', 'be', 'used', 'a', 'datasets', 'for', 'our', 'experiment', '.', 'We', 'split', '400', 'travel', 'news', 'into', '5', 'set', 'of', '80', 'news', 'each', '.', 'We', 'then', 'evaluated', 'the', 'performance', 'of', 'text', 'summarization', 'method', 'which', 'were', 'LSA', 'and', 'NMF', 'by', 'comparing', 'their', 'result', 'with', 'the', 'summary', 'manually', 'curated', 'by', 'two', 'expert', 'from', 'the', 'Faculty', 'of', 'Liberal', 'Arts', ',', 'Ubon', 'Ratchathani', 'University', '.', 'The', 'open-source', 'python', 'library', 'such', 'a', 'numpy', '[', '19', ']', 'and', 'sklearn', '[', '20', ']', 'were', 'used', 'in', 'our', 'system', '.', 'We', 'converted', 'the', 'Thai', 'travel', 'news', 'obtained', 'from', 'Thairath', 'and', 'Manager', 'online', 'newspaper', 'to', 'plain', 'text', '.', 'Then', ',', 'the', 'sentence', 'of', 'each', 'news', 'were', 'segmented', 'by', 'human', 'with', 'the', 'following', 'format', ':', 'Si', '=', '‘', 'xxx', '’', ',', 'where', 'Si', 'represents', 'the', 'order', 'of', 'the', 'sentence', 'in', 'the', 'original', 'document', 'and', '‘', 'xxx', '’', 'represents', 'the', 'content', 'of', 'that', 'sentence', '.', 'After', 'removing', 'stop', 'word', 'and', 'duplicate', 'word', ',', 'we', 'built', 'a', 'document', 'term', 'matrix', 'or', 'matrix', 'A', 'then', 'applied', 'SVD', 'and', 'NMF', 'to', 'the', 'matrix', '.', 'Then', ',', 'we', 'used', 'python', 'module', 'numpy.linalg.svd', 'to', 'calculate', 'SVD', 'and', 'sklearn.decomposition', 'to', 'calculate', 'NMF', '.', 'For', 'sentence', 'selection', ',', 'we', 'used', 'Gong', ',', 'Y.', 'et', 'al', '.', 'and', 'Murray', ',', 'G.', 'et', 'al', '.', 'approach', 'for', 'calculating', 'weight', 'of', 'the', 'sentence', 'score', 'then', 'selected', 'sentence', 'with', 'the', 'highest', 'score', 'into', 'the', 'summary', '.', 'For', 'keyword', 'score', 'calculation', 'of', 'NMF', ',', 'we', 'calculated', 'the', 'keyword', 'score', 'from', 'Eq', '.', '(', '5', ')', 'and', 'then', 'selected', 'the', 'sentence', 'with', 'the', 'highest', 'score', 'from', 'each', 'concept', '.', 'The', 'python', 'module', 'sklearn.cluster', 'wa', 'used', 'for', 'K-means', 'clustering', '.', 'The', 'selected', 'sentence', 'from', 'all', 'approach', 'were', 'in', 'the', 'same', 'order', 'a', 'the', 'original', 'document', '.', 'In', 'this', 'paper', ',', 'we', 'performed', 'the', '20', '%', ',', '30', '%', 'and', '40', '%', 'document', 'compression', '.', 'This', 'meant', '80', '%', ',', '70', '%', 'and', '60', '%', 'of', 'the', 'sentence', 'will', 'be', 'selected', 'into', 'the', 'summary', '.', 'S3', '4', '.', 'Figure', '1', '.', 'Document', 'summarization', 'pipeline', 'based', 'on', 'LSA', 'and', 'NMF', 'S2', 'For', 'sentence', 'selection', 'by', 'K-means', 'clustering', ',', 'we', 'grouped', 'similar', 'sentence', 'into', 'the', 'same', 'cluster', 'using', 'the', 'following', 'step', ':', '1', '.', 'Randomly', 'select', 'K', 'sentence', 'a', 'the', 'representative', 'of', 'K', 'group', '.', 'K', 'in', 'this', 'paper', 'is', 'the', 'number', 'of', 'sentence', 'that', 'will', 'be', 'selected', 'into', 'the', 'summary', '.', '2', '.', 'Calculate', 'centroid', 'of', 'each', 'group', 'by', 'using', 'the', 'value', 'of', 'sentence', 'vector', 'from', 'V', 'matrix', 'for', 'LSA', 'and', '𝐻𝐻𝑇𝑇', 'matrix', 'for', 'NMF', '.', '3', '.', 'Use', 'cosine', 'similarity', 'to', 'calculate', 'sentence', 'similarity', 'between', 'a', 'sentence', 'and', 'the', 'centroid', 'of', 'each', 'group', '.', 'Then', 'assign', 'that', 'sentence', 'to', 'the', 'group', 'with', 'the', 'highest', 'similarity', '.', '4', '.', 'Repeat', 'step', '2-3', 'until', 'all', 'sentence', 'are', 'assigned', 'to', 'a', 'group', ',', 'no', 'sentence', 'change', 'the', 'group', ',', 'or', 'the', 'similarity', 'between', 'sentence', 'and', 'their', 'centroid', 'is', 'close', '.', '5', '.', 'Select', 'a', 'sentence', 'with', 'the', 'maximum', 'similarity', 'score', 'with', 'the', 'centroid', 'of', 'the', 'group', 'and', 'add', 'it', 'into', 'the', 'summary', '.', 'S1', '3.6', 'A∙B', '=', 'n', 'n', '||A||', '||B||', '�∑i=1', 'A2i', '�∑i=1', 'Bi2', '(', '6', ')', 'Mr.Yontas', 'ak', '1', '0', '0', '0', '0', '0', '0', '0', '0', 'Supason', '1', '0', '0', '0', '0', '0', '0', '0', '0', 'Tourism', 'Authority', 'of', 'Thailand', '1', '0', '0', '0', '0', '0', '0', '0', '0', '…', '…', '…', '…', '…', '…', '…', '…', '…', '…', 'Table', '3', 'demonstrates', 'an', 'example', 'of', 'a', 'matrix', '𝐴𝐴', ',', 'constructed', 'from', 'word', 'count', 'by', 'sentence', 'of', 'a', 'Thai', 'travel', 'news', '.', 'It', 'wa', 'composed', 'of', '98', 'word', 'and', '9', 'sentence', '.', 'This', 'matrix', '𝐴𝐴', 'wa', 'then', 'applied', 'with', 'the', 'LSA', 'and', 'NMF', '.', 'The', 'sentence', 'vector', 'were', 'calculated', 'from', 'the', 'term', 'weight', 'and', 'the', 'semantic', 'feature', 'vector', 'from', 'Eq', '.', '(', '1', ')', 'for', 'LSA', 'and', 'Eq', '.', '(', '2', ')', 'for', 'NMF', '.', 'sentence', 'from', 'all', 'concept', '.', 'The', 'Generic', 'Sentence', 'Relevance', 'score', 'for', 'NMF', 'also', 'collected', 'one', 'sentence', 'for', 'each', 'concept', ',', 'the', 'same', 'a', 'Gong', ',', 'Y.', 'et', 'al', '.', 'but', 'with', 'the', 'highest', 'score', 'calculated', 'by', 'Eq', '.', '(', '5', ')', '.', 'As', 'multiple', 'important', 'sentence', 'could', 'be', 'selected', 'from', 'a', 'more', 'important', 'concept', ',', 'Murray', ',', 'G.', 'et', 'al', '.', 'outperformed', 'both', 'Gong', ',', 'Y.', 'et', 'al', '.', 'and', 'the', 'GRS', 'method', '.', '6', '.', 'EXPERIMENT', 'AND', 'RESULTS', '6.1', 'Performance', 'Evaluations', 'Measure', '7', '.', 'We', 'evaluated', 'the', 'result', 'of', 'the', 'summarization', 'by', 'using', 'standard', 'accuracy', ',', 'precision', ',', 'recall', ',', 'and', 'F1', 'score', '[', '21', ']', '.', 'These', 'measurement', 'quantify', 'the', 'difference', 'between', 'the', 'summary', 'from', 'human', 'and', 'the', 'experimental', 'method', '.', 'The', 'precision', 'show', 'the', 'correctness', 'of', 'the', 'extracted', 'sentence', 'and', 'the', 'recall', 'reflects', 'the', 'number', 'of', 'good', 'sentence', 'missed', 'by', 'the', 'method', '.', '6', '.', '2', 'Experiment', 'Results', 'In', 'this', 'experimental', 'set', ',', 'we', 'would', 'like', 'to', 'explore', 'how', 'the', 'different', 'sentence', 'selection', 'method', ':', 'the', 'Generic', 'Sentence', 'Relevance', 'score', 'and', 'K-means', 'clustering', ',', 'affected', 'the', 'text', 'summarization', 'result', '.', 'For', 'K-means', 'clustering', ',', 'both', 'SVD', 'and', 'NMF', 'had', 'similar', 'summarization', 'efficiency', '.', 'The', 'F1', 'score', 'of', 'SVD', 'with', 'K-means', 'clustering', 'wa', '0.83', ',', '0.72', ',', 'and', '0.62', 'for', 'the', 'compression', 'rate', 'of', '20', '%', ',', '30', '%', ',', 'and', '40', '%', '.', 'For', 'the', 'NMF', 'with', 'K-means', 'clustering', ',', 'the', 'F1', 'score', 'for', 'the', 'three', 'compression', 'rate', 'wa', '0.83', ',', '0.74', 'and', '0.64', '.', 'For', 'the', 'Generic', 'Sentence', 'Relevance', 'score', ',', 'the', 'best', 'F1', 'score', 'for', 'the', 'compression', 'rate', 'of', '20', '%', ',', '30', '%', ',', 'and', '40', '%', 'wa', '0.86', ',', '0.78', 'and', '0.68', 'respectively', 'and', 'the', 'best', 'F1', 'score', 'for', 'all', 'compression', 'rate', 'were', 'from', 'the', 'approach', 'of', 'Murray', ',', 'G.', 'et', 'al', '.', 'Figure', '2', '.', 'Thai', 'text', 'summarization', 'efficiency', 'of', '5', 'model', 'Figure', '2', 'show', 'the', 'Thai', 'text', 'summarization', 'efficiency', 'of', '5', 'model', ':', '(', '1', ')', 'NMF', 'with', 'GRS', ',', '(', '2', ')', 'NMF', 'with', 'K-means', ',', '(', '3', ')', 'SVD', 'with', 'sentence', 'score', 'by', 'Gong', ',', 'Y.', 'et', 'al.', ',', '(', '4', ')', 'SVD', 'with', 'K-means', ',', 'and', '(', '5', ')', 'SVD', 'with', 'sentence', 'score', 'by', 'Murray', ',', 'G.', 'et', 'al', '.', 'applied', 'to', '400', 'Thai', 'travel', 'news', ',', 'divided', 'into', '5', 'set', 'of', '80', 'news', 'each', ',', 'with', 'the', 'varied', 'compression', 'rate', 'of', '20', '%', ',', '30', '%', 'and', '40', '%', '.', 'From', 'this', 'experiment', ',', 'the', 'best', 'model', 'based', 'on', 'keyword', 'score', 'for', 'Thai', 'travel', 'news', 'summarization', 'wa', 'SVD', 'with', 'sentence', 'selection', 'by', 'Murray', ',', 'G.', 'et', 'al', '.', 'This', 'model', 'with', 'the', 'compression', 'rate', 'of', '20', '%', 'got', 'the', 'highest', 'score', 'because', 'Murray', 'G.', 'et', 'al', '.', 'method', 'determined', 'the', 'number', 'of', 'sentence', 'to', 'be', 'extracted', 'from', 'each', 'concept', 'based', 'on', 'the', 'importance', 'of', 'that', 'concept', '.', 'The', 'method', 'of', 'Gong', ',', 'Y.', 'et', 'al.', ',', 'on', 'the', 'other', 'hand', 'wa', 'proposed', 'to', 'select', 'only', 'one', 'sentence', 'with', 'the', 'highest', 'score', 'from', 'each', 'concept', 'so', 'that', 'the', 'summary', 'would', 'include', 'CONCLUSIONS', 'In', 'this', 'paper', ',', 'we', 'applied', 'several', 'text', 'summarization', 'method', 'to', 'Thai', 'Travel', 'News', 'based', 'on', 'keyword', 'scored', 'in', 'Thai', 'language', 'by', 'extracting', 'the', 'most', 'relevant', 'sentence', 'from', 'the', 'original', 'document', '.', 'We', 'compared', 'LSA', 'and', 'NMF', 'together', 'with', 'different', 'sentence', 'selection', 'method', ',', 'to', 'find', 'the', 'algorithm', 'suitable', 'with', 'this', \"paper's\", 'data', 'source', '.', 'We', 'concluded', 'that', 'keyword', 'scored', 'calculation', 'by', 'LSA', 'with', 'sentence', 'selection', 'by', 'Generic', 'Sentence', 'Relevance', 'score', 'by', 'Murray', ',', 'G.', 'et', 'al', '.', 'wa', 'the', 'best', 'algorithm', 'while', 'the', 'best', 'compression', 'rate', 'of', 'all', 'model', 'wa', '20', '%', ',', 'for', 'summarizing', 'Thai', 'Travel', 'News', 'compared', 'with', 'human', '.', 'In', 'future', 'work', ',', 'we', 'plan', 'to', 'perform', 'the', 'experiment', 'with', 'different', 'type', 'of', 'document', 'and', 'improve', 'word', 'segmentation', 'of', 'compound', 'noun', 'that', 'wa', 'not', 'handled', 'by', 'Cutkum', '.', '8', '.', 'ACKNOWLEDGMENTS', 'We', 'would', 'like', 'to', 'thank', 'the', 'department', 'of', 'computer', 'engineering', ',', 'faculty', 'of', 'engineering', ',', 'Chulalongkorn', 'University', 'for', 'providing', 'computing', 'facility', '.']\n",
            "After removing stopwords: ['Extractive', 'Text', 'Summarization', 'Thai', 'Travel', 'News', 'Based', 'Keyword', 'Scored', 'Thai', 'Language', 'Sarunya', 'Nathonghor', 'Duangdao', 'Wichadakul', 'Department', 'Computer', 'Engineering', 'Chulalongkorn', 'University', 'Bangkok', ',', 'Thailand', 'Department', 'Computer', 'Engineering', 'Chulalongkorn', 'University', 'Bangkok', ',', 'Thailand', 'Sarunya.N', '@', 'Student.Chula.ac.th', 'ABSTRACT', 'recent', 'years', ',', 'people', 'seeking', 'solution', 'improve', 'text', 'summarization', 'Thai', 'language', '.', 'Although', 'several', 'solutions', 'PageRank', ',', 'Graph', 'Rank', ',', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'models', ',', 'etc.', ',', 'proposed', ',', 'research', 'results', 'Thai', 'text', 'summarization', 'restricted', 'due', 'limited', 'corpus', 'Thai', 'language', 'complex', 'grammar', '.', 'paper', 'applied', 'text', 'summarization', 'system', 'Thai', 'travel', 'news', 'based', 'keyword', 'scored', 'Thai', 'language', 'extracting', 'relevant', 'sentences', 'original', 'document', '.', 'compared', 'LSA', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'find', 'algorithm', 'suitable', 'Thai', 'travel', 'news', '.', 'suitable', 'compression', 'rates', 'Generic', 'Sentence', 'Relevance', 'score', '(', 'GRS', ')', 'K-means', 'clustering', 'also', 'evaluated', '.', 'experiments', ',', 'concluded', 'keyword', 'scored', 'calculation', 'LSA', 'sentence', 'selection', 'GRS', 'best', 'algorithm', 'summarizing', 'Thai', 'Travel', 'News', ',', 'compared', 'human', 'best', 'compression', 'rate', '20', '%', '.', 'CCS', 'Concepts', '•', 'Information', 'systems', '➝', 'Information', 'retrieval', '➝', 'Retrieval', 'tasks', 'goals➝', 'Summarization', 'Keywords', 'Text', 'summarization', ';', 'extractive', 'summarization', ';', 'non-negative', 'matrix', 'factorization', '1', '.', 'INTRODUCTION', 'Daily', 'newspaper', 'abundant', 'data', 'users', 'enough', 'time', 'reading', '.', 'difficult', 'identify', 'relevant', 'information', 'satisfy', 'information', 'needed', 'users', '.', 'Automatic', 'summarization', 'reduce', 'problem', 'information', 'overloading', 'proposed', 'previously', 'English', 'languages', '.', 'However', ',', 'research', 'results', 'Thai', 'text', 'summarization', 'due', 'lack', 'corpus', 'Thai', 'language', 'complicated', 'grammar', '.', 'Text', 'Summarization', '[', '1', ']', 'technique', 'summarizing', 'content', 'documents', '.', 'consists', 'three', 'steps', ':', '1', ')', 'create', 'intermediate', 'representation', 'input', 'text', ',', '2', ')', 'calculate', 'score', 'sentences', 'based', 'concepts', ',', '3', ')', 'choose', 'important', 'Permission', 'make', 'digital', 'hard', 'copies', 'part', 'work', 'personal', 'classroom', 'use', 'granted', 'without', 'fee', 'provided', 'copies', 'made', 'distributed', 'profit', 'commercial', 'advantage', 'copies', 'bear', 'notice', 'full', 'citation', 'first', 'page', '.', 'Copyrights', 'components', 'work', 'owned', 'others', 'ACM', 'must', 'honored', '.', 'Abstracting', 'credit', 'permitted', '.', 'copy', 'otherwise', ',', 'republish', ',', 'post', 'servers', 'redistribute', 'lists', ',', 'requires', 'prior', 'specific', 'permission', 'and/or', 'fee', '.', 'Request', 'permissions', 'Permissions', '@', 'acm.org', '.', 'ITCC', '2020', ',', 'August', '12–14', ',', '2020', ',', 'Kuala', 'Lumpur', ',', 'Malaysia', '©', '2020', 'Association', 'Computing', 'Machinery', '.', 'ACM', 'ISBN', '978-1-4503-7539-9/20/08…', '$', '15.00', 'DOI', ':', 'https', ':', '//doi.org/10.1145/3417473.3417479', 'Duangdao.W', '@', 'Chula.ac.th', 'sentences', 'included', 'summary', '.', 'Text', 'summarization', 'divided', '2', 'approaches', '.', 'first', 'approach', 'extractive', 'summarization', ',', 'relies', 'method', 'extracting', 'words', 'searching', 'keywords', 'original', 'document', '.', 'second', 'approach', 'abstractive', 'summarization', ',', 'analyzes', 'words', 'linguistic', 'principles', 'transcription', 'interpretation', 'original', 'document', '.', 'approach', 'implies', 'effective', 'accurate', 'summary', 'extractive', 'methods', '.', 'However', ',', 'lack', 'Thai', 'corpus', ',', 'chose', 'apply', 'extractive', 'summarization', 'method', 'Thai', 'text', 'summarization', '.', 'research', 'focused', 'sentence', 'extraction', 'function', 'based', 'keyword', 'score', 'calculation', 'selecting', 'important', 'sentences', 'based', 'Generic', 'Sentence', 'Relevance', 'score', '(', 'GRS', ')', ',', 'calculated', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', '.', 'also', 'tried', 'using', 'K-means', 'clustering', 'document', 'summarization', '.', 'experiment', ',', 'compared', '5', 'models', '5', 'rounds', 'Thai', 'travel', 'news', 'using', 'compression', 'rates', '20', '%', ',', '30', '%', '40', '%', 'reported', 'rate', 'method', 'produced', 'best', 'result', 'experiment', '.', '2', '.', 'RELATED', 'WORKS', 'recent', 'years', ',', 'several', 'models', 'Thai', 'Text', 'summarization', 'introduced', '.', 'Suwanno', ',', 'N.', 'et', 'al', '.', '[', '2', ']', 'proposed', 'Thai', 'text', 'summarization', 'extracted', 'paragraph', 'document', 'based', 'Thai', 'compound', 'nouns', ',', 'term', 'frequency', 'method', ',', 'headline', 'score', 'generating', 'summary', '.', 'Chongsuntornsri', ',', 'A.', ',', 'et', 'al', '.', '[', '3', ']', 'proposed', 'new', 'approach', 'Text', 'summarization', 'Thai', 'based', 'content-', 'graph-based', 'use', 'Topic', 'Sensitive', 'PageRank', 'algorithm', 'summarizing', 'ranking', 'text', 'segments', '.', 'Jaruskulchai', 'C.', ',', 'et', 'al', '.', '[', '4', ']', 'proposed', 'method', 'summarize', 'documents', 'extracting', 'important', 'sentences', 'combining', 'specific', 'properties', '(', 'Local', 'Property', ')', 'overall', 'properties', '(', 'Global', 'Property', ')', 'sentences', '.', 'overall', 'properties', 'based', 'relationship', 'sentences', 'document', '.', 'experiments', ',', 'summarization', 'industrial', 'news', 'got', '60', '%', 'precision', ',', '44', '%', 'recall', ',', '50.9', '%', 'F-measure', ',', 'general', 'news', 'got', '51.8', '%', 'precision', ',', '38.5', '%', 'recall', ',', '43.1', '%', 'F-measure', 'fashion', 'magazines', 'got', '53.0', '%', 'precision', ',', '33.0', '%', 'recall', ',', '40.4', '%', 'F-measure', '.', 'Mani', ',', 'I.', ',', 'et', 'al', '.', '[', '5', ']', 'proposed', 'techniques', 'text', 'summarization', 'using', 'word', 'frequency', 'document', 'calculated', 'weight', 'word', 'create', 'keyword', 'group', '.', 'calculated', 'cosine', 'similarity', 'sentences', '.', 'researcher', 'used', '*', 'search', 'algorithm', 'find', 'shortest', 'sequence', 'sentences', 'keyword', 'group', 'topic', 'calculation', ',', 'sentence', 'segmentation', 'word', 'grouping', '.', 'sequence', 'sentences', 'main', 'group', 'selected', 'important', 'sentences', '.', 'summarization', 'agricultural', 'news', 'got', '68.57', '%', 'precision', ',', '51.95', '%', 'recall', '56.72', '%', 'F-measure', '.', 'Lee', ',', 'J.', ',', 'et', 'al', '.', '[', '6', ']', 'proposed', 'document', 'summarization', 'method', 'using', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', '.', 'compared', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'NMF', 'find', 'weight', 'word', 'calculated', 'summation', 'weights', '.', 'important', 'sentences', 'ranked', 'selected', 'summary', 'based', 'summed', 'weight', '.', 'Based', 'LSA', ',', 'found', 'many', 'weights', 'zero', 'negative', 'values', '.', 'However', ',', 'applied', 'NMF', ',', 'found', 'positive', 'values', 'scope', 'semantic', 'features', '’', 'meaning', 'narrow', '.', 'Therefore', ',', 'proposed', 'NMF', 'provided', 'greater', 'possibility', 'extracting', 'important', 'sentences', '.', '3', '.', 'PREPROCESSING', 'THAI', 'TEXT', 'first', 'step', 'working', 'Thai', 'Text', 'word', 'tokenization', '.', 'Even', 'though', 'Thai', 'writing', 'system', 'delimiters', 'indicate', 'word', 'boundaries', 'together', 'many', 'rules', 'word', 'segmentation', ',', 'several', 'Thai', 'word', 'tokenization', 'programs', 'proposed', '.', 'Table', '1', 'shows', 'F1', 'score', 'recent', 'programs', 'trained', 'tested', 'one', 'laboratory', 'members', 'data', 'BEST2010', 'corpus', '[', '7', ']', '.', 'Cutkum', '[', '8', ']', 'got', 'highest', 'F1', 'score', ',', 'hence', ',', 'used', 'Cutkum', 'step', '.', 'Table', '1', '.', 'Comparison', 'Thai', 'word', 'tokenization', 'programs', 'Tools', 'F1', 'Score', 'Validate', 'PyICU', '[', '9', ']', 'Article', '100', '0.6155', 'Encyclopedia', '100', '0.6932', 'News', '100', '0.5987', 'Novel', '100', '0.6800', 'Lexto', '[', '10', ']', '0.7267', '0.7709', '0.6994', '0.7701', 'Cutkum', 'wordcutpy', '[', '11', ']', '0.9322', '0.6212', '0.9299', '0.6286', '0.8987', '0.6571', '0.7140', '0.6247', 'cunlp', '[', '12', ']', '0.6910', '0.6172', '0.5748', '0.0000', 'SWATH', '[', '13', ']', '0.6347', '0.6858', '0.6200', '0.6867', '3.1', 'Latent', 'Semantic', 'Analysis', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', '[', '14', ']', 'algorithm', ',', 'reduces', 'dimensionality', 'term', 'document', '.', 'algorithm', 'creates', 'matrix', 'using', 'word', 'frequency', ',', 'applies', 'singular', 'value', 'decomposition', '(', 'SVD', ')', '[', '15', ']', ',', 'finds', 'closely', 'related', 'terms', 'documents', '.', 'original', 'matrix', 'separated', 'three', 'matrices', ',', 'U', 'x', 'r', '(', 'words', 'x', 'extracted', 'concept', ')', 'matrix', ',', 'V', 'n', 'x', 'r', '(', 'sentences', 'x', 'extracted', 'concepts', ')', 'matrix', ',', 'Σ', 'r', 'x', 'r', 'diagonal', 'matrix', ',', 'reconstructed', 'find', 'original', 'matrix', '.', 'SVD', 'represented', 'Eq', '.', '(', '1', ')', '.', '3.2', '≈', '𝑈𝑈𝑈𝑈𝑉𝑉', '𝑇𝑇', 'related', 'singular', 'value', 'sum', 'singular', 'values', ',', 'concept', '.', '3.3', '(', '2', ')', '=', '𝑊𝑊𝑊𝑊', 'Factors', 'W', 'H', 'found', 'solving', 'optimization', 'problem', 'follows', ',', 'where𝑊𝑊𝑗𝑗𝑗𝑗', '≥', '0', ',', '𝐻𝐻𝑖𝑖𝑖𝑖', '≥', '0.', '𝑚𝑚', '𝑛𝑛', '𝑟𝑟', '𝑗𝑗=1', '𝑖𝑖=1', '𝑙𝑙=1', '2', '𝑚𝑚𝑚𝑚𝑚𝑚', '𝐹𝐹', '(', '𝑊𝑊', ',', '𝐻𝐻', ')', '=', '||', '𝐴𝐴', '−', '𝑊𝑊𝑊𝑊', '||2𝐹𝐹', '=', '�', '�', '�𝐴𝐴𝑖𝑖𝑖𝑖', '−', '�', '𝑊𝑊𝑖𝑖𝑖𝑖', '𝐻𝐻𝑖𝑖𝑖𝑖', '�', '(', '3', ')', 'NMF', 'LSA', 'matrix', 'factorization', 'algorithms', '.', 'However', ',', 'using', 'NMF', 'find', 'keywords', ',', 'NMF', 'return', 'keywords', 'closely', 'related', 'components', 'nonnegative', 'values', '.', 'LSA', 'positive', 'negative', 'values', 'well', 'zeroes', ',', 'gets', 'wider', 'distribution', '.', 'semantic', 'feature', 'represents', 'concept', 'meaning', 'root', 'words', 'relationship', '.', 'example', ',', 'man', ',', 'human', ',', 'male', 'adult', 'semantic', ',', 'hence', 'semantic', 'values', 'close', '.', 'paper', ',', 'applied', 'LSA', 'NMF', 'Thai', 'Travel', 'News', 'dataset', 'calculating', 'semantic', 'weights', ',', 'represented', 'relationship', 'sentences', 'words', 'order', 'select', 'representative', 'sentences', 'summarization', '.', '3.4', 'Generic', 'document', 'summarization', 'NMF', 'Lee', ',', 'J.', ',', 'et', 'al', '.', 'proposed', 'Eq', '.', '(', '4', ')', 'Eq', '.', '(', '5', ')', 'select', 'number', 'sentences', 'based', 'NMF', ',', 'got', 'highest', 'semantic', 'weight', 'values', ',', '𝐻𝐻𝑖𝑖𝑖𝑖', 'weight', 'topic', '𝑖𝑖', 'sentence', '𝑗𝑗', '.', 'Generic', 'Relevance', 'jth', 'sentence', '𝑟𝑟', '(', '1', ')', '=', '�', '𝐻𝐻𝑖𝑖𝑖𝑖', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', 'Document', 'summarization', 'using', 'LSA', 'Gong', ',', 'Y.', 'et', 'al', '.', '[', '16', ']', 'proposed', 'document', 'summarization', 'based', 'SVD', 'matrices', '.', 'work', ',', 'applying', 'SVD', 'matrix', ',', '𝑉𝑉', '𝑇𝑇', 'matrix', 'used', 'selecting', 'important', 'sentences', '.', 'cell', 'value', 'matrix', 'shows', 'relationship', 'sentence', 'extracted', 'concepts', '.', 'sentence', 'highest', 'cell', 'value', 'concept', 'selected', 'summary', 'starting', 'important', 'concept', '.', 'total', 'number', 'sentences', 'summary', 'equal', 'number', 'detected', 'concepts', '.', 'Murray', ',', 'G.', 'et', 'al', '.', '[', '17', ']', 'proposed', 'document', 'summarization', 'based', 'SVD', 'matrices', 'using', '𝑉𝑉', '𝑇𝑇', 'Σ', 'matrices', 'sentence', 'selection', '.', 'authors', 'proposed', 'one', 'sentence', 'could', 'collected', 'important', 'concepts', '.', 'decision', 'many', 'sentences', 'would', 'collected', 'concept', 'depending', 'Σ', 'matrix', '.', 'value', 'decided', 'getting', 'percentage', 'Non-negative', 'Matrix', 'Factorization', 'Non-negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'method', 'matrix', 'factorization', 'subject', 'non-negative', 'constraint', '.', 'Lee', ',', 'J.', ',', 'et', 'al', '.', 'proposed', 'model', 'based', 'NMF', 'document', 'summarization', '.', 'NMF', 'decomposes', 'non-negative', 'matrix', '𝐴𝐴', '∈', '𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'two', 'nonnegative', 'matrices', '.', 'first', 'matrix', '𝑚𝑚', 'x', '𝑟𝑟', 'non-negative', 'semantic', 'feature', 'matrix', '(', 'NSFM', ')', ',', '𝑊𝑊', '.', 'second', 'matrix', '𝑟𝑟', 'x', '𝑛𝑛', 'nonnegative', 'semantic', 'variable', 'matrix', '(', 'NSVM', ')', ',', '𝐻𝐻', '.', ',', '𝑊𝑊', '∈', '𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', '𝐻𝐻', '∈', '𝑅𝑅𝑟𝑟𝑟𝑟𝑟𝑟', 'terms', 'non-negative', 'shown', 'Eq', '.', '(', '2', ')', 'Eq', '.', '(', '3', ')', '.', '(', '4', ')', '𝑖𝑖=1', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', '=', '∑𝑛𝑛𝑞𝑞=1', '𝐻𝐻𝑖𝑖𝑖𝑖', '𝑟𝑟', '∑𝑝𝑝=1', '∑𝑛𝑛𝑞𝑞=1', '𝐻𝐻𝑝𝑝𝑝𝑝', '(', '5', ')', '𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', '(', '𝐻𝐻𝑖𝑖', ')', 'relative', 'relevance', 'ith', 'semantic', 'feature', '(', '𝑊𝑊𝑖𝑖', ')', ',', '𝐻𝐻𝑖𝑖𝑖𝑖', 'weight', 'topic', '𝑖𝑖', 'sentence', '𝑞𝑞', '𝐻𝐻𝑝𝑝𝑝𝑝', 'weight', 'topic', '𝑝𝑝', 'sentence', '𝑞𝑞', '.', 'sentences', 'ranked', 'Generic', 'Relevance', 'Sentence', 'scores', '.', 'Sentences', 'maximum', 'score', 'selected', 'summary', '.', '3.5', 'Cosine', 'Similarity', 'Cosine', 'similarity', '[', '18', ']', 'widely', 'used', 'method', 'measure', 'similarity', 'vectors', 'representing', 'documents', '.', 'result', 'cosine', 'similarity', 'ranging', '0', '1', '.', 'closer', '1', ',', 'means', 'vectors', 'similar', '.', 'Eq', '.', '(', '6', ')', 'Eq', '.', '(', '7', ')', 'represents', 'cosine', 'similarity', 'equation', ',', 'cos', '(', 'θ', ')', 'dot', 'product', 'vectors', 'sentences', 'B', 'divided', 'product', 'two', \"vectors'\", 'lengths', '.', 'paper', ',', 'deployed', 'cosine', 'similarity', 'measure', 'similarity', 'sentences', 'K-means', 'clustering', '.', 'A∙B', '||A||', '||B||', '∑ni=1', 'Ai', 'Bi', 'Similarity', '(', ',', 'B', ')', '=', 'cos', '(', 'θ', ')', '=', '(', '7', ')', 'K-means', 'Clustering', '15', '67', '7', '7', '13', '13', '55', '38', 'Table', '2', 'shows', 'overall', 'number', 'sentences', 'news', 'within', 'dataset', '.', 'average', 'numbers', 'sentences', 'per', 'news', '5', 'sets', '21', ',', '16', ',', '15', ',', '13', '13', 'sentences', ',', 'respectively', '.', '5', '.', 'PIPELINE', 'GENERATING', 'SUMMARIES', 'section', ',', 'demonstrate', 'pipeline', '(', 'Figure', '1', ')', 'used', 'text', 'summarization', 'generate', 'summary', 'Thai', 'travel', 'news', '.', 'Word', 'S9', '6', 'Round', '4', 'Round', '5', 'Table', '3', '.', 'Example', 'Word', 'Sentence', 'Matrix', 'S8', 'Round', '3', 'Avg', '.', 'Number', 'Sentences', 'S7', '21', '16', 'Round', '1', 'Round', '2', 'Min', '.', 'Number', 'Sentences', 'S6', '7', '7', 'Max', '.', 'Number', 'Sentences', '58', '58', 'Dataset', 'S5', 'Table', '2', '.', 'Overall', 'Sentence', 'Language', 'Dataset', 'S4', 'DATA', 'PREPARATION', 'standard', 'data', 'sets', 'Thai', 'language', 'unavailable', 'evaluating', 'text', 'summarization', 'system', '.', 'Therefore', ',', 'collected', '400', 'Thai', 'travel', 'news', 'Thairath', 'Manager', 'online', 'newspapers', 'used', 'datasets', 'experiments', '.', 'split', '400', 'travel', 'news', '5', 'sets', '80', 'news', '.', 'evaluated', 'performance', 'text', 'summarization', 'methods', 'LSA', 'NMF', 'comparing', 'results', 'summaries', 'manually', 'curated', 'two', 'experts', 'Faculty', 'Liberal', 'Arts', ',', 'Ubon', 'Ratchathani', 'University', '.', 'open-source', 'python', 'libraries', 'numpy', '[', '19', ']', 'sklearn', '[', '20', ']', 'used', 'system', '.', 'converted', 'Thai', 'travel', 'news', 'obtained', 'Thairath', 'Manager', 'online', 'newspapers', 'plain', 'text', '.', ',', 'sentences', 'news', 'segmented', 'human', 'following', 'format', ':', 'Si', '=', '‘', 'xxx', '’', ',', 'Si', 'represents', 'order', 'sentence', 'original', 'document', '‘', 'xxx', '’', 'represents', 'content', 'sentence', '.', 'removing', 'stop', 'words', 'duplicate', 'words', ',', 'built', 'document', 'term', 'matrix', 'matrix', 'applied', 'SVD', 'NMF', 'matrix', '.', ',', 'used', 'python', 'modules', 'numpy.linalg.svd', 'calculate', 'SVD', 'sklearn.decomposition', 'calculate', 'NMF', '.', 'sentence', 'selection', ',', 'used', 'Gong', ',', 'Y.', 'et', 'al', '.', 'Murray', ',', 'G.', 'et', 'al', '.', 'approaches', 'calculating', 'weight', 'sentence', 'scores', 'selected', 'sentences', 'highest', 'scores', 'summary', '.', 'keyword', 'score', 'calculation', 'NMF', ',', 'calculated', 'keyword', 'score', 'Eq', '.', '(', '5', ')', 'selected', 'sentence', 'highest', 'score', 'concept', '.', 'python', 'module', 'sklearn.cluster', 'used', 'K-means', 'clustering', '.', 'selected', 'sentences', 'approaches', 'order', 'original', 'document', '.', 'paper', ',', 'performed', '20', '%', ',', '30', '%', '40', '%', 'document', 'compression', '.', 'meant', '80', '%', ',', '70', '%', '60', '%', 'sentences', 'selected', 'summary', '.', 'S3', '4', '.', 'Figure', '1', '.', 'Document', 'summarization', 'pipeline', 'based', 'LSA', 'NMF', 'S2', 'sentence', 'selection', 'K-means', 'clustering', ',', 'grouped', 'similar', 'sentences', 'cluster', 'using', 'following', 'steps', ':', '1', '.', 'Randomly', 'select', 'K', 'sentences', 'representative', 'K', 'groups', '.', 'K', 'paper', 'number', 'sentences', 'selected', 'summary', '.', '2', '.', 'Calculate', 'centroid', 'group', 'using', 'value', 'sentence', 'vector', 'V', 'matrix', 'LSA', '𝐻𝐻𝑇𝑇', 'matrix', 'NMF', '.', '3', '.', 'Use', 'cosine', 'similarity', 'calculate', 'sentence', 'similarity', 'sentence', 'centroid', 'group', '.', 'assign', 'sentence', 'group', 'highest', 'similarity', '.', '4', '.', 'Repeat', 'steps', '2-3', 'sentences', 'assigned', 'group', ',', 'sentences', 'change', 'group', ',', 'similarity', 'sentences', 'centroid', 'close', '.', '5', '.', 'Select', 'sentence', 'maximum', 'similarity', 'score', 'centroid', 'group', 'add', 'summary', '.', 'S1', '3.6', 'A∙B', '=', 'n', 'n', '||A||', '||B||', '�∑i=1', 'A2i', '�∑i=1', 'Bi2', '(', '6', ')', 'Mr.Yontas', 'ak', '1', '0', '0', '0', '0', '0', '0', '0', '0', 'Supason', '1', '0', '0', '0', '0', '0', '0', '0', '0', 'Tourism', 'Authority', 'Thailand', '1', '0', '0', '0', '0', '0', '0', '0', '0', '…', '…', '…', '…', '…', '…', '…', '…', '…', '…', 'Table', '3', 'demonstrates', 'example', 'matrix', '𝐴𝐴', ',', 'constructed', 'word', 'count', 'sentence', 'Thai', 'travel', 'news', '.', 'composed', '98', 'words', '9', 'sentences', '.', 'matrix', '𝐴𝐴', 'applied', 'LSA', 'NMF', '.', 'sentence', 'vectors', 'calculated', 'term', 'weight', 'semantic', 'feature', 'vectors', 'Eq', '.', '(', '1', ')', 'LSA', 'Eq', '.', '(', '2', ')', 'NMF', '.', 'sentences', 'concepts', '.', 'Generic', 'Sentence', 'Relevance', 'score', 'NMF', 'also', 'collected', 'one', 'sentence', 'concept', ',', 'Gong', ',', 'Y.', 'et', 'al', '.', 'highest', 'score', 'calculated', 'Eq', '.', '(', '5', ')', '.', 'multiple', 'important', 'sentences', 'could', 'selected', 'important', 'concept', ',', 'Murray', ',', 'G.', 'et', 'al', '.', 'outperformed', 'Gong', ',', 'Y.', 'et', 'al', '.', 'GRS', 'method', '.', '6', '.', 'EXPERIMENT', 'RESULTS', '6.1', 'Performance', 'Evaluations', 'Measure', '7', '.', 'evaluated', 'results', 'summarization', 'using', 'standard', 'accuracy', ',', 'precision', ',', 'recall', ',', 'F1', 'score', '[', '21', ']', '.', 'measurements', 'quantify', 'differences', 'summary', 'human', 'experimental', 'methods', '.', 'precision', 'shows', 'correctness', 'extracted', 'sentences', 'recall', 'reflects', 'number', 'good', 'sentences', 'missed', 'method', '.', '6', '.', '2', 'Experiment', 'Results', 'experimental', 'set', ',', 'would', 'like', 'explore', 'different', 'sentence', 'selection', 'methods', ':', 'Generic', 'Sentence', 'Relevance', 'score', 'K-means', 'clustering', ',', 'affected', 'text', 'summarization', 'result', '.', 'K-means', 'clustering', ',', 'SVD', 'NMF', 'similar', 'summarization', 'efficiency', '.', 'F1', 'score', 'SVD', 'K-means', 'clustering', '0.83', ',', '0.72', ',', '0.62', 'compression', 'rate', '20', '%', ',', '30', '%', ',', '40', '%', '.', 'NMF', 'K-means', 'clustering', ',', 'F1', 'score', 'three', 'compression', 'rates', '0.83', ',', '0.74', '0.64', '.', 'Generic', 'Sentence', 'Relevance', 'score', ',', 'best', 'F1', 'score', 'compression', 'rate', '20', '%', ',', '30', '%', ',', '40', '%', '0.86', ',', '0.78', '0.68', 'respectively', 'best', 'F1', 'scores', 'compression', 'rates', 'approach', 'Murray', ',', 'G.', 'et', 'al', '.', 'Figure', '2', '.', 'Thai', 'text', 'summarization', 'efficiency', '5', 'models', 'Figure', '2', 'shows', 'Thai', 'text', 'summarization', 'efficiency', '5', 'models', ':', '(', '1', ')', 'NMF', 'GRS', ',', '(', '2', ')', 'NMF', 'K-means', ',', '(', '3', ')', 'SVD', 'sentence', 'score', 'Gong', ',', 'Y.', 'et', 'al.', ',', '(', '4', ')', 'SVD', 'K-means', ',', '(', '5', ')', 'SVD', 'sentence', 'score', 'Murray', ',', 'G.', 'et', 'al', '.', 'applied', '400', 'Thai', 'travel', 'news', ',', 'divided', '5', 'sets', '80', 'news', ',', 'varied', 'compression', 'rates', '20', '%', ',', '30', '%', '40', '%', '.', 'experiment', ',', 'best', 'model', 'based', 'keyword', 'score', 'Thai', 'travel', 'news', 'summarization', 'SVD', 'sentence', 'selection', 'Murray', ',', 'G.', 'et', 'al', '.', 'model', 'compression', 'rate', '20', '%', 'got', 'highest', 'score', 'Murray', 'G.', 'et', 'al', '.', 'method', 'determined', 'number', 'sentences', 'extracted', 'concept', 'based', 'importance', 'concept', '.', 'method', 'Gong', ',', 'Y.', 'et', 'al.', ',', 'hand', 'proposed', 'select', 'one', 'sentence', 'highest', 'score', 'concept', 'summary', 'would', 'include', 'CONCLUSIONS', 'paper', ',', 'applied', 'several', 'text', 'summarization', 'methods', 'Thai', 'Travel', 'News', 'based', 'keyword', 'scored', 'Thai', 'language', 'extracting', 'relevant', 'sentences', 'original', 'document', '.', 'compared', 'LSA', 'NMF', 'together', 'different', 'sentence', 'selection', 'methods', ',', 'find', 'algorithm', 'suitable', \"paper's\", 'data', 'source', '.', 'concluded', 'keyword', 'scored', 'calculation', 'LSA', 'sentence', 'selection', 'Generic', 'Sentence', 'Relevance', 'score', 'Murray', ',', 'G.', 'et', 'al', '.', 'best', 'algorithm', 'best', 'compression', 'rate', 'models', '20', '%', ',', 'summarizing', 'Thai', 'Travel', 'News', 'compared', 'humans', '.', 'future', 'work', ',', 'plan', 'perform', 'experiments', 'different', 'types', 'documents', 'improve', 'word', 'segmentation', 'compound', 'nouns', 'handled', 'Cutkum', '.', '8', '.', 'ACKNOWLEDGMENTS', 'would', 'like', 'thank', 'department', 'computer', 'engineering', ',', 'faculty', 'engineering', ',', 'Chulalongkorn', 'University', 'providing', 'computing', 'facilities', '.']\n",
            "POS tags: [('Extractive', 'JJ'), ('Text', 'NNP'), ('Summarization', 'NNP'), ('for', 'IN'), ('Thai', 'NNP'), ('Travel', 'NNP'), ('News', 'NNP'), ('Based', 'VBD'), ('on', 'IN'), ('Keyword', 'NNP'), ('Scored', 'NNP'), ('in', 'IN'), ('Thai', 'NNP'), ('Language', 'NNP'), ('Sarunya', 'NNP'), ('Nathonghor', 'NNP'), ('Duangdao', 'NNP'), ('Wichadakul', 'NNP'), ('Department', 'NNP'), ('of', 'IN'), ('Computer', 'NNP'), ('Engineering', 'NNP'), ('Chulalongkorn', 'NNP'), ('University', 'NNP'), ('Bangkok', 'NNP'), (',', ','), ('Thailand', 'NNP'), ('Department', 'NNP'), ('of', 'IN'), ('Computer', 'NNP'), ('Engineering', 'NNP'), ('Chulalongkorn', 'NNP'), ('University', 'NNP'), ('Bangkok', 'NNP'), (',', ','), ('Thailand', 'NNP'), ('Sarunya.N', 'NNP'), ('@', 'NNP'), ('Student.Chula.ac.th', 'NNP'), ('ABSTRACT', 'NNP'), ('In', 'IN'), ('recent', 'JJ'), ('years', 'NNS'), (',', ','), ('people', 'NNS'), ('are', 'VBP'), ('seeking', 'VBG'), ('for', 'IN'), ('a', 'DT'), ('solution', 'NN'), ('to', 'TO'), ('improve', 'VB'), ('text', 'NN'), ('summarization', 'NN'), ('for', 'IN'), ('Thai', 'NNP'), ('language', 'NN'), ('.', '.'), ('Although', 'IN'), ('several', 'JJ'), ('solutions', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('PageRank', 'NNP'), (',', ','), ('Graph', 'NNP'), ('Rank', 'NNP'), (',', ','), ('Latent', 'NNP'), ('Semantic', 'NNP'), ('Analysis', 'NNP'), ('(', '('), ('LSA', 'NNP'), (')', ')'), ('models', 'NNS'), (',', ','), ('etc.', 'FW'), (',', ','), ('have', 'VBP'), ('been', 'VBN'), ('proposed', 'VBN'), (',', ','), ('research', 'NN'), ('results', 'NNS'), ('in', 'IN'), ('Thai', 'NNP'), ('text', 'JJ'), ('summarization', 'NN'), ('were', 'VBD'), ('restricted', 'VBN'), ('due', 'JJ'), ('to', 'TO'), ('limited', 'JJ'), ('corpus', 'NN'), ('in', 'IN'), ('Thai', 'NNP'), ('language', 'NN'), ('with', 'IN'), ('complex', 'JJ'), ('grammar', 'NN'), ('.', '.'), ('This', 'DT'), ('paper', 'NN'), ('applied', 'VBD'), ('a', 'DT'), ('text', 'NN'), ('summarization', 'NN'), ('system', 'NN'), ('for', 'IN'), ('Thai', 'NNP'), ('travel', 'NN'), ('news', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('keyword', 'NN'), ('scored', 'VBN'), ('in', 'IN'), ('Thai', 'NNP'), ('language', 'NN'), ('by', 'IN'), ('extracting', 'VBG'), ('the', 'DT'), ('most', 'RBS'), ('relevant', 'JJ'), ('sentences', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('document', 'NN'), ('.', '.'), ('We', 'PRP'), ('compared', 'VBN'), ('LSA', 'NNP'), ('and', 'CC'), ('Non-negative', 'JJ'), ('Matrix', 'NNP'), ('Factorization', 'NNP'), ('(', '('), ('NMF', 'NNP'), (')', ')'), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('algorithm', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('suitable', 'JJ'), ('with', 'IN'), ('Thai', 'NNP'), ('travel', 'NN'), ('news', 'NN'), ('.', '.'), ('The', 'DT'), ('suitable', 'JJ'), ('compression', 'NN'), ('rates', 'NNS'), ('for', 'IN'), ('Generic', 'NNP'), ('Sentence', 'NNP'), ('Relevance', 'NNP'), ('score', 'NN'), ('(', '('), ('GRS', 'NNP'), (')', ')'), ('and', 'CC'), ('K-means', 'NNS'), ('clustering', 'VBG'), ('were', 'VBD'), ('also', 'RB'), ('evaluated', 'VBN'), ('.', '.'), ('From', 'IN'), ('these', 'DT'), ('experiments', 'NNS'), (',', ','), ('we', 'PRP'), ('concluded', 'VBD'), ('that', 'IN'), ('keyword', 'NN'), ('scored', 'VBN'), ('calculation', 'NN'), ('by', 'IN'), ('LSA', 'NNP'), ('with', 'IN'), ('sentence', 'NN'), ('selection', 'NN'), ('by', 'IN'), ('GRS', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('best', 'JJS'), ('algorithm', 'NN'), ('for', 'IN'), ('summarizing', 'VBG'), ('Thai', 'NNP'), ('Travel', 'NNP'), ('News', 'NNP'), (',', ','), ('compared', 'VBN'), ('with', 'IN'), ('human', 'JJ'), ('with', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('compression', 'NN'), ('rate', 'NN'), ('of', 'IN'), ('20', 'CD'), ('%', 'NN'), ('.', '.'), ('CCS', 'NNP'), ('Concepts', 'NNP'), ('•', 'NNP'), ('Information', 'NNP'), ('systems', 'NNS'), ('➝', 'NNP'), ('Information', 'NNP'), ('retrieval', 'NN'), ('➝', 'NNP'), ('Retrieval', 'NNP'), ('tasks', 'NNS'), ('and', 'CC'), ('goals➝', 'JJ'), ('Summarization', 'NNP'), ('Keywords', 'NNP'), ('Text', 'NNP'), ('summarization', 'NN'), (';', ':'), ('extractive', 'JJ'), ('summarization', 'NN'), (';', ':'), ('non-negative', 'JJ'), ('matrix', 'NN'), ('factorization', 'NN'), ('1', 'CD'), ('.', '.'), ('INTRODUCTION', 'NNP'), ('Daily', 'NNP'), ('newspaper', 'NN'), ('has', 'VBZ'), ('abundant', 'VBN'), ('of', 'IN'), ('data', 'NNS'), ('that', 'WDT'), ('users', 'NNS'), ('do', 'VBP'), ('not', 'RB'), ('have', 'VB'), ('enough', 'JJ'), ('time', 'NN'), ('for', 'IN'), ('reading', 'VBG'), ('them', 'PRP'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('difficult', 'JJ'), ('to', 'TO'), ('identify', 'VB'), ('the', 'DT'), ('relevant', 'JJ'), ('information', 'NN'), ('to', 'TO'), ('satisfy', 'VB'), ('the', 'DT'), ('information', 'NN'), ('needed', 'VBN'), ('by', 'IN'), ('users', 'NNS'), ('.', '.'), ('Automatic', 'JJ'), ('summarization', 'NN'), ('can', 'MD'), ('reduce', 'VB'), ('the', 'DT'), ('problem', 'NN'), ('of', 'IN'), ('information', 'NN'), ('overloading', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('has', 'VBZ'), ('been', 'VBN'), ('proposed', 'VBN'), ('previously', 'RB'), ('in', 'IN'), ('English', 'NNP'), ('and', 'CC'), ('other', 'JJ'), ('languages', 'NNS'), ('.', '.'), ('However', 'RB'), (',', ','), ('there', 'EX'), ('were', 'VBD'), ('only', 'RB'), ('a', 'DT'), ('few', 'JJ'), ('research', 'NN'), ('results', 'NNS'), ('in', 'IN'), ('Thai', 'NNP'), ('text', 'NN'), ('summarization', 'NN'), ('due', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('lack', 'NN'), ('of', 'IN'), ('corpus', 'NN'), ('in', 'IN'), ('Thai', 'NNP'), ('language', 'NN'), ('and', 'CC'), ('the', 'DT'), ('complicated', 'JJ'), ('grammar', 'NN'), ('.', '.'), ('Text', 'NNP'), ('Summarization', 'NNP'), ('[', 'VBD'), ('1', 'CD'), (']', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('technique', 'NN'), ('for', 'IN'), ('summarizing', 'VBG'), ('the', 'DT'), ('content', 'NN'), ('of', 'IN'), ('the', 'DT'), ('documents', 'NNS'), ('.', '.'), ('It', 'PRP'), ('consists', 'VBZ'), ('of', 'IN'), ('three', 'CD'), ('steps', 'NNS'), (':', ':'), ('1', 'CD'), (')', ')'), ('create', 'VBP'), ('an', 'DT'), ('intermediate', 'JJ'), ('representation', 'NN'), ('of', 'IN'), ('the', 'DT'), ('input', 'NN'), ('text', 'NN'), (',', ','), ('2', 'CD'), (')', ')'), ('calculate', 'NN'), ('score', 'NN'), ('for', 'IN'), ('the', 'DT'), ('sentences', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('concepts', 'NNS'), (',', ','), ('and', 'CC'), ('3', 'CD'), (')', ')'), ('choose', 'NN'), ('important', 'JJ'), ('Permission', 'NN'), ('to', 'TO'), ('make', 'VB'), ('digital', 'JJ'), ('or', 'CC'), ('hard', 'JJ'), ('copies', 'NNS'), ('of', 'IN'), ('all', 'DT'), ('or', 'CC'), ('part', 'NN'), ('of', 'IN'), ('this', 'DT'), ('work', 'NN'), ('for', 'IN'), ('personal', 'JJ'), ('or', 'CC'), ('classroom', 'NN'), ('use', 'NN'), ('is', 'VBZ'), ('granted', 'VBN'), ('without', 'IN'), ('fee', 'NN'), ('provided', 'VBD'), ('that', 'IN'), ('copies', 'NNS'), ('are', 'VBP'), ('not', 'RB'), ('made', 'VBN'), ('or', 'CC'), ('distributed', 'VBN'), ('for', 'IN'), ('profit', 'NN'), ('or', 'CC'), ('commercial', 'JJ'), ('advantage', 'NN'), ('and', 'CC'), ('that', 'IN'), ('copies', 'NNS'), ('bear', 'VBP'), ('this', 'DT'), ('notice', 'NN'), ('and', 'CC'), ('the', 'DT'), ('full', 'JJ'), ('citation', 'NN'), ('on', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('page', 'NN'), ('.', '.'), ('Copyrights', 'NNS'), ('for', 'IN'), ('components', 'NNS'), ('of', 'IN'), ('this', 'DT'), ('work', 'NN'), ('owned', 'VBN'), ('by', 'IN'), ('others', 'NNS'), ('than', 'IN'), ('ACM', 'NNP'), ('must', 'MD'), ('be', 'VB'), ('honored', 'VBN'), ('.', '.'), ('Abstracting', 'VBG'), ('with', 'IN'), ('credit', 'NN'), ('is', 'VBZ'), ('permitted', 'VBN'), ('.', '.'), ('To', 'TO'), ('copy', 'VB'), ('otherwise', 'RB'), (',', ','), ('or', 'CC'), ('republish', 'VB'), (',', ','), ('to', 'TO'), ('post', 'VB'), ('on', 'IN'), ('servers', 'NNS'), ('or', 'CC'), ('to', 'TO'), ('redistribute', 'VB'), ('to', 'TO'), ('lists', 'NNS'), (',', ','), ('requires', 'VBZ'), ('prior', 'JJ'), ('specific', 'JJ'), ('permission', 'NN'), ('and/or', 'IN'), ('a', 'DT'), ('fee', 'NN'), ('.', '.'), ('Request', 'JJS'), ('permissions', 'NNS'), ('from', 'IN'), ('Permissions', 'NNP'), ('@', 'NNP'), ('acm.org', 'NN'), ('.', '.'), ('ITCC', 'NNP'), ('2020', 'CD'), (',', ','), ('August', 'NNP'), ('12–14', 'CD'), (',', ','), ('2020', 'CD'), (',', ','), ('Kuala', 'NNP'), ('Lumpur', 'NNP'), (',', ','), ('Malaysia', 'NNP'), ('©', 'NNP'), ('2020', 'CD'), ('Association', 'NNP'), ('for', 'IN'), ('Computing', 'VBG'), ('Machinery', 'NNP'), ('.', '.'), ('ACM', 'NNP'), ('ISBN', 'NNP'), ('978-1-4503-7539-9/20/08…', 'JJ'), ('$', '$'), ('15.00', 'CD'), ('DOI', 'NNP'), (':', ':'), ('https', 'NN'), (':', ':'), ('//doi.org/10.1145/3417473.3417479', 'JJ'), ('Duangdao.W', 'NNP'), ('@', 'NNP'), ('Chula.ac.th', 'NNP'), ('sentences', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('included', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('summary', 'NN'), ('.', '.'), ('Text', 'JJ'), ('summarization', 'NN'), ('can', 'MD'), ('be', 'VB'), ('divided', 'VBN'), ('into', 'IN'), ('2', 'CD'), ('approaches', 'NNS'), ('.', '.'), ('The', 'DT'), ('first', 'JJ'), ('approach', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('extractive', 'JJ'), ('summarization', 'NN'), (',', ','), ('which', 'WDT'), ('relies', 'VBZ'), ('on', 'IN'), ('a', 'DT'), ('method', 'NN'), ('for', 'IN'), ('extracting', 'VBG'), ('words', 'NNS'), ('and', 'CC'), ('searching', 'VBG'), ('for', 'IN'), ('keywords', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('document', 'NN'), ('.', '.'), ('The', 'DT'), ('second', 'JJ'), ('approach', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('abstractive', 'JJ'), ('summarization', 'NN'), (',', ','), ('which', 'WDT'), ('analyzes', 'VBZ'), ('words', 'NNS'), ('by', 'IN'), ('linguistic', 'JJ'), ('principles', 'NNS'), ('with', 'IN'), ('transcription', 'NN'), ('or', 'CC'), ('interpretation', 'NN'), ('from', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('document', 'NN'), ('.', '.'), ('This', 'DT'), ('approach', 'NN'), ('implies', 'VBZ'), ('more', 'RBR'), ('effective', 'JJ'), ('and', 'CC'), ('accurate', 'JJ'), ('summary', 'NN'), ('than', 'IN'), ('the', 'DT'), ('extractive', 'JJ'), ('methods', 'NNS'), ('.', '.'), ('However', 'RB'), (',', ','), ('with', 'IN'), ('the', 'DT'), ('lack', 'NN'), ('of', 'IN'), ('Thai', 'NNP'), ('corpus', 'NN'), (',', ','), ('we', 'PRP'), ('chose', 'VBD'), ('to', 'TO'), ('apply', 'VB'), ('an', 'DT'), ('extractive', 'JJ'), ('summarization', 'NN'), ('method', 'NN'), ('for', 'IN'), ('Thai', 'NNP'), ('text', 'JJ'), ('summarization', 'NN'), ('.', '.'), ('This', 'DT'), ('research', 'NN'), ('focused', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('sentence', 'NN'), ('extraction', 'NN'), ('function', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('keyword', 'NN'), ('score', 'NN'), ('calculation', 'NN'), ('then', 'RB'), ('selecting', 'VBG'), ('important', 'JJ'), ('sentences', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('Generic', 'NNP'), ('Sentence', 'NNP'), ('Relevance', 'NNP'), ('score', 'NN'), ('(', '('), ('GRS', 'NNP'), (')', ')'), (',', ','), ('calculated', 'VBN'), ('from', 'IN'), ('Latent', 'NNP'), ('Semantic', 'NNP'), ('Analysis', 'NNP'), ('(', '('), ('LSA', 'NNP'), (')', ')'), ('and', 'CC'), ('Non-negative', 'JJ'), ('Matrix', 'NNP'), ('Factorization', 'NNP'), ('(', '('), ('NMF', 'NNP'), (')', ')'), ('.', '.'), ('We', 'PRP'), ('also', 'RB'), ('tried', 'VBD'), ('using', 'VBG'), ('K-means', 'NNP'), ('clustering', 'NN'), ('for', 'IN'), ('document', 'JJ'), ('summarization', 'NN'), ('.', '.'), ('In', 'IN'), ('this', 'DT'), ('experiment', 'NN'), (',', ','), ('we', 'PRP'), ('compared', 'VBN'), ('5', 'CD'), ('models', 'NNS'), ('for', 'IN'), ('5', 'CD'), ('rounds', 'NNS'), ('with', 'IN'), ('Thai', 'NNP'), ('travel', 'VBP'), ('news', 'NN'), ('using', 'VBG'), ('the', 'DT'), ('compression', 'NN'), ('rates', 'NNS'), ('of', 'IN'), ('20', 'CD'), ('%', 'NN'), (',', ','), ('30', 'CD'), ('%', 'NN'), ('and', 'CC'), ('40', 'CD'), ('%', 'NN'), ('and', 'CC'), ('reported', 'VBD'), ('the', 'DT'), ('rate', 'NN'), ('and', 'CC'), ('method', 'NN'), ('that', 'WDT'), ('produced', 'VBD'), ('the', 'DT'), ('best', 'JJS'), ('result', 'NN'), ('from', 'IN'), ('the', 'DT'), ('experiment', 'NN'), ('.', '.'), ('2', 'CD'), ('.', '.'), ('RELATED', 'JJ'), ('WORKS', 'NNP'), ('In', 'IN'), ('recent', 'JJ'), ('years', 'NNS'), (',', ','), ('several', 'JJ'), ('models', 'NNS'), ('in', 'IN'), ('Thai', 'NNP'), ('Text', 'NNP'), ('summarization', 'NN'), ('have', 'VBP'), ('been', 'VBN'), ('introduced', 'VBN'), ('.', '.'), ('Suwanno', 'NNP'), (',', ','), ('N.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('[', 'CC'), ('2', 'CD'), (']', 'NNS'), ('proposed', 'VBD'), ('a', 'DT'), ('Thai', 'NNP'), ('text', 'NN'), ('summarization', 'NN'), ('that', 'WDT'), ('extracted', 'VBD'), ('a', 'DT'), ('paragraph', 'NN'), ('from', 'IN'), ('a', 'DT'), ('document', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('Thai', 'NNP'), ('compound', 'NN'), ('nouns', 'RB'), (',', ','), ('term', 'NN'), ('frequency', 'NN'), ('method', 'NN'), (',', ','), ('and', 'CC'), ('headline', 'NN'), ('score', 'NN'), ('for', 'IN'), ('generating', 'VBG'), ('a', 'DT'), ('summary', 'JJ'), ('.', '.'), ('Chongsuntornsri', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.'), ('[', 'CC'), ('3', 'CD'), (']', 'NNS'), ('proposed', 'VBD'), ('a', 'DT'), ('new', 'JJ'), ('approach', 'NN'), ('for', 'IN'), ('Text', 'NNP'), ('summarization', 'NN'), ('in', 'IN'), ('Thai', 'NNP'), ('based', 'VBN'), ('on', 'IN'), ('content-', 'JJ'), ('and', 'CC'), ('graph-based', 'JJ'), ('with', 'IN'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('Topic', 'NNP'), ('Sensitive', 'NNP'), ('PageRank', 'NNP'), ('algorithm', 'NN'), ('for', 'IN'), ('summarizing', 'VBG'), ('and', 'CC'), ('ranking', 'NN'), ('of', 'IN'), ('text', 'JJ'), ('segments', 'NNS'), ('.', '.'), ('Jaruskulchai', 'NNP'), ('C.', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.'), ('[', 'CC'), ('4', 'CD'), (']', 'NNS'), ('proposed', 'VBD'), ('a', 'DT'), ('method', 'NN'), ('to', 'TO'), ('summarize', 'VB'), ('documents', 'NNS'), ('by', 'IN'), ('extracting', 'VBG'), ('important', 'JJ'), ('sentences', 'NNS'), ('from', 'IN'), ('combining', 'VBG'), ('the', 'DT'), ('specific', 'NN'), ('properties', 'NNS'), ('(', '('), ('Local', 'NNP'), ('Property', 'NNP'), (')', ')'), ('and', 'CC'), ('the', 'DT'), ('overall', 'JJ'), ('properties', 'NNS'), ('(', '('), ('Global', 'NNP'), ('Property', 'NNP'), (')', ')'), ('of', 'IN'), ('the', 'DT'), ('sentences', 'NNS'), ('.', '.'), ('The', 'DT'), ('overall', 'JJ'), ('properties', 'NNS'), ('were', 'VBD'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('relationship', 'NN'), ('between', 'IN'), ('sentences', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('document', 'NN'), ('.', '.'), ('From', 'IN'), ('their', 'PRP$'), ('experiments', 'NNS'), (',', ','), ('the', 'DT'), ('summarization', 'NN'), ('of', 'IN'), ('the', 'DT'), ('industrial', 'JJ'), ('news', 'NN'), ('got', 'VBD'), ('60', 'CD'), ('%', 'NN'), ('precision', 'NN'), (',', ','), ('44', 'CD'), ('%', 'NN'), ('recall', 'NN'), (',', ','), ('and', 'CC'), ('50.9', 'CD'), ('%', 'NN'), ('F-measure', 'NN'), (',', ','), ('the', 'DT'), ('general', 'JJ'), ('news', 'NN'), ('got', 'VBD'), ('the', 'DT'), ('51.8', 'CD'), ('%', 'NN'), ('precision', 'NN'), (',', ','), ('38.5', 'CD'), ('%', 'NN'), ('recall', 'NN'), (',', ','), ('and', 'CC'), ('43.1', 'CD'), ('%', 'NN'), ('F-measure', 'NN'), ('while', 'IN'), ('the', 'DT'), ('fashion', 'NN'), ('magazines', 'NNS'), ('got', 'VBD'), ('53.0', 'CD'), ('%', 'NN'), ('precision', 'NN'), (',', ','), ('33.0', 'CD'), ('%', 'NN'), ('recall', 'NN'), (',', ','), ('and', 'CC'), ('40.4', 'CD'), ('%', 'NN'), ('F-measure', 'NN'), ('.', '.'), ('Mani', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('et', 'NN'), ('al', 'NN'), ('.', '.'), ('[', 'CC'), ('5', 'CD'), (']', 'NNS'), ('proposed', 'VBN'), ('techniques', 'NNS'), ('of', 'IN'), ('text', 'JJ'), ('summarization', 'NN'), ('by', 'IN'), ('using', 'VBG'), ('word', 'NN'), ('frequency', 'NN'), ('in', 'IN'), ('the', 'DT'), ('document', 'NN'), ('and', 'CC'), ('calculated', 'VBD'), ('the', 'DT'), ('weight', 'NN'), ('of', 'IN'), ('word', 'NN'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('keyword', 'NN'), ('group', 'NN'), ('.', '.'), ('They', 'PRP'), ('then', 'RB'), ('calculated', 'VBD'), ('the', 'DT'), ('cosine', 'JJ'), ('similarity', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('.', '.'), ('The', 'DT'), ('researcher', 'NN'), ('used', 'VBD'), ('A', 'DT'), ('*', 'JJ'), ('search', 'NN'), ('algorithm', 'NN'), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('shortest', 'JJS'), ('sequence', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('from', 'IN'), ('keyword', 'NN'), ('group', 'NN'), ('by', 'IN'), ('topic', 'NN'), ('calculation', 'NN'), (',', ','), ('sentence', 'NN'), ('segmentation', 'NN'), ('and', 'CC'), ('word', 'NN'), ('grouping', 'NN'), ('.', '.'), ('The', 'DT'), ('sequence', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('that', 'WDT'), ('were', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('main', 'JJ'), ('group', 'NN'), ('were', 'VBD'), ('selected', 'VBN'), ('as', 'IN'), ('important', 'JJ'), ('sentences', 'NNS'), ('.', '.'), ('Their', 'PRP$'), ('summarization', 'NN'), ('of', 'IN'), ('the', 'DT'), ('agricultural', 'JJ'), ('news', 'NN'), ('got', 'VBD'), ('68.57', 'CD'), ('%', 'NN'), ('precision', 'NN'), (',', ','), ('51.95', 'CD'), ('%', 'NN'), ('recall', 'NN'), ('and', 'CC'), ('56.72', 'CD'), ('%', 'NN'), ('F-measure', 'NN'), ('.', '.'), ('Lee', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.'), ('[', 'CC'), ('6', 'CD'), (']', 'NNS'), ('proposed', 'VBD'), ('a', 'DT'), ('document', 'NN'), ('summarization', 'NN'), ('method', 'NN'), ('using', 'VBG'), ('Non-negative', 'JJ'), ('Matrix', 'NNP'), ('Factorization', 'NNP'), ('(', '('), ('NMF', 'NNP'), (')', ')'), ('.', '.'), ('They', 'PRP'), ('compared', 'VBN'), ('between', 'IN'), ('Latent', 'NNP'), ('Semantic', 'NNP'), ('Analysis', 'NNP'), ('(', '('), ('LSA', 'NNP'), (')', ')'), ('and', 'CC'), ('NMF', 'NNP'), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('weight', 'NN'), ('of', 'IN'), ('each', 'DT'), ('word', 'NN'), ('and', 'CC'), ('calculated', 'VBD'), ('the', 'DT'), ('summation', 'NN'), ('of', 'IN'), ('weights', 'NNS'), ('.', '.'), ('The', 'DT'), ('important', 'JJ'), ('sentences', 'NNS'), ('were', 'VBD'), ('ranked', 'VBN'), ('and', 'CC'), ('selected', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('summary', 'JJ'), ('based', 'VBN'), ('on', 'IN'), ('their', 'PRP$'), ('summed', 'JJ'), ('weight', 'NN'), ('.', '.'), ('Based', 'VBN'), ('on', 'IN'), ('LSA', 'NNP'), (',', ','), ('they', 'PRP'), ('found', 'VBD'), ('many', 'JJ'), ('weights', 'NNS'), ('with', 'IN'), ('zero', 'NN'), ('and', 'CC'), ('negative', 'JJ'), ('values', 'NNS'), ('.', '.'), ('However', 'RB'), (',', ','), ('when', 'WRB'), ('applied', 'VBN'), ('NMF', 'NNP'), (',', ','), ('they', 'PRP'), ('found', 'VBD'), ('only', 'RB'), ('the', 'DT'), ('positive', 'JJ'), ('values', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('scope', 'NN'), ('of', 'IN'), ('the', 'DT'), ('semantic', 'JJ'), ('features', 'NNS'), ('’', 'VBP'), ('meaning', 'NN'), ('was', 'VBD'), ('narrow', 'JJ'), ('.', '.'), ('Therefore', 'RB'), (',', ','), ('they', 'PRP'), ('proposed', 'VBD'), ('that', 'IN'), ('NMF', 'NNP'), ('provided', 'VBD'), ('a', 'DT'), ('greater', 'JJR'), ('possibility', 'NN'), ('for', 'IN'), ('extracting', 'VBG'), ('important', 'JJ'), ('sentences', 'NNS'), ('.', '.'), ('3', 'CD'), ('.', '.'), ('PREPROCESSING', 'NN'), ('FOR', 'IN'), ('THAI', 'NNP'), ('TEXT', 'NNP'), ('The', 'DT'), ('first', 'JJ'), ('step', 'NN'), ('for', 'IN'), ('working', 'VBG'), ('with', 'IN'), ('Thai', 'NNP'), ('Text', 'NNP'), ('is', 'VBZ'), ('word', 'NN'), ('tokenization', 'NN'), ('.', '.'), ('Even', 'RB'), ('though', 'IN'), ('Thai', 'NNP'), ('writing', 'VBG'), ('system', 'NN'), ('has', 'VBZ'), ('no', 'DT'), ('delimiters', 'NNS'), ('to', 'TO'), ('indicate', 'VB'), ('word', 'NN'), ('boundaries', 'VBZ'), ('together', 'RB'), ('with', 'IN'), ('many', 'JJ'), ('rules', 'NNS'), ('for', 'IN'), ('word', 'NN'), ('segmentation', 'NN'), (',', ','), ('several', 'JJ'), ('Thai', 'NNP'), ('word', 'NN'), ('tokenization', 'NN'), ('programs', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('proposed', 'VBN'), ('.', '.'), ('Table', 'JJ'), ('1', 'CD'), ('shows', 'NNS'), ('F1', 'NNP'), ('score', 'NN'), ('of', 'IN'), ('the', 'DT'), ('recent', 'JJ'), ('programs', 'NNS'), ('trained', 'VBD'), ('and', 'CC'), ('tested', 'VBN'), ('by', 'IN'), ('one', 'CD'), ('of', 'IN'), ('our', 'PRP$'), ('laboratory', 'NN'), ('members', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('data', 'NNS'), ('from', 'IN'), ('BEST2010', 'NNP'), ('corpus', 'NN'), ('[', 'VBD'), ('7', 'CD'), (']', 'NN'), ('.', '.'), ('Cutkum', 'NNP'), ('[', 'VBD'), ('8', 'CD'), (']', 'NNP'), ('got', 'VBD'), ('the', 'DT'), ('highest', 'JJS'), ('F1', 'NNP'), ('score', 'NN'), (',', ','), ('hence', 'RB'), (',', ','), ('we', 'PRP'), ('used', 'VBD'), ('Cutkum', 'NNP'), ('for', 'IN'), ('this', 'DT'), ('step', 'NN'), ('.', '.'), ('Table', 'JJ'), ('1', 'CD'), ('.', '.'), ('Comparison', 'NNP'), ('of', 'IN'), ('Thai', 'NNP'), ('word', 'NN'), ('tokenization', 'NN'), ('programs', 'NNS'), ('Tools', 'NNP'), ('F1', 'NNP'), ('Score', 'NNP'), ('Validate', 'NNP'), ('PyICU', 'NNP'), ('[', 'VBD'), ('9', 'CD'), (']', 'JJ'), ('Article', 'NNP'), ('100', 'CD'), ('0.6155', 'CD'), ('Encyclopedia', 'NNP'), ('100', 'CD'), ('0.6932', 'CD'), ('News', 'NNP'), ('100', 'CD'), ('0.5987', 'CD'), ('Novel', 'NNP'), ('100', 'CD'), ('0.6800', 'CD'), ('Lexto', 'NNP'), ('[', 'VBD'), ('10', 'CD'), (']', 'JJ'), ('0.7267', 'CD'), ('0.7709', 'CD'), ('0.6994', 'CD'), ('0.7701', 'CD'), ('Cutkum', 'NNP'), ('wordcutpy', 'NN'), ('[', 'VBD'), ('11', 'CD'), (']', 'JJ'), ('0.9322', 'CD'), ('0.6212', 'CD'), ('0.9299', 'CD'), ('0.6286', 'CD'), ('0.8987', 'CD'), ('0.6571', 'CD'), ('0.7140', 'CD'), ('0.6247', 'CD'), ('cunlp', 'NN'), ('[', 'VBD'), ('12', 'CD'), (']', 'JJ'), ('0.6910', 'CD'), ('0.6172', 'CD'), ('0.5748', 'CD'), ('0.0000', 'CD'), ('SWATH', 'NNP'), ('[', 'VBD'), ('13', 'CD'), (']', 'JJ'), ('0.6347', 'CD'), ('0.6858', 'CD'), ('0.6200', 'CD'), ('0.6867', 'CD'), ('3.1', 'CD'), ('Latent', 'NNP'), ('Semantic', 'NNP'), ('Analysis', 'NNP'), ('Latent', 'NNP'), ('Semantic', 'NNP'), ('Analysis', 'NNP'), ('(', '('), ('LSA', 'NNP'), (')', ')'), ('[', 'VBD'), ('14', 'CD'), (']', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('algorithm', 'NN'), (',', ','), ('which', 'WDT'), ('reduces', 'VBZ'), ('the', 'DT'), ('dimensionality', 'NN'), ('of', 'IN'), ('term', 'NN'), ('document', 'NN'), ('.', '.'), ('The', 'DT'), ('algorithm', 'NN'), ('creates', 'VBZ'), ('a', 'DT'), ('matrix', 'NN'), ('by', 'IN'), ('using', 'VBG'), ('word', 'NN'), ('frequency', 'NN'), (',', ','), ('applies', 'VBZ'), ('the', 'DT'), ('singular', 'JJ'), ('value', 'NN'), ('decomposition', 'NN'), ('(', '('), ('SVD', 'NNP'), (')', ')'), ('[', 'VBD'), ('15', 'CD'), (']', 'NN'), (',', ','), ('and', 'CC'), ('then', 'RB'), ('finds', 'VBZ'), ('closely', 'RB'), ('related', 'JJ'), ('terms', 'NNS'), ('and', 'CC'), ('documents', 'NNS'), ('.', '.'), ('The', 'DT'), ('original', 'JJ'), ('matrix', 'NN'), ('A', 'DT'), ('can', 'MD'), ('be', 'VB'), ('separated', 'VBN'), ('into', 'IN'), ('three', 'CD'), ('matrices', 'NNS'), (',', ','), ('where', 'WRB'), ('U', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('m', 'NN'), ('x', 'NNP'), ('r', 'NN'), ('(', '('), ('words', 'NNS'), ('x', 'RB'), ('extracted', 'VBD'), ('concept', 'NN'), (')', ')'), ('matrix', 'NN'), (',', ','), ('V', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('n', 'JJ'), ('x', 'NN'), ('r', 'NN'), ('(', '('), ('sentences', 'NNS'), ('x', 'RB'), ('extracted', 'VBD'), ('concepts', 'NNS'), (')', ')'), ('matrix', 'NN'), (',', ','), ('and', 'CC'), ('Σ', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('r', 'NN'), ('x', 'NNP'), ('r', 'VBZ'), ('diagonal', 'JJ'), ('matrix', 'NN'), (',', ','), ('which', 'WDT'), ('can', 'MD'), ('be', 'VB'), ('reconstructed', 'VBN'), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('original', 'JJ'), ('matrix', 'NN'), ('A', 'NNP'), ('.', '.'), ('The', 'DT'), ('SVD', 'NNP'), ('can', 'MD'), ('be', 'VB'), ('represented', 'VBN'), ('in', 'IN'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('1', 'CD'), (')', ')'), ('.', '.'), ('3.2', 'CD'), ('A', 'NNP'), ('≈', 'NNP'), ('𝑈𝑈𝑈𝑈𝑉𝑉', 'NNP'), ('𝑇𝑇', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('related', 'JJ'), ('singular', 'JJ'), ('value', 'NN'), ('over', 'IN'), ('the', 'DT'), ('sum', 'NN'), ('of', 'IN'), ('all', 'DT'), ('singular', 'JJ'), ('values', 'NNS'), (',', ','), ('for', 'IN'), ('each', 'DT'), ('concept', 'NN'), ('.', '.'), ('3.3', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), ('A', 'DT'), ('=', 'JJ'), ('𝑊𝑊𝑊𝑊', 'NN'), ('Factors', 'NNS'), ('W', 'NNP'), ('and', 'CC'), ('H', 'NNP'), ('can', 'MD'), ('be', 'VB'), ('found', 'VBN'), ('by', 'IN'), ('solving', 'VBG'), ('the', 'DT'), ('optimization', 'NN'), ('problem', 'NN'), ('as', 'IN'), ('follows', 'VBZ'), (',', ','), ('where𝑊𝑊𝑗𝑗𝑗𝑗', 'JJ'), ('≥', 'NN'), ('0', 'CD'), (',', ','), ('𝐻𝐻𝑖𝑖𝑖𝑖', 'NNP'), ('≥', 'VBZ'), ('0.', 'CD'), ('𝑚𝑚', 'NN'), ('𝑛𝑛', 'NNP'), ('𝑟𝑟', 'NNP'), ('𝑗𝑗=1', 'NNP'), ('𝑖𝑖=1', 'NNP'), ('𝑙𝑙=1', 'VBD'), ('2', 'CD'), ('𝑚𝑚𝑚𝑚𝑚𝑚', 'NN'), ('𝐹𝐹', 'NNP'), ('(', '('), ('𝑊𝑊', 'NNP'), (',', ','), ('𝐻𝐻', 'NNP'), (')', ')'), ('=', 'VBP'), ('||', 'JJ'), ('𝐴𝐴', 'NNP'), ('−', 'NNP'), ('𝑊𝑊𝑊𝑊', 'NNP'), ('||2𝐹𝐹', 'NNP'), ('=', 'NNP'), ('�', 'NNP'), ('�', 'NNP'), ('�𝐴𝐴𝑖𝑖𝑖𝑖', 'NNP'), ('−', 'NNP'), ('�', 'NNP'), ('𝑊𝑊𝑖𝑖𝑖𝑖', 'NNP'), ('𝐻𝐻𝑖𝑖𝑖𝑖', 'NNP'), ('�', 'NNP'), ('(', '('), ('3', 'CD'), (')', ')'), ('NMF', 'NNP'), ('and', 'CC'), ('LSA', 'NNP'), ('are', 'VBP'), ('both', 'DT'), ('matrix', 'JJ'), ('factorization', 'NN'), ('algorithms', 'NN'), ('.', '.'), ('However', 'RB'), (',', ','), ('when', 'WRB'), ('using', 'VBG'), ('NMF', 'NNP'), ('to', 'TO'), ('find', 'VB'), ('keywords', 'NNS'), (',', ','), ('NMF', 'NNP'), ('will', 'MD'), ('return', 'VB'), ('the', 'DT'), ('keywords', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('closely', 'RB'), ('related', 'JJ'), ('because', 'IN'), ('its', 'PRP$'), ('components', 'NNS'), ('have', 'VBP'), ('only', 'RB'), ('nonnegative', 'JJ'), ('values', 'NNS'), ('.', '.'), ('As', 'IN'), ('LSA', 'NNP'), ('has', 'VBZ'), ('both', 'DT'), ('positive', 'JJ'), ('and', 'CC'), ('negative', 'JJ'), ('values', 'NNS'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('some', 'DT'), ('zeroes', 'NNS'), (',', ','), ('it', 'PRP'), ('gets', 'VBZ'), ('a', 'DT'), ('wider', 'NN'), ('distribution', 'NN'), ('.', '.'), ('The', 'DT'), ('semantic', 'JJ'), ('feature', 'NN'), ('represents', 'VBZ'), ('a', 'DT'), ('concept', 'NN'), ('of', 'IN'), ('meaning', 'VBG'), ('for', 'IN'), ('root', 'NN'), ('of', 'IN'), ('words', 'NNS'), ('that', 'WDT'), ('have', 'VBP'), ('a', 'DT'), ('relationship', 'NN'), ('.', '.'), ('For', 'IN'), ('example', 'NN'), (',', ','), ('man', 'NN'), (',', ','), ('human', 'JJ'), (',', ','), ('male', 'NN'), ('and', 'CC'), ('adult', 'NN'), ('have', 'VBP'), ('the', 'DT'), ('same', 'JJ'), ('semantic', 'JJ'), (',', ','), ('hence', 'VB'), ('their', 'PRP$'), ('semantic', 'JJ'), ('values', 'NNS'), ('are', 'VBP'), ('close', 'JJ'), ('.', '.'), ('In', 'IN'), ('this', 'DT'), ('paper', 'NN'), (',', ','), ('we', 'PRP'), ('applied', 'VBD'), ('LSA', 'NNP'), ('and', 'CC'), ('NMF', 'NNP'), ('on', 'IN'), ('the', 'DT'), ('Thai', 'NNP'), ('Travel', 'NNP'), ('News', 'NNP'), ('dataset', 'NN'), ('for', 'IN'), ('calculating', 'VBG'), ('the', 'DT'), ('semantic', 'JJ'), ('weights', 'NNS'), (',', ','), ('which', 'WDT'), ('represented', 'VBD'), ('the', 'DT'), ('relationship', 'NN'), ('between', 'IN'), ('sentences', 'NNS'), ('and', 'CC'), ('words', 'NNS'), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('select', 'VB'), ('the', 'DT'), ('representative', 'JJ'), ('sentences', 'NNS'), ('for', 'IN'), ('summarization', 'NN'), ('.', '.'), ('3.4', 'CD'), ('Generic', 'JJ'), ('document', 'NN'), ('summarization', 'NN'), ('by', 'IN'), ('NMF', 'NNP'), ('Lee', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.'), ('proposed', 'VBN'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('4', 'CD'), (')', ')'), ('and', 'CC'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('5', 'CD'), (')', ')'), ('to', 'TO'), ('select', 'VB'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('NMF', 'NNP'), (',', ','), ('which', 'WDT'), ('got', 'VBD'), ('the', 'DT'), ('highest', 'JJS'), ('semantic', 'JJ'), ('weight', 'NN'), ('values', 'NNS'), (',', ','), ('where', 'WRB'), ('𝐻𝐻𝑖𝑖𝑖𝑖', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('weight', 'NN'), ('of', 'IN'), ('the', 'DT'), ('topic', 'NN'), ('𝑖𝑖', 'NN'), ('in', 'IN'), ('the', 'DT'), ('sentence', 'NN'), ('𝑗𝑗', 'NN'), ('.', '.'), ('Generic', 'JJ'), ('Relevance', 'NN'), ('of', 'IN'), ('jth', 'JJ'), ('sentence', 'NN'), ('𝑟𝑟', 'NNP'), ('(', '('), ('1', 'CD'), (')', ')'), ('=', 'NN'), ('�', 'NNP'), ('𝐻𝐻𝑖𝑖𝑖𝑖', 'NNP'), ('𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', 'NNP'), ('(', '('), ('𝐻𝐻𝑖𝑖', 'NNP'), (')', ')'), ('Document', 'NNP'), ('summarization', 'NN'), ('using', 'VBG'), ('LSA', 'NNP'), ('Gong', 'NNP'), (',', ','), ('Y.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('[', 'CC'), ('16', 'CD'), (']', 'NNS'), ('proposed', 'VBD'), ('a', 'DT'), ('document', 'NN'), ('summarization', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('SVD', 'NNP'), ('matrices', 'NNS'), ('.', '.'), ('In', 'IN'), ('our', 'PRP$'), ('work', 'NN'), (',', ','), ('after', 'IN'), ('applying', 'VBG'), ('SVD', 'NNP'), ('to', 'TO'), ('matrix', 'VB'), ('A', 'NNP'), (',', ','), ('𝑉𝑉', 'NNP'), ('𝑇𝑇', 'NNP'), ('matrix', 'NN'), ('used', 'VBN'), ('for', 'IN'), ('selecting', 'VBG'), ('the', 'DT'), ('important', 'JJ'), ('sentences', 'NNS'), ('.', '.'), ('The', 'DT'), ('cell', 'NN'), ('value', 'NN'), ('of', 'IN'), ('the', 'DT'), ('matrix', 'NN'), ('shows', 'VBZ'), ('the', 'DT'), ('relationship', 'NN'), ('between', 'IN'), ('sentence', 'NN'), ('and', 'CC'), ('extracted', 'VBD'), ('concepts', 'NNS'), ('.', '.'), ('A', 'DT'), ('sentence', 'NN'), ('with', 'IN'), ('the', 'DT'), ('highest', 'JJS'), ('cell', 'NN'), ('value', 'NN'), ('of', 'IN'), ('each', 'DT'), ('concept', 'NN'), ('will', 'MD'), ('be', 'VB'), ('selected', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('summary', 'JJ'), ('starting', 'NN'), ('from', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('important', 'JJ'), ('concept', 'NN'), ('.', '.'), ('The', 'DT'), ('total', 'JJ'), ('number', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('summary', 'NN'), ('will', 'MD'), ('be', 'VB'), ('equal', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('number', 'NN'), ('all', 'DT'), ('detected', 'VBD'), ('concepts', 'NNS'), ('.', '.'), ('Murray', 'NNP'), (',', ','), ('G.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('[', 'CC'), ('17', 'CD'), (']', 'NNS'), ('proposed', 'VBD'), ('a', 'DT'), ('document', 'NN'), ('summarization', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('SVD', 'NNP'), ('matrices', 'NNS'), ('using', 'VBG'), ('𝑉𝑉', 'JJ'), ('𝑇𝑇', 'NN'), ('and', 'CC'), ('Σ', 'JJ'), ('matrices', 'NNS'), ('for', 'IN'), ('sentence', 'NN'), ('selection', 'NN'), ('.', '.'), ('The', 'DT'), ('authors', 'NNS'), ('proposed', 'VBD'), ('that', 'IN'), ('more', 'JJR'), ('than', 'IN'), ('one', 'CD'), ('sentence', 'NN'), ('could', 'MD'), ('be', 'VB'), ('collected', 'VBN'), ('from', 'IN'), ('the', 'DT'), ('more', 'RBR'), ('important', 'JJ'), ('concepts', 'NNS'), ('.', '.'), ('The', 'DT'), ('decision', 'NN'), ('of', 'IN'), ('how', 'WRB'), ('many', 'JJ'), ('sentences', 'NNS'), ('would', 'MD'), ('be', 'VB'), ('collected', 'VBN'), ('from', 'IN'), ('each', 'DT'), ('concept', 'NN'), ('depending', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('Σ', 'NNP'), ('matrix', 'NN'), ('.', '.'), ('The', 'DT'), ('value', 'NN'), ('was', 'VBD'), ('decided', 'VBN'), ('by', 'IN'), ('getting', 'VBG'), ('the', 'DT'), ('percentage', 'NN'), ('Non-negative', 'JJ'), ('Matrix', 'NNP'), ('Factorization', 'NNP'), ('Non-negative', 'NNP'), ('Matrix', 'NNP'), ('Factorization', 'NNP'), ('(', '('), ('NMF', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('method', 'NN'), ('of', 'IN'), ('matrix', 'JJ'), ('factorization', 'NN'), ('subject', 'NN'), ('to', 'TO'), ('the', 'DT'), ('non-negative', 'JJ'), ('constraint', 'NN'), ('.', '.'), ('Lee', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.'), ('proposed', 'VBD'), ('the', 'DT'), ('model', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('NMF', 'NNP'), ('for', 'IN'), ('document', 'NN'), ('summarization', 'NN'), ('.', '.'), ('NMF', 'NNP'), ('decomposes', 'VBZ'), ('a', 'DT'), ('non-negative', 'JJ'), ('matrix', 'NN'), ('𝐴𝐴', 'NNP'), ('∈', 'NNP'), ('𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'NNP'), ('into', 'IN'), ('two', 'CD'), ('nonnegative', 'JJ'), ('matrices', 'NNS'), ('.', '.'), ('The', 'DT'), ('first', 'JJ'), ('matrix', 'NN'), ('𝑚𝑚', 'NNP'), ('x', 'NNP'), ('𝑟𝑟', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('non-negative', 'JJ'), ('semantic', 'JJ'), ('feature', 'NN'), ('matrix', 'NN'), ('(', '('), ('NSFM', 'NNP'), (')', ')'), (',', ','), ('𝑊𝑊', 'UH'), ('.', '.'), ('The', 'DT'), ('second', 'JJ'), ('matrix', 'NN'), ('𝑟𝑟', 'NNP'), ('x', 'NNP'), ('𝑛𝑛', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('nonnegative', 'JJ'), ('semantic', 'JJ'), ('variable', 'JJ'), ('matrix', 'NN'), ('(', '('), ('NSVM', 'NNP'), (')', ')'), (',', ','), ('𝐻𝐻', 'NNP'), ('.', '.'), ('So', 'RB'), (',', ','), ('we', 'PRP'), ('have', 'VBP'), ('𝑊𝑊', 'VBN'), ('∈', 'NNP'), ('𝑅𝑅𝑚𝑚𝑚𝑚𝑚𝑚', 'NNP'), ('and', 'CC'), ('𝐻𝐻', 'NNP'), ('∈', 'NNP'), ('𝑅𝑅𝑟𝑟𝑟𝑟𝑟𝑟', 'NNP'), ('and', 'CC'), ('both', 'DT'), ('terms', 'NNS'), ('are', 'VBP'), ('non-negative', 'JJ'), ('as', 'IN'), ('shown', 'VBN'), ('in', 'IN'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('2', 'CD'), (')', ')'), ('and', 'CC'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('3', 'CD'), (')', ')'), ('.', '.'), ('(', '('), ('4', 'CD'), (')', ')'), ('𝑖𝑖=1', 'NN'), ('𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', 'NNP'), ('(', '('), ('𝐻𝐻𝑖𝑖', 'NNP'), (')', ')'), ('=', 'VBP'), ('∑𝑛𝑛𝑞𝑞=1', 'JJ'), ('𝐻𝐻𝑖𝑖𝑖𝑖', 'NNP'), ('𝑟𝑟', 'NNP'), ('∑𝑝𝑝=1', 'NNP'), ('∑𝑛𝑛𝑞𝑞=1', 'NNP'), ('𝐻𝐻𝑝𝑝𝑝𝑝', 'NNP'), ('(', '('), ('5', 'CD'), (')', ')'), ('The', 'DT'), ('𝑤𝑤𝑤𝑤𝑤𝑤𝑤𝑤ℎ𝑡𝑡', 'NN'), ('(', '('), ('𝐻𝐻𝑖𝑖', 'NNP'), (')', ')'), ('is', 'VBZ'), ('the', 'DT'), ('relative', 'JJ'), ('relevance', 'NN'), ('of', 'IN'), ('the', 'DT'), ('ith', 'JJ'), ('semantic', 'JJ'), ('feature', 'NN'), ('(', '('), ('𝑊𝑊𝑖𝑖', 'NNP'), (')', ')'), (',', ','), ('where', 'WRB'), ('𝐻𝐻𝑖𝑖𝑖𝑖', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('weight', 'NN'), ('of', 'IN'), ('the', 'DT'), ('topic', 'NN'), ('𝑖𝑖', 'NN'), ('in', 'IN'), ('the', 'DT'), ('sentence', 'NN'), ('𝑞𝑞', 'NN'), ('and', 'CC'), ('𝐻𝐻𝑝𝑝𝑝𝑝', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('weight', 'NN'), ('of', 'IN'), ('the', 'DT'), ('topic', 'NN'), ('𝑝𝑝', 'NN'), ('in', 'IN'), ('the', 'DT'), ('sentence', 'NN'), ('𝑞𝑞', 'NN'), ('.', '.'), ('The', 'DT'), ('sentences', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('ranked', 'VBN'), ('by', 'IN'), ('Generic', 'NNP'), ('Relevance', 'NNP'), ('Sentence', 'NNP'), ('scores', 'NNS'), ('.', '.'), ('Sentences', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('maximum', 'JJ'), ('score', 'NN'), ('will', 'MD'), ('be', 'VB'), ('selected', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('summary', 'JJ'), ('.', '.'), ('3.5', 'CD'), ('Cosine', 'NNP'), ('Similarity', 'NNP'), ('Cosine', 'NNP'), ('similarity', 'NN'), ('[', 'NNP'), ('18', 'CD'), (']', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('widely', 'RB'), ('used', 'VBN'), ('method', 'NN'), ('to', 'TO'), ('measure', 'VB'), ('the', 'DT'), ('similarity', 'NN'), ('between', 'IN'), ('vectors', 'NNS'), ('representing', 'VBG'), ('the', 'DT'), ('documents', 'NNS'), ('.', '.'), ('The', 'DT'), ('result', 'NN'), ('of', 'IN'), ('cosine', 'NN'), ('similarity', 'NN'), ('is', 'VBZ'), ('ranging', 'VBG'), ('from', 'IN'), ('0', 'CD'), ('to', 'TO'), ('1', 'CD'), ('.', '.'), ('If', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('closer', 'RBR'), ('to', 'TO'), ('1', 'CD'), (',', ','), ('that', 'DT'), ('means', 'VBZ'), ('both', 'DT'), ('vectors', 'NNS'), ('are', 'VBP'), ('similar', 'JJ'), ('.', '.'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('6', 'CD'), (')', ')'), ('and', 'CC'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('7', 'CD'), (')', ')'), ('represents', 'VBZ'), ('the', 'DT'), ('cosine', 'NN'), ('similarity', 'NN'), ('equation', 'NN'), (',', ','), ('where', 'WRB'), ('cos', 'NN'), ('(', '('), ('θ', 'NNP'), (')', ')'), ('is', 'VBZ'), ('the', 'DT'), ('dot', 'JJ'), ('product', 'NN'), ('between', 'IN'), ('vectors', 'NNS'), ('of', 'IN'), ('sentences', 'NNS'), ('A', 'NNP'), ('and', 'CC'), ('B', 'NNP'), ('and', 'CC'), ('divided', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('product', 'NN'), ('of', 'IN'), ('the', 'DT'), ('two', 'CD'), (\"vectors'\", 'JJ'), ('lengths', 'NNS'), ('.', '.'), ('In', 'IN'), ('this', 'DT'), ('paper', 'NN'), (',', ','), ('we', 'PRP'), ('deployed', 'VBD'), ('cosine', 'JJ'), ('similarity', 'NN'), ('to', 'TO'), ('measure', 'VB'), ('the', 'DT'), ('similarity', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('in', 'IN'), ('K-means', 'NNP'), ('clustering', 'NN'), ('.', '.'), ('A∙B', 'NNP'), ('||A||', 'NNP'), ('||B||', 'NNP'), ('∑ni=1', 'NNP'), ('Ai', 'NNP'), ('Bi', 'NNP'), ('Similarity', 'NNP'), ('(', '('), ('A', 'NNP'), (',', ','), ('B', 'NNP'), (')', ')'), ('=', 'NN'), ('cos', 'NN'), ('(', '('), ('θ', 'NNP'), (')', ')'), ('=', 'NNP'), ('(', '('), ('7', 'CD'), (')', ')'), ('K-means', 'NNPS'), ('Clustering', 'VBG'), ('15', 'CD'), ('67', 'CD'), ('7', 'CD'), ('7', 'CD'), ('13', 'CD'), ('13', 'CD'), ('55', 'CD'), ('38', 'CD'), ('Table', 'JJ'), ('2', 'CD'), ('shows', 'VBZ'), ('the', 'DT'), ('overall', 'JJ'), ('number', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('of', 'IN'), ('news', 'NN'), ('within', 'IN'), ('each', 'DT'), ('dataset', 'NN'), ('.', '.'), ('The', 'DT'), ('average', 'JJ'), ('numbers', 'NNS'), ('of', 'IN'), ('sentences', 'NNS'), ('per', 'IN'), ('news', 'NN'), ('of', 'IN'), ('the', 'DT'), ('5', 'CD'), ('sets', 'NNS'), ('were', 'VBD'), ('21', 'CD'), (',', ','), ('16', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('13', 'CD'), ('and', 'CC'), ('13', 'CD'), ('sentences', 'NNS'), (',', ','), ('respectively', 'RB'), ('.', '.'), ('5', 'CD'), ('.', '.'), ('PIPELINE', 'NNP'), ('FOR', 'IN'), ('GENERATING', 'NNP'), ('SUMMARIES', 'NNP'), ('In', 'IN'), ('this', 'DT'), ('section', 'NN'), (',', ','), ('we', 'PRP'), ('demonstrate', 'VBP'), ('our', 'PRP$'), ('pipeline', 'NN'), ('(', '('), ('Figure', 'NNP'), ('1', 'CD'), (')', ')'), ('used', 'VBN'), ('for', 'IN'), ('text', 'JJ'), ('summarization', 'NN'), ('to', 'TO'), ('generate', 'VB'), ('a', 'DT'), ('summary', 'NN'), ('for', 'IN'), ('a', 'DT'), ('Thai', 'NNP'), ('travel', 'NN'), ('news', 'NN'), ('.', '.'), ('Word', 'NNP'), ('S9', 'NNP'), ('6', 'CD'), ('Round', 'NNP'), ('4', 'CD'), ('Round', 'NNP'), ('5', 'CD'), ('Table', 'NNP'), ('3', 'CD'), ('.', '.'), ('Example', 'NN'), ('of', 'IN'), ('Word', 'NNP'), ('by', 'IN'), ('Sentence', 'NNP'), ('Matrix', 'NNP'), ('A', 'NNP'), ('S8', 'NNP'), ('Round', 'NNP'), ('3', 'CD'), ('Avg', 'NNP'), ('.', '.'), ('Number', 'NNP'), ('of', 'IN'), ('Sentences', 'NNP'), ('S7', 'NNP'), ('21', 'CD'), ('16', 'CD'), ('Round', 'NNP'), ('1', 'CD'), ('Round', 'NNP'), ('2', 'CD'), ('Min', 'NNP'), ('.', '.'), ('Number', 'NNP'), ('of', 'IN'), ('Sentences', 'NNP'), ('S6', 'NNP'), ('7', 'CD'), ('7', 'CD'), ('Max', 'NNP'), ('.', '.'), ('Number', 'NNP'), ('of', 'IN'), ('Sentences', 'NNP'), ('58', 'CD'), ('58', 'CD'), ('Dataset', 'NNP'), ('S5', 'NNP'), ('Table', 'NNP'), ('2', 'CD'), ('.', '.'), ('Overall', 'JJ'), ('Sentence', 'NNP'), ('Language', 'NNP'), ('of', 'IN'), ('each', 'DT'), ('Dataset', 'NNP'), ('S4', 'NNP'), ('DATA', 'NNP'), ('PREPARATION', 'NNP'), ('The', 'DT'), ('standard', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('in', 'IN'), ('Thai', 'NNP'), ('language', 'NN'), ('are', 'VBP'), ('unavailable', 'JJ'), ('for', 'IN'), ('evaluating', 'VBG'), ('text', 'JJ'), ('summarization', 'NN'), ('system', 'NN'), ('.', '.'), ('Therefore', 'RB'), (',', ','), ('we', 'PRP'), ('collected', 'VBD'), ('400', 'CD'), ('Thai', 'NNP'), ('travel', 'NN'), ('news', 'NN'), ('from', 'IN'), ('Thairath', 'NNP'), ('and', 'CC'), ('Manager', 'NNP'), ('online', 'VBP'), ('newspapers', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('used', 'VBN'), ('as', 'IN'), ('datasets', 'NNS'), ('for', 'IN'), ('our', 'PRP$'), ('experiments', 'NNS'), ('.', '.'), ('We', 'PRP'), ('split', 'VBD'), ('400', 'CD'), ('travel', 'JJ'), ('news', 'NN'), ('into', 'IN'), ('5', 'CD'), ('sets', 'NNS'), ('of', 'IN'), ('80', 'CD'), ('news', 'NN'), ('each', 'DT'), ('.', '.'), ('We', 'PRP'), ('then', 'RB'), ('evaluated', 'VBD'), ('the', 'DT'), ('performance', 'NN'), ('of', 'IN'), ('text', 'JJ'), ('summarization', 'NN'), ('methods', 'NNS'), ('which', 'WDT'), ('were', 'VBD'), ('LSA', 'NNP'), ('and', 'CC'), ('NMF', 'NNP'), ('by', 'IN'), ('comparing', 'VBG'), ('their', 'PRP$'), ('results', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('summaries', 'NNS'), ('manually', 'RB'), ('curated', 'VBN'), ('by', 'IN'), ('two', 'CD'), ('experts', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('Faculty', 'NN'), ('of', 'IN'), ('Liberal', 'NNP'), ('Arts', 'NNP'), (',', ','), ('Ubon', 'NNP'), ('Ratchathani', 'NNP'), ('University', 'NNP'), ('.', '.'), ('The', 'DT'), ('open-source', 'JJ'), ('python', 'NN'), ('libraries', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('numpy', 'JJ'), ('[', '$'), ('19', 'CD'), (']', 'NN'), ('and', 'CC'), ('sklearn', 'VB'), ('[', 'JJ'), ('20', 'CD'), (']', 'NN'), ('were', 'VBD'), ('used', 'VBN'), ('in', 'IN'), ('our', 'PRP$'), ('system', 'NN'), ('.', '.'), ('We', 'PRP'), ('converted', 'VBD'), ('the', 'DT'), ('Thai', 'NNP'), ('travel', 'NN'), ('news', 'NN'), ('obtained', 'VBN'), ('from', 'IN'), ('Thairath', 'NNP'), ('and', 'CC'), ('Manager', 'NNP'), ('online', 'VBP'), ('newspapers', 'NNS'), ('to', 'TO'), ('plain', 'VB'), ('text', 'NN'), ('.', '.'), ('Then', 'RB'), (',', ','), ('the', 'DT'), ('sentences', 'NNS'), ('of', 'IN'), ('each', 'DT'), ('news', 'NN'), ('were', 'VBD'), ('segmented', 'VBN'), ('by', 'IN'), ('human', 'JJ'), ('with', 'IN'), ('the', 'DT'), ('following', 'JJ'), ('format', 'NN'), (':', ':'), ('Si', 'NNP'), ('=', 'NNP'), ('‘', 'NNP'), ('xxx', 'NNP'), ('’', 'NNP'), (',', ','), ('where', 'WRB'), ('Si', 'NNP'), ('represents', 'VBZ'), ('the', 'DT'), ('order', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sentence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('document', 'NN'), ('and', 'CC'), ('‘', 'NNP'), ('xxx', 'NNP'), ('’', 'NNP'), ('represents', 'VBZ'), ('the', 'DT'), ('content', 'NN'), ('of', 'IN'), ('that', 'DT'), ('sentence', 'NN'), ('.', '.'), ('After', 'IN'), ('removing', 'VBG'), ('stop', 'JJ'), ('words', 'NNS'), ('and', 'CC'), ('duplicate', 'NN'), ('words', 'NNS'), (',', ','), ('we', 'PRP'), ('built', 'VBP'), ('a', 'DT'), ('document', 'JJ'), ('term', 'NN'), ('matrix', 'NN'), ('or', 'CC'), ('matrix', 'VB'), ('A', 'DT'), ('then', 'RB'), ('applied', 'VBN'), ('SVD', 'NNP'), ('and', 'CC'), ('NMF', 'NNP'), ('to', 'TO'), ('the', 'DT'), ('matrix', 'NN'), ('.', '.'), ('Then', 'RB'), (',', ','), ('we', 'PRP'), ('used', 'VBD'), ('python', 'NN'), ('modules', 'NNS'), ('numpy.linalg.svd', 'VBP'), ('to', 'TO'), ('calculate', 'VB'), ('SVD', 'NNP'), ('and', 'CC'), ('sklearn.decomposition', 'NN'), ('to', 'TO'), ('calculate', 'VB'), ('NMF', 'NNP'), ('.', '.'), ('For', 'IN'), ('sentence', 'NN'), ('selection', 'NN'), (',', ','), ('we', 'PRP'), ('used', 'VBD'), ('Gong', 'NNP'), (',', ','), ('Y.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('and', 'CC'), ('Murray', 'NNP'), (',', ','), ('G.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('approaches', 'NNS'), ('for', 'IN'), ('calculating', 'VBG'), ('weight', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sentence', 'NN'), ('scores', 'VBZ'), ('then', 'RB'), ('selected', 'VBN'), ('sentences', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('highest', 'JJS'), ('scores', 'NNS'), ('into', 'IN'), ('the', 'DT'), ('summary', 'NN'), ('.', '.'), ('For', 'IN'), ('keyword', 'NN'), ('score', 'NN'), ('calculation', 'NN'), ('of', 'IN'), ('NMF', 'NNP'), (',', ','), ('we', 'PRP'), ('calculated', 'VBD'), ('the', 'DT'), ('keyword', 'NN'), ('score', 'NN'), ('from', 'IN'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('5', 'CD'), (')', ')'), ('and', 'CC'), ('then', 'RB'), ('selected', 'VBD'), ('the', 'DT'), ('sentence', 'NN'), ('with', 'IN'), ('the', 'DT'), ('highest', 'JJS'), ('score', 'NN'), ('from', 'IN'), ('each', 'DT'), ('concept', 'NN'), ('.', '.'), ('The', 'DT'), ('python', 'NN'), ('module', 'NN'), ('sklearn.cluster', 'NN'), ('was', 'VBD'), ('used', 'VBN'), ('for', 'IN'), ('K-means', 'NNP'), ('clustering', 'NN'), ('.', '.'), ('The', 'DT'), ('selected', 'JJ'), ('sentences', 'NNS'), ('from', 'IN'), ('all', 'DT'), ('approaches', 'NNS'), ('were', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('order', 'NN'), ('as', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('document', 'NN'), ('.', '.'), ('In', 'IN'), ('this', 'DT'), ('paper', 'NN'), (',', ','), ('we', 'PRP'), ('performed', 'VBD'), ('the', 'DT'), ('20', 'CD'), ('%', 'NN'), (',', ','), ('30', 'CD'), ('%', 'NN'), ('and', 'CC'), ('40', 'CD'), ('%', 'NN'), ('document', 'JJ'), ('compression', 'NN'), ('.', '.'), ('This', 'DT'), ('meant', 'VBD'), ('80', 'CD'), ('%', 'NN'), (',', ','), ('70', 'CD'), ('%', 'NN'), ('and', 'CC'), ('60', 'CD'), ('%', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sentences', 'NNS'), ('will', 'MD'), ('be', 'VB'), ('selected', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('summary', 'JJ'), ('.', '.'), ('S3', 'NNP'), ('4', 'CD'), ('.', '.'), ('Figure', 'NN'), ('1', 'CD'), ('.', '.'), ('Document', 'NNP'), ('summarization', 'NN'), ('pipeline', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('LSA', 'NNP'), ('and', 'CC'), ('NMF', 'NNP'), ('S2', 'NNP'), ('For', 'IN'), ('sentence', 'NN'), ('selection', 'NN'), ('by', 'IN'), ('K-means', 'NNP'), ('clustering', 'NN'), (',', ','), ('we', 'PRP'), ('grouped', 'VBD'), ('similar', 'JJ'), ('sentences', 'NNS'), ('into', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('cluster', 'NN'), ('using', 'VBG'), ('the', 'DT'), ('following', 'JJ'), ('steps', 'NNS'), (':', ':'), ('1', 'CD'), ('.', '.'), ('Randomly', 'NNP'), ('select', 'JJ'), ('K', 'NNP'), ('sentences', 'NNS'), ('as', 'IN'), ('the', 'DT'), ('representative', 'NN'), ('of', 'IN'), ('K', 'NNP'), ('groups', 'NNS'), ('.', '.'), ('K', 'NNP'), ('in', 'IN'), ('this', 'DT'), ('paper', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('that', 'WDT'), ('will', 'MD'), ('be', 'VB'), ('selected', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('summary', 'JJ'), ('.', '.'), ('2', 'CD'), ('.', '.'), ('Calculate', 'NNP'), ('centroid', 'NN'), ('of', 'IN'), ('each', 'DT'), ('group', 'NN'), ('by', 'IN'), ('using', 'VBG'), ('the', 'DT'), ('value', 'NN'), ('of', 'IN'), ('sentence', 'NN'), ('vector', 'NN'), ('from', 'IN'), ('V', 'NNP'), ('matrix', 'NN'), ('for', 'IN'), ('LSA', 'NNP'), ('and', 'CC'), ('𝐻𝐻𝑇𝑇', 'NNP'), ('matrix', 'NN'), ('for', 'IN'), ('NMF', 'NNP'), ('.', '.'), ('3', 'CD'), ('.', '.'), ('Use', 'VB'), ('cosine', 'JJ'), ('similarity', 'NN'), ('to', 'TO'), ('calculate', 'VB'), ('sentence', 'NN'), ('similarity', 'NN'), ('between', 'IN'), ('a', 'DT'), ('sentence', 'NN'), ('and', 'CC'), ('the', 'DT'), ('centroid', 'NN'), ('of', 'IN'), ('each', 'DT'), ('group', 'NN'), ('.', '.'), ('Then', 'RB'), ('assign', 'VBZ'), ('that', 'IN'), ('sentence', 'NN'), ('to', 'TO'), ('the', 'DT'), ('group', 'NN'), ('with', 'IN'), ('the', 'DT'), ('highest', 'JJS'), ('similarity', 'NN'), ('.', '.'), ('4', 'CD'), ('.', '.'), ('Repeat', 'JJ'), ('steps', 'NNS'), ('2-3', 'JJ'), ('until', 'IN'), ('all', 'DT'), ('sentences', 'NNS'), ('are', 'VBP'), ('assigned', 'VBN'), ('to', 'TO'), ('a', 'DT'), ('group', 'NN'), (',', ','), ('no', 'DT'), ('sentences', 'NNS'), ('change', 'VBP'), ('the', 'DT'), ('group', 'NN'), (',', ','), ('or', 'CC'), ('the', 'DT'), ('similarity', 'NN'), ('between', 'IN'), ('sentences', 'NNS'), ('and', 'CC'), ('their', 'PRP$'), ('centroid', 'NN'), ('is', 'VBZ'), ('close', 'RB'), ('.', '.'), ('5', 'CD'), ('.', '.'), ('Select', 'VB'), ('a', 'DT'), ('sentence', 'NN'), ('with', 'IN'), ('the', 'DT'), ('maximum', 'JJ'), ('similarity', 'NN'), ('score', 'NN'), ('with', 'IN'), ('the', 'DT'), ('centroid', 'NN'), ('of', 'IN'), ('the', 'DT'), ('group', 'NN'), ('and', 'CC'), ('add', 'VB'), ('it', 'PRP'), ('into', 'IN'), ('the', 'DT'), ('summary', 'JJ'), ('.', '.'), ('S1', 'NNP'), ('3.6', 'CD'), ('A∙B', 'NNP'), ('=', 'NNP'), ('n', 'MD'), ('n', 'VB'), ('||A||', 'NNP'), ('||B||', 'NNP'), ('�∑i=1', 'NNP'), ('A2i', 'NNP'), ('�∑i=1', 'NNP'), ('Bi2', 'NNP'), ('(', '('), ('6', 'CD'), (')', ')'), ('Mr.Yontas', 'NNP'), ('ak', '$'), ('1', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('Supason', 'NNP'), ('1', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('Tourism', 'NNP'), ('Authority', 'NNP'), ('of', 'IN'), ('Thailand', 'NNP'), ('1', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('0', 'CD'), ('…', 'NN'), ('…', 'NNP'), ('…', 'NNP'), ('…', 'NNP'), ('…', 'NNP'), ('…', 'NNP'), ('…', 'NNP'), ('…', 'NNP'), ('…', 'NNP'), ('…', 'NNP'), ('Table', 'NNP'), ('3', 'CD'), ('demonstrates', 'VBZ'), ('an', 'DT'), ('example', 'NN'), ('of', 'IN'), ('a', 'DT'), ('matrix', 'NN'), ('𝐴𝐴', 'NN'), (',', ','), ('constructed', 'VBN'), ('from', 'IN'), ('word', 'NN'), ('count', 'NN'), ('by', 'IN'), ('sentence', 'NN'), ('of', 'IN'), ('a', 'DT'), ('Thai', 'NNP'), ('travel', 'NN'), ('news', 'NN'), ('.', '.'), ('It', 'PRP'), ('was', 'VBD'), ('composed', 'VBN'), ('of', 'IN'), ('98', 'CD'), ('words', 'NNS'), ('and', 'CC'), ('9', 'CD'), ('sentences', 'NNS'), ('.', '.'), ('This', 'DT'), ('matrix', 'NN'), ('𝐴𝐴', 'NN'), ('was', 'VBD'), ('then', 'RB'), ('applied', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('LSA', 'NNP'), ('and', 'CC'), ('NMF', 'NNP'), ('.', '.'), ('The', 'DT'), ('sentence', 'NN'), ('vectors', 'NNS'), ('were', 'VBD'), ('calculated', 'VBN'), ('from', 'IN'), ('the', 'DT'), ('term', 'NN'), ('weight', 'NN'), ('and', 'CC'), ('the', 'DT'), ('semantic', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('from', 'IN'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('1', 'CD'), (')', ')'), ('for', 'IN'), ('LSA', 'NNP'), ('and', 'CC'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('2', 'CD'), (')', ')'), ('for', 'IN'), ('NMF', 'NNP'), ('.', '.'), ('sentences', 'NNS'), ('from', 'IN'), ('all', 'DT'), ('concepts', 'NNS'), ('.', '.'), ('The', 'DT'), ('Generic', 'JJ'), ('Sentence', 'NNP'), ('Relevance', 'NNP'), ('score', 'NN'), ('for', 'IN'), ('NMF', 'NNP'), ('also', 'RB'), ('collected', 'VBD'), ('one', 'CD'), ('sentence', 'NN'), ('for', 'IN'), ('each', 'DT'), ('concept', 'NN'), (',', ','), ('the', 'DT'), ('same', 'JJ'), ('as', 'IN'), ('Gong', 'NNP'), (',', ','), ('Y.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('but', 'CC'), ('with', 'IN'), ('the', 'DT'), ('highest', 'JJS'), ('score', 'NN'), ('calculated', 'VBN'), ('by', 'IN'), ('Eq', 'NNP'), ('.', '.'), ('(', '('), ('5', 'CD'), (')', ')'), ('.', '.'), ('As', 'IN'), ('multiple', 'JJ'), ('important', 'JJ'), ('sentences', 'NNS'), ('could', 'MD'), ('be', 'VB'), ('selected', 'VBN'), ('from', 'IN'), ('a', 'DT'), ('more', 'RBR'), ('important', 'JJ'), ('concept', 'NN'), (',', ','), ('Murray', 'NNP'), (',', ','), ('G.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('outperformed', 'VBN'), ('both', 'DT'), ('Gong', 'NNP'), (',', ','), ('Y.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('and', 'CC'), ('the', 'DT'), ('GRS', 'NNP'), ('method', 'NN'), ('.', '.'), ('6', 'CD'), ('.', '.'), ('EXPERIMENT', 'NNP'), ('AND', 'CC'), ('RESULTS', 'NNP'), ('6.1', 'CD'), ('Performance', 'NNP'), ('Evaluations', 'NNP'), ('Measure', 'NNP'), ('7', 'CD'), ('.', '.'), ('We', 'PRP'), ('evaluated', 'VBD'), ('the', 'DT'), ('results', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('summarization', 'NN'), ('by', 'IN'), ('using', 'VBG'), ('standard', 'JJ'), ('accuracy', 'NN'), (',', ','), ('precision', 'NN'), (',', ','), ('recall', 'NN'), (',', ','), ('and', 'CC'), ('F1', 'NNP'), ('score', 'VBD'), ('[', 'JJ'), ('21', 'CD'), (']', 'NN'), ('.', '.'), ('These', 'DT'), ('measurements', 'NNS'), ('quantify', 'VBP'), ('the', 'DT'), ('differences', 'NNS'), ('between', 'IN'), ('the', 'DT'), ('summary', 'NN'), ('from', 'IN'), ('human', 'JJ'), ('and', 'CC'), ('the', 'DT'), ('experimental', 'JJ'), ('methods', 'NNS'), ('.', '.'), ('The', 'DT'), ('precision', 'NN'), ('shows', 'VBZ'), ('the', 'DT'), ('correctness', 'NN'), ('of', 'IN'), ('the', 'DT'), ('extracted', 'JJ'), ('sentences', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('recall', 'NN'), ('reflects', 'VBZ'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('good', 'JJ'), ('sentences', 'NNS'), ('missed', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('method', 'NN'), ('.', '.'), ('6', 'CD'), ('.', '.'), ('2', 'CD'), ('Experiment', 'JJ'), ('Results', 'NNS'), ('In', 'IN'), ('this', 'DT'), ('experimental', 'JJ'), ('set', 'NN'), (',', ','), ('we', 'PRP'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('explore', 'VB'), ('how', 'WRB'), ('the', 'DT'), ('different', 'JJ'), ('sentence', 'NN'), ('selection', 'NN'), ('methods', 'NNS'), (':', ':'), ('the', 'DT'), ('Generic', 'NNP'), ('Sentence', 'NNP'), ('Relevance', 'NNP'), ('score', 'NN'), ('and', 'CC'), ('K-means', 'NNP'), ('clustering', 'NN'), (',', ','), ('affected', 'VBD'), ('the', 'DT'), ('text', 'NN'), ('summarization', 'NN'), ('result', 'NN'), ('.', '.'), ('For', 'IN'), ('K-means', 'NNP'), ('clustering', 'NN'), (',', ','), ('both', 'DT'), ('SVD', 'NNP'), ('and', 'CC'), ('NMF', 'NNP'), ('had', 'VBD'), ('similar', 'JJ'), ('summarization', 'NN'), ('efficiency', 'NN'), ('.', '.'), ('The', 'DT'), ('F1', 'NNP'), ('score', 'NN'), ('of', 'IN'), ('SVD', 'NNP'), ('with', 'IN'), ('K-means', 'NNP'), ('clustering', 'NN'), ('was', 'VBD'), ('0.83', 'CD'), (',', ','), ('0.72', 'CD'), (',', ','), ('and', 'CC'), ('0.62', 'CD'), ('for', 'IN'), ('the', 'DT'), ('compression', 'NN'), ('rate', 'NN'), ('of', 'IN'), ('20', 'CD'), ('%', 'NN'), (',', ','), ('30', 'CD'), ('%', 'NN'), (',', ','), ('and', 'CC'), ('40', 'CD'), ('%', 'NN'), ('.', '.'), ('For', 'IN'), ('the', 'DT'), ('NMF', 'NNP'), ('with', 'IN'), ('K-means', 'NNP'), ('clustering', 'NN'), (',', ','), ('the', 'DT'), ('F1', 'NNP'), ('score', 'NN'), ('for', 'IN'), ('the', 'DT'), ('three', 'CD'), ('compression', 'NN'), ('rates', 'NNS'), ('was', 'VBD'), ('0.83', 'CD'), (',', ','), ('0.74', 'CD'), ('and', 'CC'), ('0.64', 'CD'), ('.', '.'), ('For', 'IN'), ('the', 'DT'), ('Generic', 'NNP'), ('Sentence', 'NNP'), ('Relevance', 'NNP'), ('score', 'NN'), (',', ','), ('the', 'DT'), ('best', 'JJS'), ('F1', 'NN'), ('score', 'NN'), ('for', 'IN'), ('the', 'DT'), ('compression', 'NN'), ('rate', 'NN'), ('of', 'IN'), ('20', 'CD'), ('%', 'NN'), (',', ','), ('30', 'CD'), ('%', 'NN'), (',', ','), ('and', 'CC'), ('40', 'CD'), ('%', 'NN'), ('was', 'VBD'), ('0.86', 'CD'), (',', ','), ('0.78', 'CD'), ('and', 'CC'), ('0.68', 'CD'), ('respectively', 'RB'), ('and', 'CC'), ('the', 'DT'), ('best', 'JJS'), ('F1', 'NN'), ('scores', 'NNS'), ('for', 'IN'), ('all', 'DT'), ('compression', 'NN'), ('rates', 'NNS'), ('were', 'VBD'), ('from', 'IN'), ('the', 'DT'), ('approach', 'NN'), ('of', 'IN'), ('Murray', 'NNP'), (',', ','), ('G.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('Figure', 'NN'), ('2', 'CD'), ('.', '.'), ('Thai', 'NNP'), ('text', 'JJ'), ('summarization', 'NN'), ('efficiency', 'NN'), ('of', 'IN'), ('5', 'CD'), ('models', 'NNS'), ('Figure', 'NNP'), ('2', 'CD'), ('shows', 'VBZ'), ('the', 'DT'), ('Thai', 'NNP'), ('text', 'NN'), ('summarization', 'NN'), ('efficiency', 'NN'), ('of', 'IN'), ('5', 'CD'), ('models', 'NNS'), (':', ':'), ('(', '('), ('1', 'CD'), (')', ')'), ('NMF', 'NN'), ('with', 'IN'), ('GRS', 'NNP'), (',', ','), ('(', '('), ('2', 'CD'), (')', ')'), ('NMF', 'NN'), ('with', 'IN'), ('K-means', 'NNP'), (',', ','), ('(', '('), ('3', 'CD'), (')', ')'), ('SVD', 'NN'), ('with', 'IN'), ('sentence', 'NN'), ('score', 'NN'), ('by', 'IN'), ('Gong', 'NNP'), (',', ','), ('Y.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('(', '('), ('4', 'CD'), (')', ')'), ('SVD', 'NN'), ('with', 'IN'), ('K-means', 'NNP'), (',', ','), ('and', 'CC'), ('(', '('), ('5', 'CD'), (')', ')'), ('SVD', 'NN'), ('with', 'IN'), ('sentence', 'NN'), ('score', 'NN'), ('by', 'IN'), ('Murray', 'NNP'), (',', ','), ('G.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('applied', 'VBN'), ('to', 'TO'), ('400', 'CD'), ('Thai', 'NNP'), ('travel', 'NN'), ('news', 'NN'), (',', ','), ('divided', 'VBD'), ('into', 'IN'), ('5', 'CD'), ('sets', 'NNS'), ('of', 'IN'), ('80', 'CD'), ('news', 'NN'), ('each', 'DT'), (',', ','), ('with', 'IN'), ('the', 'DT'), ('varied', 'JJ'), ('compression', 'NN'), ('rates', 'NNS'), ('of', 'IN'), ('20', 'CD'), ('%', 'NN'), (',', ','), ('30', 'CD'), ('%', 'NN'), ('and', 'CC'), ('40', 'CD'), ('%', 'NN'), ('.', '.'), ('From', 'IN'), ('this', 'DT'), ('experiment', 'NN'), (',', ','), ('the', 'DT'), ('best', 'JJS'), ('model', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('keyword', 'NN'), ('score', 'NN'), ('for', 'IN'), ('Thai', 'NNP'), ('travel', 'NN'), ('news', 'NN'), ('summarization', 'NN'), ('was', 'VBD'), ('SVD', 'NNP'), ('with', 'IN'), ('sentence', 'NN'), ('selection', 'NN'), ('by', 'IN'), ('Murray', 'NNP'), (',', ','), ('G.', 'NNP'), ('et', 'CC'), ('al', 'RB'), ('.', '.'), ('This', 'DT'), ('model', 'NN'), ('with', 'IN'), ('the', 'DT'), ('compression', 'NN'), ('rate', 'NN'), ('of', 'IN'), ('20', 'CD'), ('%', 'NN'), ('got', 'VBD'), ('the', 'DT'), ('highest', 'JJS'), ('score', 'NN'), ('because', 'IN'), ('Murray', 'NNP'), ('G.', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.'), ('method', 'NN'), ('determined', 'VBD'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('extracted', 'VBN'), ('from', 'IN'), ('each', 'DT'), ('concept', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('importance', 'NN'), ('of', 'IN'), ('that', 'DT'), ('concept', 'NN'), ('.', '.'), ('The', 'DT'), ('method', 'NN'), ('of', 'IN'), ('Gong', 'NNP'), (',', ','), ('Y.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('on', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('hand', 'NN'), ('was', 'VBD'), ('proposed', 'VBN'), ('to', 'TO'), ('select', 'VB'), ('only', 'RB'), ('one', 'CD'), ('sentence', 'NN'), ('with', 'IN'), ('the', 'DT'), ('highest', 'JJS'), ('score', 'NN'), ('from', 'IN'), ('each', 'DT'), ('concept', 'NN'), ('so', 'RB'), ('that', 'IN'), ('the', 'DT'), ('summary', 'NN'), ('would', 'MD'), ('include', 'VB'), ('CONCLUSIONS', 'NNP'), ('In', 'IN'), ('this', 'DT'), ('paper', 'NN'), (',', ','), ('we', 'PRP'), ('applied', 'VBD'), ('several', 'JJ'), ('text', 'JJ'), ('summarization', 'NN'), ('methods', 'NNS'), ('to', 'TO'), ('Thai', 'NNP'), ('Travel', 'NNP'), ('News', 'NNP'), ('based', 'VBN'), ('on', 'IN'), ('keyword', 'NN'), ('scored', 'VBN'), ('in', 'IN'), ('Thai', 'NNP'), ('language', 'NN'), ('by', 'IN'), ('extracting', 'VBG'), ('the', 'DT'), ('most', 'RBS'), ('relevant', 'JJ'), ('sentences', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('document', 'NN'), ('.', '.'), ('We', 'PRP'), ('compared', 'VBN'), ('LSA', 'NNP'), ('and', 'CC'), ('NMF', 'NNP'), ('together', 'RB'), ('with', 'IN'), ('different', 'JJ'), ('sentence', 'NN'), ('selection', 'NN'), ('methods', 'NNS'), (',', ','), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('algorithm', 'NN'), ('suitable', 'JJ'), ('with', 'IN'), ('this', 'DT'), (\"paper's\", 'NN'), ('data', 'VBZ'), ('source', 'NN'), ('.', '.'), ('We', 'PRP'), ('concluded', 'VBD'), ('that', 'IN'), ('keyword', 'NN'), ('scored', 'VBN'), ('calculation', 'NN'), ('by', 'IN'), ('LSA', 'NNP'), ('with', 'IN'), ('sentence', 'NN'), ('selection', 'NN'), ('by', 'IN'), ('Generic', 'NNP'), ('Sentence', 'NNP'), ('Relevance', 'NNP'), ('score', 'NN'), ('by', 'IN'), ('Murray', 'NNP'), (',', ','), ('G.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.'), ('was', 'VBD'), ('the', 'DT'), ('best', 'JJS'), ('algorithm', 'NN'), ('while', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('compression', 'NN'), ('rate', 'NN'), ('of', 'IN'), ('all', 'DT'), ('models', 'NNS'), ('was', 'VBD'), ('20', 'CD'), ('%', 'NN'), (',', ','), ('for', 'IN'), ('summarizing', 'VBG'), ('Thai', 'NNP'), ('Travel', 'NNP'), ('News', 'NNP'), ('compared', 'VBN'), ('with', 'IN'), ('humans', 'NNS'), ('.', '.'), ('In', 'IN'), ('future', 'JJ'), ('work', 'NN'), (',', ','), ('we', 'PRP'), ('plan', 'VBP'), ('to', 'TO'), ('perform', 'VB'), ('the', 'DT'), ('experiments', 'NNS'), ('with', 'IN'), ('different', 'JJ'), ('types', 'NNS'), ('of', 'IN'), ('documents', 'NNS'), ('and', 'CC'), ('improve', 'VB'), ('word', 'NN'), ('segmentation', 'NN'), ('of', 'IN'), ('compound', 'NN'), ('nouns', 'NNS'), ('that', 'WDT'), ('was', 'VBD'), ('not', 'RB'), ('handled', 'VBN'), ('by', 'IN'), ('Cutkum', 'NNP'), ('.', '.'), ('8', 'CD'), ('.', '.'), ('ACKNOWLEDGMENTS', 'IN'), ('We', 'PRP'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('thank', 'VB'), ('the', 'DT'), ('department', 'NN'), ('of', 'IN'), ('computer', 'NN'), ('engineering', 'NN'), (',', ','), ('faculty', 'NN'), ('of', 'IN'), ('engineering', 'NN'), (',', ','), ('Chulalongkorn', 'NNP'), ('University', 'NNP'), ('for', 'IN'), ('providing', 'VBG'), ('computing', 'VBG'), ('facilities', 'NNS'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import tokenize, stem, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Read text from TXT file\n",
        "with open('/content/paperThailand.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenize the text into sentences\n",
        "sentences = tokenize.sent_tokenize(text)\n",
        "print('Total sentences in the given text:', len(sentences))\n",
        "print(sentences)\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = tokenize.word_tokenize(text)\n",
        "print('Total words in the given text:', len(words))\n",
        "print(words)\n",
        "\n",
        "# Stemming using PorterStemmer\n",
        "stemmer = stem.PorterStemmer()\n",
        "stem_words = [stemmer.stem(word) for word in words]\n",
        "print('After stemming:', stem_words)\n",
        "\n",
        "# Lemmatization using WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemma_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "print('After lemmatization:', lemma_words)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "print('After removing stopwords:', filtered_words)\n",
        "\n",
        "# Part-of-speech tagging\n",
        "pos_tags = pos_tag(words)\n",
        "print('POS tags:', pos_tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import tokenize, stem, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import heapq\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Read text from TXT file\n",
        "with open('/content/paperThailand.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Preprocess the text\n",
        "sentences = tokenize.sent_tokenize(text)\n",
        "words = tokenize.word_tokenize(text)\n",
        "stemmer = stem.PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_word(word):\n",
        "    word = word.lower()\n",
        "    if word not in stop_words:\n",
        "        word = lemmatizer.lemmatize(word)\n",
        "        word = stemmer.stem(word)\n",
        "        return word\n",
        "    return None\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    processed_sentence = []\n",
        "    for word in tokenize.word_tokenize(sentence):\n",
        "        processed_word = preprocess_word(word)\n",
        "        if processed_word:\n",
        "            processed_sentence.append(processed_word)\n",
        "    return processed_sentence\n",
        "\n",
        "preprocessed_sentences = [preprocess_sentence(sentence) for sentence in sentences]\n",
        "\n",
        "# Text summarization using TF-IDF\n",
        "word_frequencies = {}\n",
        "for sentence in preprocessed_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "\n",
        "maximum_frequency = max(word_frequencies.values())\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word] / maximum_frequency\n",
        "\n",
        "sentence_scores = {}\n",
        "for i, sentence in enumerate(preprocessed_sentences):\n",
        "    score = 0\n",
        "    for word in sentence:\n",
        "        if word in word_frequencies.keys():\n",
        "            score += word_frequencies[word]\n",
        "    sentence_scores[i] = score\n",
        "\n",
        "summary_sentences = heapq.nlargest(3, sentence_scores, key=sentence_scores.get)\n",
        "summary = [sentences[i] for i in summary_sentences]\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary:\")\n",
        "for sentence in summary:\n",
        "    print(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOwDS8D1vG_Q",
        "outputId": "254cb335-f60d-487d-cb5f-119ce8289c50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "Thai text summarization efficiency of 5 models\n",
            "Figure 2 shows the Thai text summarization efficiency of 5 models:\n",
            "(1) NMF with GRS, (2) NMF with K-means, (3) SVD with sentence\n",
            "score by Gong, Y. et al., (4) SVD with K-means, and (5) SVD with\n",
            "sentence score by Murray, G. et al.\n",
            "From\n",
            "their experiments, the summarization of the industrial news got\n",
            "60% precision, 44% recall, and 50.9% F-measure, the general news\n",
            "got the 51.8% precision, 38.5% recall, and 43.1% F-measure while\n",
            "the fashion magazines got 53.0% precision, 33.0% recall, and\n",
            "40.4% F-measure.\n",
            "S1\n",
            "\n",
            "3.6\n",
            "\n",
            "A∙B\n",
            "=\n",
            "n\n",
            "n\n",
            "||A|| ||B||\n",
            "�∑i=1\n",
            "A2i �∑i=1\n",
            "Bi2\n",
            "\n",
            "(6)\n",
            "\n",
            "Mr.Yontas\n",
            "ak\n",
            "\n",
            "1\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "Supason\n",
            "\n",
            "1\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "Tourism\n",
            "Authority\n",
            "of Thailand\n",
            "\n",
            "1\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "0\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "…\n",
            "\n",
            "\fTable 3 demonstrates an example of a matrix 𝐴𝐴, constructed from\n",
            "word count by sentence of a Thai travel news.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import tokenize, stem, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import heapq\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Read text from TXT file\n",
        "with open('/content/paperThailand.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Preprocess the text\n",
        "sentences = tokenize.sent_tokenize(text)\n",
        "words = tokenize.word_tokenize(text)\n",
        "stemmer = stem.PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_word(word):\n",
        "    word = word.lower()\n",
        "    if word not in stop_words:\n",
        "        word = lemmatizer.lemmatize(word)\n",
        "        word = stemmer.stem(word)\n",
        "        return word\n",
        "    return None\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    processed_sentence = []\n",
        "    for word in tokenize.word_tokenize(sentence):\n",
        "        processed_word = preprocess_word(word)\n",
        "        if processed_word:\n",
        "            processed_sentence.append(processed_word)\n",
        "    return processed_sentence\n",
        "\n",
        "preprocessed_sentences = [preprocess_sentence(sentence) for sentence in sentences]\n",
        "\n",
        "# Text summarization using TF-IDF\n",
        "word_frequencies = {}\n",
        "for sentence in preprocessed_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "\n",
        "maximum_frequency = max(word_frequencies.values())\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word] / maximum_frequency\n",
        "\n",
        "sentence_scores = {}\n",
        "for i, sentence in enumerate(preprocessed_sentences):\n",
        "    score = 0\n",
        "    for word in sentence:\n",
        "        if word in word_frequencies.keys():\n",
        "            score += word_frequencies[word]\n",
        "    sentence_scores[i] = score\n",
        "\n",
        "summary_sentences = heapq.nlargest(3, sentence_scores, key=sentence_scores.get)\n",
        "summary = [sentences[i] for i in summary_sentences]\n",
        "\n",
        "# Save preprocessed text and summary to a new file\n",
        "preprocessed_filename = 'preprocessed_text.txt'\n",
        "summary_filename = 'summary.txt'\n",
        "\n",
        "# Save preprocessed text\n",
        "with open(preprocessed_filename, 'w') as file:\n",
        "    for sentence in preprocessed_sentences:\n",
        "        file.write(' '.join(sentence))\n",
        "        file.write('\\n')\n",
        "\n",
        "# Save summary\n",
        "with open(summary_filename, 'w') as file:\n",
        "    for sentence in summary:\n",
        "        file.write(sentence)\n",
        "        file.write('\\n')\n",
        "\n",
        "print(\"Preprocessed text saved to:\", preprocessed_filename)\n",
        "print(\"Summary saved to:\", summary_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNsbiu207rkC",
        "outputId": "20962780-6ac0-444d-b070-5aff0243be35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed text saved to: preprocessed_text.txt\n",
            "Summary saved to: summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}