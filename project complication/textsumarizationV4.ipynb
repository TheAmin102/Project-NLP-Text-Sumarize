{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTDsv6LlMBcb",
        "outputId": "569bc5c4-0c88-49eb-e4dc-7e09018c1ab8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\miki\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\miki\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# !pip install nltk bs4\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LMtRwIOOMCR3"
      },
      "outputs": [],
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "article = \"ABSTRACT In recent years, people are seeking for a solution to improve text summarization for Thai language. Although several solutions such as PageRank, Graph Rank, Latent Semantic Analysis (LSA) models, etc., have been proposed, research results in Thai text summarization were restricted due to limited corpus in Thai language with complex grammar. This paper applied a text summarization system for Thai travel news based on keyword scored in Thai language by extracting the most relevant sentences from the original document. We compared LSA and Non-negative Matrix Factorization (NMF) to find the algorithm that is suitable with Thai travel news. The suitable compression rates for Generic Sentence Relevance score (GRS) and K-means clustering were also evaluated. From these experiments, we concluded that keyword scored calculation by LSA with sentence selection by GRS is the best algorithm for summarizing Thai Travel News, compared with human with the best compression rate of 20%. CCS Concepts • Information systems ➝ Information retrieval ➝ Retrieval tasks and goals➝ Summarization Keywords Text summarization; extractive summarization; non-negative matrix factorization 1. INTRODUCTION Daily newspaper has abundant of text that users do not have enough time for reading them. It is difficult to identify the relevant information to satisfy the information needed by users. Automatic summarization can reduce the problem of information overloading and it has been proposed previously in English and other languages. However, there were only a few research results in Thai text summarization due to the lack of corpus in Thai language and the complicated grammar. Text Summarization [1] is a technique for summarizing the content of the documents. It consists of three steps: 1) create an intermediate representation of the input text, 2) calculate score for the sentences based on the concepts, and 3) choose important sentences to be included in the summary. Text summarization can be divided into 2 approaches. The first approach is the extractive summarization, which relies on a method for extracting words and searching for keywords from the original document. The second approach is the abstractive summarization, which analyzes words by linguistic principles with transcription or interpretation from the original document. This approach implies more effective and accurate summary than the extractive methods. However, with the lack of Thai corpus, we chose to apply an extractive summarization method for Thai text summarization. This research focused on the sentence extraction function based on keyword score calculation then selecting important sentences based on the Generic Sentence Relevance score (GRS), calculated from Latent Semantic Analysis (LSA) and Non-negative Matrix Factorization (NMF). We also tried using K-means clustering for document summarization. In this experiment, we compared 5 models for 5 rounds with Thai travel news using the compression rates of 20%, 30% and 40% and reported the rate and method that produced the best result from the experiment. 2. RELATED WORKS In recent years, several models in Thai Text summarization have been introduced. Suwanno, N. et al. [2] proposed a Thai text summarization that extracted a paragraph from a document based on Thai compound nouns, term frequency method, and headline score for generating a summary. Chongsuntornsri\"\n",
        "\n",
        "parsed_article = bs.BeautifulSoup(article, 'lxml')\n",
        "\n",
        "# Removing Square Brackets and Extra Spaces\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', parsed_article.get_text())\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)\n",
        "\n",
        "# Removing special characters and digits\n",
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text)\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5quedjgMG-7",
        "outputId": "b45277ed-d140-4657-e595-964d83cd1394"
      },
      "outputs": [],
      "source": [
        "# Download the stopwords resource\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "\n",
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0urEVA9MJTE",
        "outputId": "366a7a4f-ff79-482e-ab7e-d76aa6269e05"
      },
      "outputs": [],
      "source": [
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "\n",
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]\n",
        "\n",
        "import heapq\n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
