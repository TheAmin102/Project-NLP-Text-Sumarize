{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Abstractive Text Summarization**\n",
        "\n",
        "Model: The updated code utilizes the T5 model for abstractive text summarization. T5 (Text-To-Text Transfer Transformer) is a Transformer-based model developed by Google Research. It has been pre-trained on a large corpus of text and fine-tuned on various downstream tasks, including text summarization.\n",
        "\n",
        "Library: The code utilizes the Hugging Face transformers library, which is a powerful library for working with pre-trained Transformer models. It provides an easy-to-use interface for loading pre-trained models, tokenization, and text generation.\n",
        "\n",
        "Approach: The approach used in the code is a pipeline-based approach provided by the transformers library. The pipeline class simplifies the process of using pre-trained models for various natural language processing tasks, including text summarization. Specifically, the pipeline class provides a convenient API for abstractive text summarization using the T5 model.\n",
        "\n",
        "The code initializes the T5 model and tokenizer using the T5ForConditionalGeneration and T5Tokenizer classes, respectively, from the transformers library. It then uses the pipeline class with the \"summarization\" task to perform text summarization. The pipeline internally handles the tokenization, model loading, and text generation process, making it straightforward to generate summaries.\n",
        "\n",
        "By leveraging the T5 model, the transformers library, and the pipeline-based approach, the code achieves abstractive text summarization in a concise and efficient manner."
      ],
      "metadata": {
        "id": "RWxaLHMN7rhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REF\n",
        "# https://github.com/rojagtap/abstractive_summarizer/tree/master"
      ],
      "metadata": {
        "id": "4v8rzUCX70vY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "scJ1oVWapSvq"
      },
      "outputs": [],
      "source": [
        "# Modifications Copyright (C) 2020 Rohan Jagtap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zbxhyl_zFlWL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## TO FIX BadZipFile: File is not a zip . source: https://stackoverflow.com/questions/3083235/unzipping-file-results-in-badzipfile-file-is-not-a-zip-file\n",
        "\n",
        "# def fixBadZipfile(zipFile):\n",
        "#     with open(zipFile, 'r+b') as f:\n",
        "#         data = f.read()\n",
        "#         pos = data.find(b'\\x50\\x4b\\x05\\x06')  # End of central directory signature\n",
        "#         if pos > 0:\n",
        "#             print(\"Truncating file at location\", pos + 22)\n",
        "#             f.seek(pos + 22)  # size of 'ZIP end of central directory record'\n",
        "#             f.truncate()\n",
        "#         else:\n",
        "#             raise Exception(\"File is truncated.\")\n"
      ],
      "metadata": {
        "id": "Cjl4k1HRsFfO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH5cg5pSIHaZ"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K_AjGkWXITKA"
      },
      "outputs": [],
      "source": [
        "news = pd.read_excel(\"news.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S-rYZhayIe9x"
      },
      "outputs": [],
      "source": [
        "news.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oXtxc-toIc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "faa0d603-9be3-44df-a549-0e13f1e26af6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Headline  \\\n",
              "0  4 ex-bank officials booked for cheating bank o...   \n",
              "1     Supreme Court to go paperless in 6 months: CJI   \n",
              "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
              "3  Why has Reliance been barred from trading in f...   \n",
              "4  Was stopped from entering my own studio at Tim...   \n",
              "\n",
              "                                               Short  \n",
              "0  The CBI on Saturday booked four former officia...  \n",
              "1  Chief Justice JS Khehar has said the Supreme C...  \n",
              "2  At least three people were killed, including a...  \n",
              "3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
              "4  TV news anchor Arnab Goswami has said he was t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-469cba42-cd72-4c7d-98cb-56ff0c58c5ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Short</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
              "      <td>The CBI on Saturday booked four former officia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
              "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
              "      <td>At least three people were killed, including a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why has Reliance been barred from trading in f...</td>\n",
              "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Was stopped from entering my own studio at Tim...</td>\n",
              "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-469cba42-cd72-4c7d-98cb-56ff0c58c5ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-469cba42-cd72-4c7d-98cb-56ff0c58c5ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-469cba42-cd72-4c7d-98cb-56ff0c58c5ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vR2hg9themaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201b02f8-c046-4c16-a68e-418a86339448"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "news.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d4cEp3wmI2BX"
      },
      "outputs": [],
      "source": [
        "document = news['Short']\n",
        "summary = news['Headline']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2z55AhpKIdK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50773636-82c5-4665-cebd-3d4276b22e1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('According to the Guinness World Records, the most generations alive in a single family have been seven.  The difference between the oldest and the youngest person in the family was about 109 years, when Augusta Bunge&#39;s great-great-great-great grandson was born on January 21, 1989. The family belonged to the United States of America.',\n",
              " 'The most generations alive in a single family have been 7')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "document[30], summary[30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8gKyq1gIq4r"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TJ6LE4MrJjC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03af1eb6-8d12-46d7-e870-ae97a5ba58e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    <go> 4 ex-bank officials booked for cheating b...\n",
              "1    <go> Supreme Court to go paperless in 6 months...\n",
              "2    <go> At least 3 killed, 30 injured in blast in...\n",
              "3    <go> Why has Reliance been barred from trading...\n",
              "4    <go> Was stopped from entering my own studio a...\n",
              "Name: Headline, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# for decoder sequence\n",
        "summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
        "summary.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Zv7FIvKbTi"
      },
      "source": [
        "#### Tokenizing the texts into integer tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7TqbpEyPMRqa"
      },
      "outputs": [],
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cHw2csoYImsa"
      },
      "outputs": [],
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DWU9Xu7OKVab"
      },
      "outputs": [],
      "source": [
        "document_tokenizer.fit_on_texts(document)\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3ESm-aYR-tvx"
      },
      "outputs": [],
      "source": [
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kVyErXAei5_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866492c2-af80-497e-8025-f1d10b9c111f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[184, 22, 12, 71]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "summary_tokenizer.texts_to_sequences([\"This is a test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ryx9qx90jwXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97309f63-bde4-4b57-d3b1-9e63cdf4ca5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is a test']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "summary_tokenizer.sequences_to_texts([[184, 22, 12, 71]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KoizyBvLKv8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1809ba7-c9ee-4155-ed9e-121f8e69ad21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76362, 29661)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZden_q9_eZr"
      },
      "source": [
        "#### Obtaining insights on lengths for defining maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ma4o2nGdK5Xb"
      },
      "outputs": [],
      "source": [
        "document_lengths = pd.Series([len(x) for x in document])\n",
        "summary_lengths = pd.Series([len(x) for x in summary])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iXZlO99C-UXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c048b44f-97ea-4a1f-e6ec-5774c97430b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean       368.003049\n",
              "std         26.235510\n",
              "min        280.000000\n",
              "25%        350.000000\n",
              "50%        369.000000\n",
              "75%        387.000000\n",
              "max        469.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "document_lengths.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ALMwKMx--ZF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae36413-6245-4504-85ec-3286f0635e1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean        63.620282\n",
              "std          7.267463\n",
              "min         20.000000\n",
              "25%         59.000000\n",
              "50%         63.000000\n",
              "75%         69.000000\n",
              "max         96.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "summary_lengths.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cVeMilXr-bpC"
      },
      "outputs": [],
      "source": [
        "# maxlen\n",
        "# taking values > and round figured to 75th percentile\n",
        "# at the same time not leaving high variance\n",
        "encoder_maxlen = 400\n",
        "decoder_maxlen = 75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SWap3YJBk-D"
      },
      "source": [
        "#### Padding/Truncating sequences for identical sequence lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vEyUBeu7ACRt"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIP0kIIcB8Rm"
      },
      "source": [
        "### Creating dataset pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LzO6l3-AB7hJ"
      },
      "outputs": [],
      "source": [
        "inputs = tf.cast(inputs, dtype=tf.int32)\n",
        "targets = tf.cast(targets, dtype=tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "slZ5f4P4DurS"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wI-fV7eABWN6"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isN1CpAXLfsl"
      },
      "source": [
        "### Positional Encoding for adding notion of position among words as unlike RNN this is non-directional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Purv7oyhETDZ"
      },
      "outputs": [],
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "40J2pc2NEXp5"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Pe01DMMWHc"
      },
      "source": [
        "### Masking\n",
        "\n",
        "- Padding mask for masking \"pad\" sequences\n",
        "- Lookahead mask for masking future words from contributing in prediction of current words in self attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hN1wVQAdMVYy"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UmjAPLWuMREE"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8DqUBc4NFOy"
      },
      "source": [
        "### Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfknVF7hNKf7"
      },
      "source": [
        "#### Scaled Dot Product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "w_B6M9OBNBKB"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf7_a5uQOfJk"
      },
      "source": [
        "#### Multi-Headed Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iIuFrdXnNZEC"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A49tXMVvOkOZ"
      },
      "source": [
        "### Feed Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "d9-qoKuTNwKq"
      },
      "outputs": [],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2RRmn2bOpW9"
      },
      "source": [
        "#### Fundamental Unit of Transformer encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HNuoJoFWO335"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i6Zh8gnPqdW"
      },
      "source": [
        "#### Fundamental Unit of Transformer decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7CVmvs6dPMRC"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zt5MUc_QNid"
      },
      "source": [
        "#### Encoder consisting of multiple EncoderLayer(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BrbnTwijQJ-h"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N5LrNrvRexg"
      },
      "source": [
        "#### Decoder consisting of multiple DecoderLayer(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "UmeqkZrIRbSB"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        return x, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbMNK_bzSHnh"
      },
      "source": [
        "#### Finally, the Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "FXHRG-o4R9Mc"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UndsMPZXTdSr"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "lMTZJdIoSbuy"
      },
      "outputs": [],
      "source": [
        "# hyper-params\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOGvkYDNTjIj"
      },
      "source": [
        "#### Adam optimizer with custom learning rate scheduling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "tfiynCLlTL8C"
      },
      "outputs": [],
      "source": [
        "# class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "#     def __init__(self, d_model, warmup_steps=4000):\n",
        "#         super(CustomSchedule, self).__init__()\n",
        "\n",
        "#         self.d_model = d_model\n",
        "#         self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "#         self.warmup_steps = warmup_steps\n",
        "\n",
        "#     def __call__(self, step):\n",
        "#         arg1 = tf.math.rsqrt(step)\n",
        "#         arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "#         return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsVdrENTUERY"
      },
      "source": [
        "#### Defining losses and other metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####   DEBUG ####\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)  # Convert d_model to float32\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # Convert step to float32\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "Z2BaggfQr3r-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Ip1-943kTXXK"
      },
      "outputs": [],
      "source": [
        "# ### REPLACED BY ABOVE CODE ###\n",
        "\n",
        "# learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ktKwyvKtTvF6"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "uW4LA_45T4Aa"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Ze0u6xxXT7dI"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XvKy3v6ULnO"
      },
      "source": [
        "#### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "d5-RcxqFUCuk"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers,\n",
        "    d_model,\n",
        "    num_heads,\n",
        "    dff,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    pe_input=encoder_vocab_size,\n",
        "    pe_target=decoder_vocab_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f56BGiVXU_Dk"
      },
      "source": [
        "#### Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "FZxHuyZxU5Pa"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYIotvaBVI0d"
      },
      "source": [
        "#### Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "tOc1_3c-VGaL"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfpI0gS4c06c"
      },
      "source": [
        "#### Training steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "xmVOMzkrczgl"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp,\n",
        "            True,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####   DEBUG ####\n",
        "\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n"
      ],
      "metadata": {
        "id": "iWow8k5WxkA8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xORKpv69dSW5"
      },
      "outputs": [],
      "source": [
        "# ###REPLACED BY ABOVE CODE\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#     start = time.time()\n",
        "\n",
        "#     train_loss.reset_states()\n",
        "\n",
        "#     for (batch, (inp, tar)) in enumerate(dataset):\n",
        "#         train_step(inp, tar)\n",
        "\n",
        "#         # 55k samples\n",
        "#         # we display 3 batch results -- 0th, middle and last one (approx)\n",
        "#         # 55k / 64 ~ 858; 858 / 2 = 429\n",
        "#         if batch % 429 == 0:\n",
        "#             print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
        "\n",
        "#     if (epoch + 1) % 5 == 0:\n",
        "#         ckpt_save_path = ckpt_manager.save()\n",
        "#         print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "#     print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
        "\n",
        "#     print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVbEUCZagJ0G"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMbqGTixu1cl"
      },
      "source": [
        "#### Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "F5D5cv2Jd8-6"
      },
      "outputs": [],
      "source": [
        "def evaluate(input_document):\n",
        "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "UkpdiW6wnmiS"
      },
      "outputs": [],
      "source": [
        "# def summarize(input_document):\n",
        "#     # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
        "#     summarized = evaluate(input_document=input_document)[0].numpy()\n",
        "#     summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
        "#     return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####   DEBUG ####\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = tf.cast(x, tf.int32)  # Convert x to int32\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "4EuMZsCNyDaq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece transformers ####   DEBUG ####"
      ],
      "metadata": {
        "id": "zaW4WuMWzvFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77db9ae-1259-4f0f-c2ee-78fcd0cc0d3e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####   DEBUG ####\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "metadata": {
        "id": "b3rdTpngzI6P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "referenced_widgets": [
            "8d0c235d4ae2458d846b0921a0a586c1",
            "e61e16740e5148ecb4f4193eb02fd10c",
            "8f043cd19247459797310119ced2cf3c",
            "e0c535d8f8f545459fce404e7a5858d7",
            "e8cdafede2ff42378bdfb79ae6c8fbba",
            "d383bbf0a4eb40f1974f8a171f70dc44",
            "694173cd7fa24ca68e8035e2e8ce8956",
            "2db54c961ee244daa6ae37420e272776",
            "12cc253ca5f942d18b08ff83f4855631",
            "4f79ab839e864f629f6a60f4d31e759b",
            "535d9e7a99e84e7aba4cd6d8522fbfd9",
            "b555d0c8ce6544c4a96b77aedd68eab4",
            "e7a200cbff844570a869a38e788ed923",
            "218dc8d33a3842ccbf4144dada69e8d4",
            "9095d8a090484ee7a5090bcce827cf9c",
            "37377f53cf2947cfb89e1377097e6be2",
            "7a1c774087d241d5b9cfa47304946d34",
            "68d74726a0fa4160b7df548ded43fef9",
            "1cd06519af0b4483b7dcbc7b014b352e",
            "4fb8f311d88540619cbf2a758bc55a07",
            "0421cf63e05d416faa251284c64da27c",
            "e4a50a177891485dafc1fb86ed333403"
          ]
        },
        "outputId": "6d619b2e-27de-4be9-8a2f-b892ba310975"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading ()ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d0c235d4ae2458d846b0921a0a586c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading ()lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b555d0c8ce6544c4a96b77aedd68eab4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load the T5 tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "\n",
        "def summarize(text):\n",
        "    # Tokenize the input text\n",
        "    tokenized_text = tokenizer.encode(text, truncation=True, max_length=400, padding='longest')\n",
        "\n",
        "    # Convert the tokenized text to a tensor\n",
        "    input_text = torch.tensor([tokenized_text])\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(input_text, num_beams=4, max_length=200, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Check the length of the summary and generate a new summary if it's too short\n",
        "    while len(summary.split()) < 120:\n",
        "        summary_ids = model.generate(input_text, num_beams=4, max_length=200, early_stopping=True)\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example usage\n",
        "text = \"\"\"\n",
        "In recent years, people are seeking for a solution to improve text\n",
        "summarization for Thai language. Although several solutions such\n",
        "as PageRank, Graph Rank, Latent Semantic Analysis (LSA)\n",
        "models, etc., have been proposed, research results in Thai text\n",
        "summarization were restricted due to limited corpus in Thai\n",
        "language with complex grammar. This paper applied a text\n",
        "summarization system for Thai travel news based on keyword\n",
        "scored in Thai language by extracting the most relevant sentences\n",
        "from the original document. We compared LSA and Non-negative\n",
        "Matrix Factorization (NMF) to find the algorithm that is suitable\n",
        "with Thai travel news. The suitable compression rates for Generic\n",
        "Sentence Relevance score (GRS) and K-means clustering were also\n",
        "evaluated. From these experiments, we concluded that keyword\n",
        "scored calculation by LSA with sentence selection by GRS is the\n",
        "best algorithm for summarizing Thai Travel News, compared with\n",
        "human with the best compression rate of 20%.\n",
        "\n",
        "Daily newspaper has abundant of data that users do not have\n",
        "enough time for reading them. It is difficult to identify the relevant\n",
        "information to satisfy the information needed by users. Automatic\n",
        "summarization can reduce the problem of information overloading\n",
        "and it has been proposed previously in English and other languages.\n",
        "However, there were only a few research results in Thai text\n",
        "summarization due to the lack of corpus in Thai language and the\n",
        "complicated grammar.\n",
        "Text Summarization [1] is a technique for summarizing the content\n",
        "of the documents. It consists of three steps: 1) create an\n",
        "intermediate representation of the input text, 2) calculate score for\n",
        "the sentences based on the concepts, and 3) choose important sentences\n",
        "to be included in the summary. Text summarization can\n",
        "be divided into 2 approaches. The first approach is the extractive\n",
        "summarization, which relies on a method for extracting words and\n",
        "searching for keywords from the original document. The second\n",
        "approach is the abstractive summarization, which analyzes words\n",
        "by linguistic principles with transcription or interpretation from the\n",
        "original document. This approach implies more effective and\n",
        "accurate summary than the extractive methods. However, with the\n",
        "lack of Thai corpus, we chose to apply an extractive summarization\n",
        "method for Thai text summarization.\n",
        "This research focused on the sentence extraction function based on\n",
        "keyword score calculation then selecting important sentences based\n",
        "on the Generic Sentence Relevance score (GRS), calculated from\n",
        "Latent Semantic Analysis (LSA) and Non-negative Matrix\n",
        "Factorization (NMF). We also tried using K-means clustering for\n",
        "document summarization. In this experiment, we compared 5\n",
        "models for 5 rounds with Thai travel news using the compression\n",
        "rates of 20%, 30% and 40% and reported the rate and method that\n",
        "produced the best result from the experiment.\n",
        "\n",
        "In recent years, several models in Thai Text summarization have\n",
        "been introduced. Suwanno, N. et al. [2] proposed a Thai text\n",
        "summarization that extracted a paragraph from a document based\n",
        "on Thai compound nouns, term frequency method, and headline\n",
        "score for generating a summary. Chongsuntornsri, A., et al. [3]\n",
        "proposed a new approach for Text summarization in Thai based on\n",
        "content- and graph-based with the use of Topic Sensitive PageRank\n",
        "algorithm for summarizing and ranking of text segments.\n",
        "Jaruskulchai C., et al. [4] proposed a method to summarize\n",
        "documents by extracting important sentences from combining the\n",
        "specific properties (Local Property) and the overall properties\n",
        "(Global Property) of the sentences. The overall properties were\n",
        "based on the relationship between sentences in the document. From\n",
        "their experiments, the summarization of the industrial news got\n",
        "60% precision, 44% recall, and 50.9% F-measure, the general news\n",
        "got the 51.8% precision, 38.5% recall, and 43.1% F-measure while\n",
        "the fashion magazines got 53.0% precision, 33.0% recall, and\n",
        "40.4% F-measure.\n",
        "Mani, I., et al. [5] proposed techniques of text summarization by\n",
        "using word frequency in the document and calculated the weight of\n",
        "word to create a keyword group. They then calculated the cosine\n",
        "similarity of sentences. The researcher used A* search algorithm to\n",
        "find the shortest sequence of sentences from keyword group by\n",
        "topic calculation, sentence segmentation and word grouping. The\n",
        "sequence of sentences that were in the main group were selected as\n",
        "important sentences. Their summarization of the agricultural news\n",
        "got 68.57% precision, 51.95% recall and 56.72% F-measure.\n",
        "Lee, J., et al. [6] proposed a document summarization method using\n",
        "Non-negative Matrix Factorization (NMF). They compared\n",
        "between Latent Semantic Analysis (LSA) and NMF to find the\n",
        "weight of each word and calculated the summation of weights. The\n",
        "important sentences were ranked and selected into the summary\n",
        "based on their summed weight. Based on LSA, they found many\n",
        "weights with zero and negative values. However, when applied\n",
        "NMF, they found only the positive values and the scope of the\n",
        "semantic features meaning was narrow. Therefore, they proposed\n",
        "that NMF provided a greater possibility for extracting important\n",
        "sentences.\n",
        "\n",
        "The first step for working with Thai Text is word tokenization. Even\n",
        "though Thai writing system has no delimiters to indicate word\n",
        "boundaries together with many rules for word segmentation, several\n",
        "Thai word tokenization programs have been proposed. Table 1\n",
        "shows F1 score of the recent programs trained and tested by one of\n",
        "our laboratory members with the data from BEST2010 corpus [7].\n",
        "Cutkum [8] got the highest F1 score, hence, we used Cutkum for this\n",
        "step.\n",
        "\n",
        "Latent Semantic Analysis (LSA) [14] is the algorithm, which\n",
        "reduces the dimensionality of term document. The algorithm\n",
        "creates a matrix by using word frequency, applies the singular value\n",
        "decomposition (SVD) [15], and then finds closely related terms and\n",
        "documents. The original matrix A can be separated into three\n",
        "matrices, where U is the m x r (words x extracted concept) matrix,\n",
        "V is the n x r (sentences x extracted concepts) matrix, and  is the\n",
        "r x r diagonal matrix, which can be reconstructed to find the original\n",
        "matrix A.\n",
        "\n",
        "For sentence selection by K-means clustering, we grouped similar\n",
        "sentences into the same cluster using the following steps:\n",
        "1. Randomly select K sentences as the representative of K\n",
        "groups. K in this paper is the number of sentences that\n",
        "will be selected into the summary.\n",
        "2. Calculate centroid of each group by using the value of\n",
        "sentence vector from V matrix for LSA and  matrix\n",
        "for NMF.\n",
        "3. Use cosine similarity to calculate sentence similarity\n",
        "between a sentence and the centroid of each group. Then\n",
        "assign that sentence to the group with the highest\n",
        "similarity.\n",
        "4. Repeat steps 2-3 until all sentences are assigned to a\n",
        "group, no sentences change the group, or the similarity\n",
        "between sentences and their centroid is close.\n",
        "5. Select a sentence with the maximum similarity score with\n",
        "the centroid of the group and add it into the summary.\n",
        "\n",
        "The standard data sets in Thai language are unavailable for\n",
        "evaluating text summarization system. Therefore, we collected 400\n",
        "Thai travel news from Thairath and Manager online newspapers to\n",
        "be used as datasets for our experiments. We split 400 travel news\n",
        "into 5 sets of 80 news each. We then evaluated the performance of\n",
        "text summarization methods which were LSA and NMF by\n",
        "comparing their results with the summaries manually curated by\n",
        "two experts from the Faculty of Liberal Arts, Ubon Ratchathani\n",
        "University.\n",
        "\n",
        "The open-source python libraries such as numpy [19] and sklearn\n",
        "[20] were used in our system. We converted the Thai travel news\n",
        "obtained from Thairath and Manager online newspapers to plain\n",
        "text. Then, the sentences of each news were segmented by human\n",
        "with the following format: Si = xxx, where Si represents the order\n",
        "of the sentence in the original document and xxx represents the\n",
        "content of that sentence. After removing stop words and duplicate\n",
        "words, we built a document term matrix or matrix A then applied\n",
        "SVD and NMF to the matrix. Then, we used python modules\n",
        "numpy.linalg.svd to calculate SVD and sklearn.decomposition to\n",
        "calculate NMF. For sentence selection, we used Gong, Y. et al. and\n",
        "Murray, G. et al. approaches for calculating weight of the sentence\n",
        "scores then selected sentences with the highest scores into the\n",
        "summary. For keyword score calculation of NMF, we calculated\n",
        "the keyword score from Eq. (5) and then selected the sentence with\n",
        "the highest score from each concept. The python module\n",
        "sklearn.cluster was used for K-means clustering. The selected\n",
        "sentences from all approaches were in the same order as the original\n",
        "document. In this paper, we performed the 20%, 30% and 40%\n",
        "document compression. This meant 80%, 70% and 60% of the\n",
        "sentences will be selected into the summary.\n",
        "\n",
        "Table 3 demonstrates an example of a matrix , constructed from\n",
        "word count by sentence of a Thai travel news. It was composed of\n",
        "98 words and 9 sentences. This matrix  was then applied with the\n",
        "LSA and NMF. The sentence vectors were calculated from the term\n",
        "weight and the semantic feature vectors from Eq. (1) for LSA and\n",
        "Eq. (2) for NMF\n",
        "\n",
        "We evaluated the results of the summarization by using standard\n",
        "accuracy, precision, recall, and F1 score [21]. These measurements\n",
        "quantify the differences between the summary from human and the\n",
        "experimental methods. The precision shows the correctness of the\n",
        "extracted sentences and the recall reflects the number of good\n",
        "sentences missed by the method.\n",
        "\n",
        "In this experimental set, we would like to explore how the different\n",
        "sentence selection methods: the Generic Sentence Relevance score\n",
        "and K-means clustering, affected the text summarization result.\n",
        "For K-means clustering, both SVD and NMF had similar\n",
        "summarization efficiency. The F1 score of SVD with K-means\n",
        "clustering was 0.83, 0.72, and 0.62 for the compression rate of 20%,\n",
        "30%, and 40%. For the NMF with K-means clustering, the F1 score\n",
        "for the three compression rates was 0.83, 0.74 and 0.64.\n",
        "For the Generic Sentence Relevance score, the best F1 score for the\n",
        "compression rate of 20%, 30%, and 40% was 0.86, 0.78 and 0.68\n",
        "respectively and the best F1 scores for all compression rates were\n",
        "from the approach of Murray, G. et al.\n",
        "\n",
        "Figure 2 shows the Thai text summarization efficiency of 5 models:\n",
        "(1) NMF with GRS, (2) NMF with K-means, (3) SVD with sentence\n",
        "score by Gong, Y. et al., (4) SVD with K-means, and (5) SVD with\n",
        "sentence score by Murray, G. et al. applied to 400 Thai travel news,\n",
        "divided into 5 sets of 80 news each, with the varied compression\n",
        "rates of 20%, 30% and 40%.\n",
        "From this experiment, the best model based on keyword score for\n",
        "Thai travel news summarization was SVD with sentence selection\n",
        "by Murray, G. et al. This model with the compression rate of 20%\n",
        "got the highest score because Murray G. et al. method determined\n",
        "the number of sentences to be extracted from each concept based on\n",
        "the importance of that concept. The method of Gong, Y. et al., on\n",
        "the other hand was proposed to select only one sentence with the\n",
        "highest score from each concept so that the summary would include\n",
        "sentences from all concepts. The Generic Sentence Relevance score\n",
        "for NMF also collected one sentence for each concept, the same as\n",
        "Gong, Y. et al. but with the highest score calculated by Eq. (5). As\n",
        "multiple important sentences could be selected from a more\n",
        "important concept, Murray, G. et al. outperformed both Gong, Y. et\n",
        "al. and the GRS method.\n",
        "\n",
        "In this paper, we applied several text summarization methods to\n",
        "Thai Travel News based on keyword scored in Thai language by\n",
        "extracting the most relevant sentences from the original document.\n",
        "We compared LSA and NMF together with different sentence\n",
        "selection methods, to find the algorithm suitable with this paper's\n",
        "data source. We concluded that keyword scored calculation by LSA\n",
        "with sentence selection by Generic Sentence Relevance score by\n",
        "Murray, G. et al. was the best algorithm while the best compression\n",
        "rate of all models was 20%, for summarizing Thai Travel News\n",
        "compared with humans.\n",
        "In future work, we plan to perform the experiments with different\n",
        "types of documents and improve word segmentation of compound\n",
        "nouns that was not handled by Cutkum.\n",
        "\n",
        "We would like to thank the department of computer engineering,\n",
        "faculty of engineering, Chulalongkorn University for providing\n",
        "computing facilities.\n",
        "\"\"\"\n",
        "\n",
        "summary = summarize(text)\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "ACcEZFb8K4Xp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "e42010e1-9462-4ffa-bcba-c6346e7c1895"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-4cf4e51f0bd0>\u001b[0m in \u001b[0;36m<cell line: 251>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m \"\"\"\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-4cf4e51f0bd0>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Convert the tokenized text to a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Generate the summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####   DEBUG ####\n",
        "def summarize(text):\n",
        "    # Tokenize the input text\n",
        "    tokenized_text = tokenizer.encode(text, truncation=True, max_length=400, padding='longest')\n",
        "\n",
        "    # Convert the tokenized text to a tensor\n",
        "    input_text = tf.convert_to_tensor([tokenized_text])\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(input_text, num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "bcpLfKAKygOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "id": "CBSHOCK93Xm5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d0c235d4ae2458d846b0921a0a586c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e61e16740e5148ecb4f4193eb02fd10c",
              "IPY_MODEL_8f043cd19247459797310119ced2cf3c",
              "IPY_MODEL_e0c535d8f8f545459fce404e7a5858d7"
            ],
            "layout": "IPY_MODEL_e8cdafede2ff42378bdfb79ae6c8fbba"
          }
        },
        "e61e16740e5148ecb4f4193eb02fd10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d383bbf0a4eb40f1974f8a171f70dc44",
            "placeholder": "",
            "style": "IPY_MODEL_694173cd7fa24ca68e8035e2e8ce8956",
            "value": "Downloading ()ve/main/spiece.model: 100%"
          }
        },
        "8f043cd19247459797310119ced2cf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2db54c961ee244daa6ae37420e272776",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12cc253ca5f942d18b08ff83f4855631",
            "value": 791656
          }
        },
        "e0c535d8f8f545459fce404e7a5858d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f79ab839e864f629f6a60f4d31e759b",
            "placeholder": "",
            "style": "IPY_MODEL_535d9e7a99e84e7aba4cd6d8522fbfd9",
            "value": " 792k/792k [00:00&lt;00:00, 23.1MB/s]"
          }
        },
        "e8cdafede2ff42378bdfb79ae6c8fbba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d383bbf0a4eb40f1974f8a171f70dc44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694173cd7fa24ca68e8035e2e8ce8956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2db54c961ee244daa6ae37420e272776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12cc253ca5f942d18b08ff83f4855631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f79ab839e864f629f6a60f4d31e759b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "535d9e7a99e84e7aba4cd6d8522fbfd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b555d0c8ce6544c4a96b77aedd68eab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7a200cbff844570a869a38e788ed923",
              "IPY_MODEL_218dc8d33a3842ccbf4144dada69e8d4",
              "IPY_MODEL_9095d8a090484ee7a5090bcce827cf9c"
            ],
            "layout": "IPY_MODEL_37377f53cf2947cfb89e1377097e6be2"
          }
        },
        "e7a200cbff844570a869a38e788ed923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a1c774087d241d5b9cfa47304946d34",
            "placeholder": "",
            "style": "IPY_MODEL_68d74726a0fa4160b7df548ded43fef9",
            "value": "Downloading ()lve/main/config.json: 100%"
          }
        },
        "218dc8d33a3842ccbf4144dada69e8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cd06519af0b4483b7dcbc7b014b352e",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fb8f311d88540619cbf2a758bc55a07",
            "value": 1208
          }
        },
        "9095d8a090484ee7a5090bcce827cf9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0421cf63e05d416faa251284c64da27c",
            "placeholder": "",
            "style": "IPY_MODEL_e4a50a177891485dafc1fb86ed333403",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 90.7kB/s]"
          }
        },
        "37377f53cf2947cfb89e1377097e6be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1c774087d241d5b9cfa47304946d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d74726a0fa4160b7df548ded43fef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cd06519af0b4483b7dcbc7b014b352e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb8f311d88540619cbf2a758bc55a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0421cf63e05d416faa251284c64da27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a50a177891485dafc1fb86ed333403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}