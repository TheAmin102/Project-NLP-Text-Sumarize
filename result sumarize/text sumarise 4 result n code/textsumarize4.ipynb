{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCyNlcOhgytV",
        "outputId": "c13a91bb-cf51-4bbe-9c93-dfd1b21b52d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import heapq\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text from TXT file\n",
        "with open('/content/CleanedText.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "parsed_article = bs.BeautifulSoup(text, 'lxml')\n",
        "\n",
        "# Removing Square Brackets and Extra Spaces\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', parsed_article.get_text())\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)\n",
        "\n",
        "# Removing special characters and digits\n",
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text)\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "bEEgMSavg_MX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "\n",
        "maximum_frequency = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word] / maximum_frequency)\n",
        "\n",
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "\n",
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]\n",
        "\n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-PzYwEfhB2J",
        "outputId": "4cfbd07f-e44d-46ec-9f1b-9bd4d8cbb498"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write summary to file\n",
        "with open('/content/summarize_result.txt', 'w') as file:\n",
        "    file.write(summary)"
      ],
      "metadata": {
        "id": "RHO-bGk5h02U"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}