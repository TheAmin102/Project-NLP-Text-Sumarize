In
this
section
we
demonstrate
our
pipeline
Figure
1
used
for
text
summarization
to
generate
a
summary
for
a
Thai
travel
news
Word
S9
6
Round
4
Round
5
Table
3
Example
of
Word
by
Sentence
Matrix
A
S8
Round
3
Avg
Number
of
Sentences
S7
21
16
Round
1
Round
2
Min
Number
of
Sentences
S6
7
7
Max
Number
of
Sentences
58
58
Dataset
S5
Table
2
Overall
Sentence
Language
of
each
Dataset
S4
DATA
PREPARATION
The
standard
data
sets
in
Thai
language
are
unavailable
for
evaluating
text
summarization
system
Therefore
we
collected
400
Thai
travel
news
from
Thairath
and
Manager
online
newspapers
to
be
used
as
datasets
for
our
experiments
We
split
400
travel
news
into
5
sets
of
80
news
each
We
then
evaluated
the
performance
of
text
summarization
methods
which
were
LSA
and
NMF
by
comparing
their
results
with
the
summaries
manually
curated
by
two
experts
from
the
Faculty
of
Liberal
Arts
Ubon
Ratchathani
University
The
open
source
python
libraries
such
as
numpy
19
and
sklearn
20
were
used
in
our
system
We
converted
the
Thai
travel
news
obtained
from
Thairath
and
Manager
online
newspapers
to
plain
text
Then
the
sentences
of
each
news
were
segmented
by
human
with
the
following
format
Si
xxx
where
Si
represents
the
order
of
the
sentence
in
the
original
document
and
xxx
represents
the
content
of
that
sentence
After
removing
stop
words
and
duplicate
words
we
built
a
document
term
matrix
or
matrix
A
then
applied
SVD
and
NMF
to
the
matrix
Then
we
used
python
modules
numpy
linalg
svd
to
calculate
SVD
and
sklearn
decomposition
to
calculate
NMF
For
sentence
selection
we
used
Gong
Y
et
al
and
Murray
G
et
al
approaches
for
calculating
weight
of
the
sentence
scores
then
selected
sentences
with
the
highest
scores
into
the
summary
For
keyword
score
calculation
of
NMF
we
calculated
the
keyword
score
from
Eq
5
and
then
selected
the
sentence
with
the
highest
score
from
each
concept
The
python
module
sklearn
cluster
was
used
for
K
means
clustering
The
selected
sentences
from
all
approaches
were
in
the
same
order
as
the
original
document
In
this
paper
we
performed
the
20
30
and
40
document
compression
This
meant
80
70
and
60
of
the
sentences
will
be
selected
into
the
summary
S3
4
Figure
1
Document
summarization
pipeline
based
on
LSA
and
NMF
S2
For
sentence
selection
by
K
means
clustering
we
grouped
similar
sentences
into
the
same
cluster
using
the
following
steps
1
Randomly
select
K
sentences
as
the
representative
of
K
groups
K
in
this
paper
is
the
number
of
sentences
that
will
be
selected
into
the
summary
2
Calculate
centroid
of
each
group
by
using
the
value
of
sentence
vector
from
V
matrix
for
LSA
and
ùêªùêªùëáùëá
matrix
for
NMF
3
Use
cosine
similarity
to
calculate
sentence
similarity
between
a
sentence
and
the
centroid
of
each
group
Then
assign
that
sentence
to
the
group
with
the
highest
similarity
4
Repeat
steps
2
3
until
all
sentences
are
assigned
to
a
group
no
sentences
change
the
group
or
the
similarity
between
sentences
and
their
centroid
is
close
5
Select
a
sentence
with
the
maximum
similarity
score
with
the
centroid
of
the
group
and
add
it
into
the
summary
S1
3
6
A
B
n
n
A
B
i
1
A2i
i
1
Bi2
6
Mr
Yontas
ak
1
0
0
0
0
0
0
0
0
Supason
1
0
0
0
0
0
0
0
0
Tourism
Authority
of
Thailand
1
0
0
0
0
0
0
0
0
Table
3
demonstrates
an
example
of
a
matrix
ùê¥ùê¥
constructed
from
word
count
by
sentence
of
a
Thai
travel
news
It
was
composed
of
98
words
and
9
sentences
This
matrix
ùê¥ùê¥
was
then
applied
with
the
LSA
and
NMF
The
sentence
vectors
were
calculated
from
the
term
weight
and
the
semantic
feature
vectors
from
Eq
1
for
LSA
and
Eq
2
for
NMF
sentences
from
all
concepts
The
Generic
Sentence
Relevance
score
for
NMF
also
collected
one
sentence
for
each
concept
the
same
as
Gong
Y
et
al
but
with
the
highest
score
calculated
by
Eq
5
As
multiple
important
sentences
could
be
selected
from
a
more
important
concept
Murray
G
et
al
outperformed
both
Gong
Y
et
al
and
the
GRS
method
6
EXPERIMENT
AND
RESULTS
6
1
Performance
Evaluations
Measure
7
We
evaluated
the
results
of
the
summarization
by
using
standard
accuracy
precision
recall
and
F1
score
21
These
measurements
quantify
the
differences
between
the
summary
from
human
and
the
experimental
methods
The
precision
shows
the
correctness
of
the
extracted
sentences
and
the
recall
reflects
the
number
of
good
sentences
missed
by
the
method
6
2
Experiment
Results
In
this
experimental
set
we
would
like
to
explore
how
the
different
sentence
selection
methods
the
Generic
Sentence
Relevance
score
and
K
means
clustering
affected
the
text
summarization
result
For
K
means
clustering
both
SVD
and
NMF
had
similar
summarization
efficiency
The
F1
score
of
SVD
with
K
means
clustering
was
0
83
0
72
and
0
62
for
the
compression
rate
of
20
30
and
40
For
the
NMF
with
K
means
clustering
the
F1
score
for
the
three
compression
rates
was
0
83
0
74
and
0
64
For
the
Generic
Sentence
Relevance
score
the
best
F1
score
for
the
compression
rate
of
20
30
and
40
was
0
86
0
78
and
0
68
respectively
and
the
best
F1
scores
for
all
compression
rates
were
from
the
approach
of
Murray
G
et
al
Figure
2
Thai
text
summarization
efficiency
of
5
models
Figure
2
shows
the
Thai
text
summarization
efficiency
of
5
models
1
NMF
with
GRS
2
NMF
with
K
means
3
SVD
with
sentence
score
by
Gong
Y
et
al
4
SVD
with
K
means
and
5
SVD
with
sentence
score
by
Murray
G
et
al
applied
to
400
Thai
travel
news
divided
into
5
sets
of
80
news
each
with
the
varied
compression
rates
of
20
30
and
40
From
this
experiment
the
best
model
based
on
keyword
score
for
Thai
travel
news
summarization
was
SVD
with
sentence
selection
by
Murray
G
et
al
This
model
with
the
compression
rate
of
20
got
the
highest
score
because
Murray
G
et
al
method
determined
the
number
of
sentences
to
be
extracted
from
each
concept
based
on
the
importance
of
that
concept
The
method
of
Gong
Y
et
al
on
the
other
hand
was
proposed
to
select
only
one
sentence
with
the
highest
score
from
each
concept
so
that
the
summary
would
include
CONCLUSIONS
In
this
paper
we
applied
several
text
summarization
methods
to
Thai
Travel
News
based
on
keyword
scored
in
Thai
language
by
extracting
the
most
relevant
sentences
from
the
original
document
We
compared
LSA
and
NMF
together
with
different
sentence
selection
methods
to
find
the
algorithm
suitable
with
this
paper
s
data
source
We
concluded
that
keyword
scored
calculation
by
LSA
with
sentence
selection
by
Generic
Sentence
Relevance
score
by
Murray
G
et
al
was
the
best
algorithm
while
the
best
compression
rate
of
all
models
was
20
for
summarizing
Thai
Travel
News
compared
with
humans
In
future
work
we
plan
to
perform
the
experiments
with
different
types
of
documents
and
improve
word
segmentation
of
compound
nouns
that
was
not
handled
by
Cutkum
8
ACKNOWLEDGMENTS
We
would
like
to
thank
the
department
of
computer
engineering
faculty
of
engineering
Chulalongkorn
University
for
providing
computing
facilities
 We
also
tried
using
K
means
clustering
for
document
summarization
In
this
experiment
we
compared
5
models
for
5
rounds
with
Thai
travel
news
using
the
compression
rates
of
20
30
and
40
and
reported
the
rate
and
method
that
produced
the
best
result
from
the
experiment
2
RELATED
WORKS
In
recent
years
several
models
in
Thai
Text
summarization
have
been
introduced
Suwanno
N
et
al
2
proposed
a
Thai
text
summarization
that
extracted
a
paragraph
from
a
document
based
on
Thai
compound
nouns
term
frequency
method
and
headline
score
for
generating
a
summary
Chongsuntornsri
A
et
al
3
proposed
a
new
approach
for
Text
summarization
in
Thai
based
on
content
and
graph
based
with
the
use
of
Topic
Sensitive
PageRank
algorithm
for
summarizing
and
ranking
of
text
segments
Jaruskulchai
C
et
al
4
proposed
a
method
to
summarize
documents
by
extracting
important
sentences
from
combining
the
specific
properties
Local
Property
and
the
overall
properties
Global
Property
of
the
sentences
The
overall
properties
were
based
on
the
relationship
between
sentences
in
the
document
From
their
experiments
the
summarization
of
the
industrial
news
got
60
precision
44
recall
and
50
9
F
measure
the
general
news
got
the
51
8
precision
38
5
recall
and
43
1
F
measure
while
the
fashion
magazines
got
53
0
precision
33
0
recall
and
40
4
F
measure
Mani
I
et
al
5
proposed
techniques
of
text
summarization
by
using
word
frequency
in
the
document
and
calculated
the
weight
of
word
to
create
a
keyword
group
They
then
calculated
the
cosine
similarity
of
sentences
The
researcher
used
A
search
algorithm
to
find
the
shortest
sequence
of
sentences
from
keyword
group
by
topic
calculation
sentence
segmentation
and
word
grouping
The
sequence
of
sentences
that
were
in
the
main
group
were
selected
as
important
sentences
Their
summarization
of
the
agricultural
news
got
68
57
precision
51
95
recall
and
56
72
F
measure
Lee
J
et
al
6
proposed
a
document
summarization
method
using
Non
negative
Matrix
Factorization
NMF
They
compared
between
Latent
Semantic
Analysis
LSA
and
NMF
to
find
the
weight
of
each
word
and
calculated
the
summation
of
weights
The
important
sentences
were
ranked
and
selected
into
the
summary
based
on
their
summed
weight
Based
on
LSA
they
found
many
weights
with
zero
and
negative
values
However
when
applied
NMF
they
found
only
the
positive
values
and
the
scope
of
the
semantic
features
meaning
was
narrow
Therefore
they
proposed
that
NMF
provided
a
greater
possibility
for
extracting
important
sentences
3
PREPROCESSING
FOR
THAI
TEXT
The
first
step
for
working
with
Thai
Text
is
word
tokenization
Even
though
Thai
writing
system
has
no
delimiters
to
indicate
word
boundaries
together
with
many
rules
for
word
segmentation
several
Thai
word
tokenization
programs
have
been
proposed
Table
1
shows
F1
score
of
the
recent
programs
trained
and
tested
by
one
of
our
laboratory
members
with
the
data
from
BEST2010
corpus
7
Cutkum
8
got
the
highest
F1
score
hence
we
used
Cutkum
for
this
step
Table
1
Comparison
of
Thai
word
tokenization
programs
Tools
F1
Score
Validate
PyICU
9
Article
100
0
6155
Encyclopedia
100
0
6932
News
100
0
5987
Novel
100
0
6800
Lexto
10
0
7267
0
7709
0
6994
0
7701
Cutkum
wordcutpy
11
0
9322
0
6212
0
9299
0
6286
0
8987
0
6571
0
7140
0
6247
cunlp
12
0
6910
0
6172
0
5748
0
0000
SWATH
13
0
6347
0
6858
0
6200
0
6867
3
1
Latent
Semantic
Analysis
Latent
Semantic
Analysis
LSA
14
is
the
algorithm
which
reduces
the
dimensionality
of
term
document
The
algorithm
creates
a
matrix
by
using
word
frequency
applies
the
singular
value
decomposition
SVD
15
and
then
finds
closely
related
terms
and
documents
The
original
matrix
A
can
be
separated
into
three
matrices
where
U
is
the
m
x
r
words
x
extracted
concept
matrix
V
is
the
n
x
r
sentences
x
extracted
concepts
matrix
and
Œ£
is
the
r
x
r
diagonal
matrix
which
can
be
reconstructed
to
find
the
original
matrix
A
The
SVD
can
be
represented
in
Eq
