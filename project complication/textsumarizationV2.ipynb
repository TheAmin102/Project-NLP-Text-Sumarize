{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TEXT SUMMARIZATION USING THE FREQUENCY METHOD\n",
        "In this method we find the frequency of all the words in our text data and store the text data and its frequency in a dictionary. After that, we tokenize our text data. The sentences which contain more high frequency words will be kept in our final summary data."
      ],
      "metadata": {
        "id": "Vz0PER3YPdLt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M2Oy65BMo_x",
        "outputId": "d51af717-ddd0-4041-ffd0-6ba273fd721a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Although several solutions such as PageRank, Graph Rank, Latent Semantic Analysis (LSA) models, etc., have been proposed, research results in Thai text summarization were restricted due to limited corpus in Thai language with complex grammar.This paper applied a text summarization system for Thai travel news based on keyword scored in Thai language by extracting the most relevant sentences from the original document.From these experiments, we concluded that keyword scored calculation by LSA with sentence selection by GRS is the best algorithm for summarizing Thai Travel News, compared with human with the best compression rate of 20%.However, there were only a few research results in Thai text summarization due to the lack of corpus in Thai language and the complicated grammar.It consists of three steps: 1) create an intermediate representation of the input text, 2) calculate score for the sentences based on the concepts, and 3) choose important sentences to be included in the summary.However, with the lack of Thai corpus, we chose to apply an extractive summarization method for Thai text summarization.This research focused on the sentence extraction function based on keyword score calculation then selecting important sentences based on the Generic Sentence Relevance score (GRS), calculated from Latent Semantic Analysis (LSA) and Non-negative Matrix Factorization (NMF).In this experiment, we compared 5 models for 5 rounds with Thai travel news using the compression rates of 20%, 30% and 40% and reported the rate and method that produced the best result from the experiment.Suwanno, N. et al. [2] proposed a Thai text summarization that extracted a paragraph from a document based on Thai compound nouns, term frequency method, and headline score for generating a summary.Chongsuntornsri, A., et al. [3] proposed a new approach for Text summarization in Thai based on content- and graph-based with the use of Topic Sensitive PageRank algorithm for summarizing and ranking of text segments.Jaruskulchai C., et al. [4] proposed a method to summarize documents by extracting important sentences from combining the specific properties (Local Property) and the overall properties (Global Property) of the sentences.From their experiments, the summarization of the industrial news got 60% precision, 44% recall, and 50.9% F-measure, the general news got the 51.8% precision, 38.5% recall, and 43.1% F-measure while the fashion magazines got 53.0% precision, 33.0% recall, and 40.4% F-measure.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def solve(text):\n",
        "    stopwords1 = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text)\n",
        "    freqTable = {}\n",
        "\n",
        "    for word in words:\n",
        "        word = word.lower()\n",
        "        if word in stopwords1:\n",
        "            continue\n",
        "        if word in freqTable:\n",
        "            freqTable[word] += 1\n",
        "        else:\n",
        "            freqTable[word] = 1\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentenceValue = {}\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for word, freq in freqTable.items():\n",
        "            if word in sentence.lower():\n",
        "                if sentence in sentenceValue:\n",
        "                    sentenceValue[sentence] += freq\n",
        "                else:\n",
        "                    sentenceValue[sentence] = freq\n",
        "\n",
        "    sumValues = 0\n",
        "    for sentence in sentenceValue:\n",
        "        sumValues += sentenceValue[sentence]\n",
        "    average = int(sumValues / len(sentenceValue))\n",
        "\n",
        "    summary = ''\n",
        "    for sentence in sentences:\n",
        "        if sentence in sentenceValue and sentenceValue[sentence] > (1.2 * average):\n",
        "            summary += sentence\n",
        "\n",
        "    return summary\n",
        "\n",
        "text = \"ABSTRACT In recent years, people are seeking for a solution to improve text summarization for Thai language. Although several solutions such as PageRank, Graph Rank, Latent Semantic Analysis (LSA) models, etc., have been proposed, research results in Thai text summarization were restricted due to limited corpus in Thai language with complex grammar. This paper applied a text summarization system for Thai travel news based on keyword scored in Thai language by extracting the most relevant sentences from the original document. We compared LSA and Non-negative Matrix Factorization (NMF) to find the algorithm that is suitable with Thai travel news. The suitable compression rates for Generic Sentence Relevance score (GRS) and K-means clustering were also evaluated. From these experiments, we concluded that keyword scored calculation by LSA with sentence selection by GRS is the best algorithm for summarizing Thai Travel News, compared with human with the best compression rate of 20%. CCS Concepts • Information systems ➝ Information retrieval ➝ Retrieval tasks and goals➝ Summarization Keywords Text summarization; extractive summarization; non-negative matrix factorization 1. INTRODUCTION Daily newspaper has abundant of text that users do not have enough time for reading them. It is difficult to identify the relevant information to satisfy the information needed by users. Automatic summarization can reduce the problem of information overloading and it has been proposed previously in English and other languages. However, there were only a few research results in Thai text summarization due to the lack of corpus in Thai language and the complicated grammar. Text Summarization [1] is a technique for summarizing the content of the documents. It consists of three steps: 1) create an intermediate representation of the input text, 2) calculate score for the sentences based on the concepts, and 3) choose important sentences to be included in the summary. Text summarization can be divided into 2 approaches. The first approach is the extractive summarization, which relies on a method for extracting words and searching for keywords from the original document. The second approach is the abstractive summarization, which analyzes words by linguistic principles with transcription or interpretation from the original document. This approach implies more effective and accurate summary than the extractive methods. However, with the lack of Thai corpus, we chose to apply an extractive summarization method for Thai text summarization. This research focused on the sentence extraction function based on keyword score calculation then selecting important sentences based on the Generic Sentence Relevance score (GRS), calculated from Latent Semantic Analysis (LSA) and Non-negative Matrix Factorization (NMF). We also tried using K-means clustering for document summarization. In this experiment, we compared 5 models for 5 rounds with Thai travel news using the compression rates of 20%, 30% and 40% and reported the rate and method that produced the best result from the experiment. 2. RELATED WORKS In recent years, several models in Thai Text summarization have been introduced. Suwanno, N. et al. [2] proposed a Thai text summarization that extracted a paragraph from a document based on Thai compound nouns, term frequency method, and headline score for generating a summary. Chongsuntornsri, A., et al. [3] proposed a new approach for Text summarization in Thai based on content- and graph-based with the use of Topic Sensitive PageRank algorithm for summarizing and ranking of text segments. Jaruskulchai C., et al. [4] proposed a method to summarize documents by extracting important sentences from combining the specific properties (Local Property) and the overall properties (Global Property) of the sentences. The overall properties were based on the relationship between sentences in the document. From their experiments, the summarization of the industrial news got 60% precision, 44% recall, and 50.9% F-measure, the general news got the 51.8% precision, 38.5% recall, and 43.1% F-measure while the fashion magazines got 53.0% precision, 33.0% recall, and 40.4% F-measure.\"\n",
        "result = solve(text)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmXCKWwKO7jP",
        "outputId": "15b11b09-c688-4bbe-89c7-b2cd364c489b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.27.1)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.10/dist-packages (from sumy) (22.3.5)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.65.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pycountry>=18.2.23->sumy) (67.7.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumy:\n",
        "Sumy is a textrank based machine learning algorithm."
      ],
      "metadata": {
        "id": "vllkapS3Pghw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Packages\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "\n",
        "# Creating text parser using tokenization\n",
        "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "# Summarize using sumy TextRank\n",
        "summarizer = TextRankSummarizer()\n",
        "summary = summarizer(parser.document, 2)\n",
        "\n",
        "text_summary = \"\"\n",
        "for sentence in summary:\n",
        "    text_summary += str(sentence)\n",
        "\n",
        "print(text_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krH3VqPyNVva",
        "outputId": "2a321224-e931-413b-97f1-af44c002a97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In this experiment, we compared 5 models for 5 rounds with Thai travel news using the compression rates of 20%, 30% and 40% and reported the rate and method that produced the best result from the experiment.From their experiments, the summarization of the industrial news got 60% precision, 44% recall, and 50.9% F-measure, the general news got the 51.8% precision, 38.5% recall, and 43.1% F-measure while the fashion magazines got 53.0% precision, 33.0% recall, and 40.4% F-measure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lex Rank:\n",
        "This is an unsupervised machine learning based approach in which we use the textrank approach to find the summary of our sentences. Using cosine similarity and vector based algorithms, we find minimum cosine distance among various words and store the more similar words together."
      ],
      "metadata": {
        "id": "DbEvz9d3PkbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "\n",
        "def sumy_method(text):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer = LexRankSummarizer()\n",
        "    # Summarize the document with 2 sentences\n",
        "    summary = summarizer(parser.document, 2)\n",
        "    dp = []\n",
        "    for i in summary:\n",
        "        lp = str(i)\n",
        "        dp.append(lp)\n",
        "    final_sentence = ' '.join(dp)\n",
        "    return final_sentence\n",
        "\n",
        "# Example usage\n",
        "text = \"ABSTRACT In recent years, people are seeking for a solution to improve text summarization for Thai language. Although several solutions such as PageRank, Graph Rank, Latent Semantic Analysis (LSA) models, etc., have been proposed, research results in Thai text summarization were restricted due to limited corpus in Thai language with complex grammar. This paper applied a text summarization system for Thai travel news based on keyword scored in Thai language by extracting the most relevant sentences from the original document. We compared LSA and Non-negative Matrix Factorization (NMF) to find the algorithm that is suitable with Thai travel news. The suitable compression rates for Generic Sentence Relevance score (GRS) and K-means clustering were also evaluated. From these experiments, we concluded that keyword scored calculation by LSA with sentence selection by GRS is the best algorithm for summarizing Thai Travel News, compared with human with the best compression rate of 20%. CCS Concepts • Information systems ➝ Information retrieval ➝ Retrieval tasks and goals➝ Summarization Keywords Text summarization; extractive summarization; non-negative matrix factorization 1. INTRODUCTION Daily newspaper has abundant of text that users do not have enough time for reading them. It is difficult to identify the relevant information to satisfy the information needed by users. Automatic summarization can reduce the problem of information overloading and it has been proposed previously in English and other languages. However, there were only a few research results in Thai text summarization due to the lack of corpus in Thai language and the complicated grammar. Text Summarization [1] is a technique for summarizing the content of the documents. It consists of three steps: 1) create an intermediate representation of the input text, 2) calculate score for the sentences based on the concepts, and 3) choose important sentences to be included in the summary. Text summarization can be divided into 2 approaches. The first approach is the extractive summarization, which relies on a method for extracting words and searching for keywords from the original document. The second approach is the abstractive summarization, which analyzes words by linguistic principles with transcription or interpretation from the original document. This approach implies more effective and accurate summary than the extractive methods. However, with the lack of Thai corpus, we chose to apply an extractive summarization method for Thai text summarization. This research focused on the sentence extraction function based on keyword score calculation then selecting important sentences based on the Generic Sentence Relevance score (GRS), calculated from Latent Semantic Analysis (LSA) and Non-negative Matrix Factorization (NMF). We also tried using K-means clustering for document summarization. In this experiment, we compared 5 models for 5 rounds with Thai travel news using the compression rates of 20%, 30% and 40% and reported the rate and method that produced the best result from the experiment. 2. RELATED WORKS In recent years, several models in Thai Text summarization have been introduced. Suwanno, N. et al. [2] proposed a Thai text summarization that extracted a paragraph from a document based on Thai compound nouns, term frequency method, and headline score for generating a summary. Chongsuntornsri, A., et al. [3] proposed a new approach for Text summarization in Thai based on content- and graph-based with the use of Topic Sensitive PageRank algorithm for summarizing and ranking of text segments. Jaruskulchai C., et al. [4] proposed a method to summarize documents by extracting important sentences from combining the specific properties (Local Property) and the overall properties (Global Property) of the sentences. The overall properties were based on the relationship between sentences in the document. From their experiments, the summarization of the industrial news got 60% precision, 44% recall, and 50.9% F-measure, the general news got the 51.8% precision, 38.5% recall, and 43.1% F-measure while the fashion magazines got 53.0% precision, 33.0% recall, and 40.4% F-measure.\"\n",
        "result = sumy_method(text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_mewMnePpdo",
        "outputId": "81541eea-a2fd-417f-cc36-9bacebacc1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This paper applied a text summarization system for Thai travel news based on keyword scored in Thai language by extracting the most relevant sentences from the original document. The first approach is the extractive summarization, which relies on a method for extracting words and searching for keywords from the original document.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Luhn:\n",
        "This approach is based on the frequency method; here we find TF-IDF (term frequency inverse document frequency)."
      ],
      "metadata": {
        "id": "yEnVDgsMQSBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.luhn import LuhnSummarizer"
      ],
      "metadata": {
        "id": "tldDCmczQguu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.luhn import LuhnSummarizer\n",
        "\n",
        "def luhn_method(text):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer_luhn = LuhnSummarizer()\n",
        "    summary_1 = summarizer_luhn(parser.document, 2)\n",
        "    dp = []\n",
        "    for i in summary_1:\n",
        "        lp = str(i)\n",
        "        dp.append(lp)\n",
        "    final_sentence = ' '.join(dp)\n",
        "    return final_sentence\n",
        "\n",
        "# Example usage\n",
        "text = \"ABSTRACT In recent years, people are seeking for a solution to improve text summarization for Thai language. Although several solutions such as PageRank, Graph Rank, Latent Semantic Analysis (LSA) models, etc., have been proposed, research results in Thai text summarization were restricted due to limited corpus in Thai language with complex grammar. This paper applied a text summarization system for Thai travel news based on keyword scored in Thai language by extracting the most relevant sentences from the original document. We compared LSA and Non-negative Matrix Factorization (NMF) to find the algorithm that is suitable with Thai travel news. The suitable compression rates for Generic Sentence Relevance score (GRS) and K-means clustering were also evaluated. From these experiments, we concluded that keyword scored calculation by LSA with sentence selection by GRS is the best algorithm for summarizing Thai Travel News, compared with human with the best compression rate of 20%. CCS Concepts • Information systems ➝ Information retrieval ➝ Retrieval tasks and goals➝ Summarization Keywords Text summarization; extractive summarization; non-negative matrix factorization 1. INTRODUCTION Daily newspaper has abundant of text that users do not have enough time for reading them. It is difficult to identify the relevant information to satisfy the information needed by users. Automatic summarization can reduce the problem of information overloading and it has been proposed previously in English and other languages. However, there were only a few research results in Thai text summarization due to the lack of corpus in Thai language and the complicated grammar. Text Summarization [1] is a technique for summarizing the content of the documents. It consists of three steps: 1) create an intermediate representation of the input text, 2) calculate score for the sentences based on the concepts, and 3) choose important sentences to be included in the summary. Text summarization can be divided into 2 approaches. The first approach is the extractive summarization, which relies on a method for extracting words and searching for keywords from the original document. The second approach is the abstractive summarization, which analyzes words by linguistic principles with transcription or interpretation from the original document. This approach implies more effective and accurate summary than the extractive methods. However, with the lack of Thai corpus, we chose to apply an extractive summarization method for Thai text summarization. This research focused on the sentence extraction function based on keyword score calculation then selecting important sentences based on the Generic Sentence Relevance score (GRS), calculated from Latent Semantic Analysis (LSA) and Non-negative Matrix Factorization (NMF). We also tried using K-means clustering for document summarization. In this experiment, we compared 5 models for 5 rounds with Thai travel news using the compression rates of 20%, 30% and 40% and reported the rate and method that produced the best result from the experiment. 2. RELATED WORKS In recent years, several models in Thai Text summarization have been introduced. Suwanno, N. et al. [2] proposed a Thai text summarization that extracted a paragraph from a document based on Thai compound nouns, term frequency method, and headline score for generating a summary. Chongsuntornsri, A., et al. [3] proposed a new approach for Text summarization in Thai based on content- and graph-based with the use of Topic Sensitive PageRank algorithm for summarizing and ranking of text segments. Jaruskulchai C., et al. [4] proposed a method to summarize documents by extracting important sentences from combining the specific properties (Local Property) and the overall properties (Global Property) of the sentences. The overall properties were based on the relationship between sentences in the document. From their experiments, the summarization of the industrial news got 60% precision, 44% recall, and 50.9% F-measure, the general news got the 51.8% precision, 38.5% recall, and 43.1% F-measure while the fashion magazines got 53.0% precision, 33.0% recall, and 40.4% F-measure.\"\n",
        "result = luhn_method(text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWWMyyDZQWT3",
        "outputId": "b47d3849-5a66-44b1-feb1-08940e022daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From these experiments, we concluded that keyword scored calculation by LSA with sentence selection by GRS is the best algorithm for summarizing Thai Travel News, compared with human with the best compression rate of 20%. This research focused on the sentence extraction function based on keyword score calculation then selecting important sentences based on the Generic Sentence Relevance score (GRS), calculated from Latent Semantic Analysis (LSA) and Non-negative Matrix Factorization (NMF).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSA\n",
        "Latent Semantic Analyzer (LSA) is based on decomposing the data into low dimensional space. LSA has the ability to store the semantic of given text while summarizing."
      ],
      "metadata": {
        "id": "8_6uTxRJQtMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.lsa import LsaSummarizer"
      ],
      "metadata": {
        "id": "tDGFNC4zQ6Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "def lsa_method(text):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer_lsa = LsaSummarizer()\n",
        "    summary_2 = summarizer_lsa(parser.document, 2)\n",
        "    dp = []\n",
        "    for i in summary_2:\n",
        "        lp = str(i)\n",
        "        dp.append(lp)\n",
        "    final_sentence = ' '.join(dp)\n",
        "    return final_sentence\n",
        "\n",
        "# Example usage\n",
        "text =  \"ABSTRACT In recent years, people are seeking for a solution to improve text summarization for Thai language. Although several solutions such as PageRank, Graph Rank, Latent Semantic Analysis (LSA) models, etc., have been proposed, research results in Thai text summarization were restricted due to limited corpus in Thai language with complex grammar. This paper applied a text summarization system for Thai travel news based on keyword scored in Thai language by extracting the most relevant sentences from the original document. We compared LSA and Non-negative Matrix Factorization (NMF) to find the algorithm that is suitable with Thai travel news. The suitable compression rates for Generic Sentence Relevance score (GRS) and K-means clustering were also evaluated. From these experiments, we concluded that keyword scored calculation by LSA with sentence selection by GRS is the best algorithm for summarizing Thai Travel News, compared with human with the best compression rate of 20%. CCS Concepts • Information systems ➝ Information retrieval ➝ Retrieval tasks and goals➝ Summarization Keywords Text summarization; extractive summarization; non-negative matrix factorization 1. INTRODUCTION Daily newspaper has abundant of text that users do not have enough time for reading them. It is difficult to identify the relevant information to satisfy the information needed by users. Automatic summarization can reduce the problem of information overloading and it has been proposed previously in English and other languages. However, there were only a few research results in Thai text summarization due to the lack of corpus in Thai language and the complicated grammar. Text Summarization [1] is a technique for summarizing the content of the documents. It consists of three steps: 1) create an intermediate representation of the input text, 2) calculate score for the sentences based on the concepts, and 3) choose important sentences to be included in the summary. Text summarization can be divided into 2 approaches. The first approach is the extractive summarization, which relies on a method for extracting words and searching for keywords from the original document. The second approach is the abstractive summarization, which analyzes words by linguistic principles with transcription or interpretation from the original document. This approach implies more effective and accurate summary than the extractive methods. However, with the lack of Thai corpus, we chose to apply an extractive summarization method for Thai text summarization. This research focused on the sentence extraction function based on keyword score calculation then selecting important sentences based on the Generic Sentence Relevance score (GRS), calculated from Latent Semantic Analysis (LSA) and Non-negative Matrix Factorization (NMF). We also tried using K-means clustering for document summarization. In this experiment, we compared 5 models for 5 rounds with Thai travel news using the compression rates of 20%, 30% and 40% and reported the rate and method that produced the best result from the experiment. 2. RELATED WORKS In recent years, several models in Thai Text summarization have been introduced. Suwanno, N. et al. [2] proposed a Thai text summarization that extracted a paragraph from a document based on Thai compound nouns, term frequency method, and headline score for generating a summary. Chongsuntornsri, A., et al. [3] proposed a new approach for Text summarization in Thai based on content- and graph-based with the use of Topic Sensitive PageRank algorithm for summarizing and ranking of text segments. Jaruskulchai C., et al. [4] proposed a method to summarize documents by extracting important sentences from combining the specific properties (Local Property) and the overall properties (Global Property) of the sentences. The overall properties were based on the relationship between sentences in the document. From their experiments, the summarization of the industrial news got 60% precision, 44% recall, and 50.9% F-measure, the general news got the 51.8% precision, 38.5% recall, and 43.1% F-measure while the fashion magazines got 53.0% precision, 33.0% recall, and 40.4% F-measure.\"\n",
        "result = lsa_method(text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1kBVerQQuVC",
        "outputId": "b1d0456c-3890-4883-ef71-bb20b62331d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We compared LSA and Non-negative Matrix Factorization (NMF) to find the algorithm that is suitable with Thai travel news. INTRODUCTION Daily newspaper has abundant of text that users do not have enough time for reading them.\n"
          ]
        }
      ]
    }
  ]
}