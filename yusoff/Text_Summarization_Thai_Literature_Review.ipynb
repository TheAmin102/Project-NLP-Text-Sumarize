{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WYdMwvYn42jw"
      },
      "source": [
        "# **Text Summarization using NLP**\n",
        "\n",
        "\n",
        "**What is text summarization?**\n",
        "\n",
        "Text summarization is the process of distilling the most important information from a source text."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QSmeHW7R6FEF"
      },
      "source": [
        "**Why automatic text summarization?**\n",
        "\n",
        "\n",
        "\n",
        "1.   Summaries reduce reading time.\n",
        "2.   When researching documents,summaries make the  selection process easier.\n",
        "3.   Automatic summarization improves the effectiveness of indexing.\n",
        "4.   Automatice summarization algorithms are less biased than human summarization.\n",
        "5.   Personalized summaries are useful in question-answering systems as they provied personalized information.\n",
        "6.   Using automatic or semi-automatic summarization systems enables commercial abstract services to increase the number of text documents they are able to process.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZU31cjFg83hu"
      },
      "source": [
        "# **Type of summarization**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1AqwSGEpi3vzAOLVt_5XXRXokZHvcn43B)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s9xxDWxC-1eM"
      },
      "source": [
        "\n",
        "\n",
        "**How to do text summarization**\n",
        "\n",
        "\n",
        "*   Text cleaning\n",
        "*   Sentence tokenization\n",
        "*   Word tokenzation\n",
        "*   Word-frequency table\n",
        "*   Summarization \n",
        " \n",
        " \n",
        "\n",
        "  **Text variable**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rOfW0xVd-tWw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2JqLo7pWYD1o"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "ABSTRACT\n",
        "In recent years, people are seeking for a solution to improve text\n",
        "summarization for Thai language. Although several solutions such\n",
        "as PageRank, Graph Rank, Latent Semantic Analysis (LSA)\n",
        "models, etc., have been proposed, research results in Thai text\n",
        "summarization were restricted due to limited corpus in Thai\n",
        "language with complex grammar. This paper applied a text\n",
        "summarization system for Thai travel news based on keyword\n",
        "scored in Thai language by extracting the most relevant sentences\n",
        "from the original document. We compared LSA and Non-negative\n",
        "Matrix Factorization (NMF) to find the algorithm that is suitable\n",
        "with Thai travel news. The suitable compression rates for Generic\n",
        "Sentence Relevance score (GRS) and K-means clustering were also\n",
        "evaluated. From these experiments, we concluded that keyword\n",
        "scored calculation by LSA with sentence selection by GRS is the\n",
        "best algorithm for summarizing Thai Travel News, compared with\n",
        "human with the best compression rate of 20%.\n",
        "CCS Concepts\n",
        "• Information systems ➝ Information retrieval ➝ Retrieval\n",
        "tasks and goals➝ Summarization\n",
        "Keywords\n",
        "Text summarization; extractive summarization; non-negative\n",
        "matrix factorization\n",
        "1. INTRODUCTION\n",
        "Daily newspaper has abundant of data that users do not have\n",
        "enough time for reading them. It is difficult to identify the relevant\n",
        "information to satisfy the information needed by users. Automatic\n",
        "summarization can reduce the problem of information overloading\n",
        "and it has been proposed previously in English and other languages.\n",
        "However, there were only a few research results in Thai text\n",
        "summarization due to the lack of corpus in Thai language and the\n",
        "complicated grammar.\n",
        "Text Summarization [1] is a technique for summarizing the content\n",
        "of the documents. It consists of three steps: 1) create an\n",
        "intermediate representation of the input text, 2) calculate score for\n",
        "the sentences based on the concepts, and 3) choose important\n",
        "sentences to be included in the summary. Text summarization can\n",
        "be divided into 2 approaches. The first approach is the extractive\n",
        "summarization, which relies on a method for extracting words and\n",
        "searching for keywords from the original document. The second\n",
        "approach is the abstractive summarization, which analyzes words\n",
        "by linguistic principles with transcription or interpretation from the\n",
        "original document. This approach implies more effective and\n",
        "accurate summary than the extractive methods. However, with the\n",
        "lack of Thai corpus, we chose to apply an extractive summarization\n",
        "method for Thai text summarization.\n",
        "This research focused on the sentence extraction function based on\n",
        "keyword score calculation then selecting important sentences based\n",
        "on the Generic Sentence Relevance score (GRS), calculated from\n",
        "Latent Semantic Analysis (LSA) and Non-negative Matrix\n",
        "Factorization (NMF). We also tried using K-means clustering for\n",
        "document summarization. In this experiment, we compared 5\n",
        "models for 5 rounds with Thai travel news using the compression\n",
        "rates of 20%, 30% and 40% and reported the rate and method that\n",
        "produced the best result from the experiment.\n",
        "2. RELATED WORKS\n",
        "In recent years, several models in Thai Text summarization have\n",
        "been introduced. Suwanno, N. et al. [2] proposed a Thai text\n",
        "summarization that extracted a paragraph from a document based\n",
        "on Thai compound nouns, term frequency method, and headline\n",
        "score for generating a summary. Chongsuntornsri, A., et al. [3]\n",
        "proposed a new approach for Text summarization in Thai based on\n",
        "content- and graph-based with the use of Topic Sensitive PageRank\n",
        "algorithm for summarizing and ranking of text segments.\n",
        "Jaruskulchai C., et al. [4] proposed a method to summarize\n",
        "documents by extracting important sentences from combining the\n",
        "specific properties (Local Property) and the overall properties\n",
        "(Global Property) of the sentences. The overall properties were\n",
        "based on the relationship between sentences in the document. From\n",
        "their experiments, the summarization of the industrial news got\n",
        "60% precision, 44% recall, and 50.9% F-measure, the general news\n",
        "got the 51.8% precision, 38.5% recall, and 43.1% F-measure while\n",
        "the fashion magazines got 53.0% precision, 33.0% recall, and\n",
        "40.4% F-measure.\n",
        "\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ICuVSNbQY-dO"
      },
      "source": [
        "\n",
        "\n",
        "# Let's Get Started with SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6Ehfk3s8ZL0b"
      },
      "outputs": [],
      "source": [
        "# pip install -U spacy\n",
        "# python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gT1zyYMnZguO"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JrR_ipOKZ4Lp"
      },
      "outputs": [],
      "source": [
        "stopwords = list(STOP_WORDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PrE3D0S6aC_s"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "# For some OS you need to make a correctino installing the package separately using this command:\n",
        "# !pip3 install -U spacy\n",
        "# !python3 -m spacy download en_core_web_sm\n",
        "# run both command above to install a separate package from the spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RntMWU8DaQDm"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "Pqre-o8AaXRA",
        "outputId": "b300f8b7-9437-49f2-81f3-08620d946c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', 'ABSTRACT', '\\n', 'In', 'recent', 'years', ',', 'people', 'are', 'seeking', 'for', 'a', 'solution', 'to', 'improve', 'text', '\\n', 'summarization', 'for', 'Thai', 'language', '.', 'Although', 'several', 'solutions', 'such', '\\n', 'as', 'PageRank', ',', 'Graph', 'Rank', ',', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', '\\n', 'models', ',', 'etc', '.', ',', 'have', 'been', 'proposed', ',', 'research', 'results', 'in', 'Thai', 'text', '\\n', 'summarization', 'were', 'restricted', 'due', 'to', 'limited', 'corpus', 'in', 'Thai', '\\n', 'language', 'with', 'complex', 'grammar', '.', 'This', 'paper', 'applied', 'a', 'text', '\\n', 'summarization', 'system', 'for', 'Thai', 'travel', 'news', 'based', 'on', 'keyword', '\\n', 'scored', 'in', 'Thai', 'language', 'by', 'extracting', 'the', 'most', 'relevant', 'sentences', '\\n', 'from', 'the', 'original', 'document', '.', 'We', 'compared', 'LSA', 'and', 'Non', '-', 'negative', '\\n', 'Matrix', 'Factorization', '(', 'NMF', ')', 'to', 'find', 'the', 'algorithm', 'that', 'is', 'suitable', '\\n', 'with', 'Thai', 'travel', 'news', '.', 'The', 'suitable', 'compression', 'rates', 'for', 'Generic', '\\n', 'Sentence', 'Relevance', 'score', '(', 'GRS', ')', 'and', 'K', '-', 'means', 'clustering', 'were', 'also', '\\n', 'evaluated', '.', 'From', 'these', 'experiments', ',', 'we', 'concluded', 'that', 'keyword', '\\n', 'scored', 'calculation', 'by', 'LSA', 'with', 'sentence', 'selection', 'by', 'GRS', 'is', 'the', '\\n', 'best', 'algorithm', 'for', 'summarizing', 'Thai', 'Travel', 'News', ',', 'compared', 'with', '\\n', 'human', 'with', 'the', 'best', 'compression', 'rate', 'of', '20', '%', '.', '\\n', 'CCS', 'Concepts', '\\n', '•', 'Information', 'systems', '➝', 'Information', 'retrieval', '➝', 'Retrieval', '\\n', 'tasks', 'and', 'goals', '➝', 'Summarization', '\\n', 'Keywords', '\\n', 'Text', 'summarization', ';', 'extractive', 'summarization', ';', 'non', '-', 'negative', '\\n', 'matrix', 'factorization', '\\n', '1', '.', 'INTRODUCTION', '\\n', 'Daily', 'newspaper', 'has', 'abundant', 'of', 'data', 'that', 'users', 'do', 'not', 'have', '\\n', 'enough', 'time', 'for', 'reading', 'them', '.', 'It', 'is', 'difficult', 'to', 'identify', 'the', 'relevant', '\\n', 'information', 'to', 'satisfy', 'the', 'information', 'needed', 'by', 'users', '.', 'Automatic', '\\n', 'summarization', 'can', 'reduce', 'the', 'problem', 'of', 'information', 'overloading', '\\n', 'and', 'it', 'has', 'been', 'proposed', 'previously', 'in', 'English', 'and', 'other', 'languages', '.', '\\n', 'However', ',', 'there', 'were', 'only', 'a', 'few', 'research', 'results', 'in', 'Thai', 'text', '\\n', 'summarization', 'due', 'to', 'the', 'lack', 'of', 'corpus', 'in', 'Thai', 'language', 'and', 'the', '\\n', 'complicated', 'grammar', '.', '\\n', 'Text', 'Summarization', '[', '1', ']', 'is', 'a', 'technique', 'for', 'summarizing', 'the', 'content', '\\n', 'of', 'the', 'documents', '.', 'It', 'consists', 'of', 'three', 'steps', ':', '1', ')', 'create', 'an', '\\n', 'intermediate', 'representation', 'of', 'the', 'input', 'text', ',', '2', ')', 'calculate', 'score', 'for', '\\n', 'the', 'sentences', 'based', 'on', 'the', 'concepts', ',', 'and', '3', ')', 'choose', 'important', '\\n', 'sentences', 'to', 'be', 'included', 'in', 'the', 'summary', '.', 'Text', 'summarization', 'can', '\\n', 'be', 'divided', 'into', '2', 'approaches', '.', 'The', 'first', 'approach', 'is', 'the', 'extractive', '\\n', 'summarization', ',', 'which', 'relies', 'on', 'a', 'method', 'for', 'extracting', 'words', 'and', '\\n', 'searching', 'for', 'keywords', 'from', 'the', 'original', 'document', '.', 'The', 'second', '\\n', 'approach', 'is', 'the', 'abstractive', 'summarization', ',', 'which', 'analyzes', 'words', '\\n', 'by', 'linguistic', 'principles', 'with', 'transcription', 'or', 'interpretation', 'from', 'the', '\\n', 'original', 'document', '.', 'This', 'approach', 'implies', 'more', 'effective', 'and', '\\n', 'accurate', 'summary', 'than', 'the', 'extractive', 'methods', '.', 'However', ',', 'with', 'the', '\\n', 'lack', 'of', 'Thai', 'corpus', ',', 'we', 'chose', 'to', 'apply', 'an', 'extractive', 'summarization', '\\n', 'method', 'for', 'Thai', 'text', 'summarization', '.', '\\n', 'This', 'research', 'focused', 'on', 'the', 'sentence', 'extraction', 'function', 'based', 'on', '\\n', 'keyword', 'score', 'calculation', 'then', 'selecting', 'important', 'sentences', 'based', '\\n', 'on', 'the', 'Generic', 'Sentence', 'Relevance', 'score', '(', 'GRS', ')', ',', 'calculated', 'from', '\\n', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'and', 'Non', '-', 'negative', 'Matrix', '\\n', 'Factorization', '(', 'NMF', ')', '.', 'We', 'also', 'tried', 'using', 'K', '-', 'means', 'clustering', 'for', '\\n', 'document', 'summarization', '.', 'In', 'this', 'experiment', ',', 'we', 'compared', '5', '\\n', 'models', 'for', '5', 'rounds', 'with', 'Thai', 'travel', 'news', 'using', 'the', 'compression', '\\n', 'rates', 'of', '20', '%', ',', '30', '%', 'and', '40', '%', 'and', 'reported', 'the', 'rate', 'and', 'method', 'that', '\\n', 'produced', 'the', 'best', 'result', 'from', 'the', 'experiment', '.', '\\n', '2', '.', 'RELATED', 'WORKS', '\\n', 'In', 'recent', 'years', ',', 'several', 'models', 'in', 'Thai', 'Text', 'summarization', 'have', '\\n', 'been', 'introduced', '.', 'Suwanno', ',', 'N.', 'et', 'al', '.', '[', '2', ']', 'proposed', 'a', 'Thai', 'text', '\\n', 'summarization', 'that', 'extracted', 'a', 'paragraph', 'from', 'a', 'document', 'based', '\\n', 'on', 'Thai', 'compound', 'nouns', ',', 'term', 'frequency', 'method', ',', 'and', 'headline', '\\n', 'score', 'for', 'generating', 'a', 'summary', '.', 'Chongsuntornsri', ',', 'A.', ',', 'et', 'al', '.', '[', '3', ']', '\\n', 'proposed', 'a', 'new', 'approach', 'for', 'Text', 'summarization', 'in', 'Thai', 'based', 'on', '\\n', 'content-', 'and', 'graph', '-', 'based', 'with', 'the', 'use', 'of', 'Topic', 'Sensitive', 'PageRank', '\\n', 'algorithm', 'for', 'summarizing', 'and', 'ranking', 'of', 'text', 'segments', '.', '\\n', 'Jaruskulchai', 'C.', ',', 'et', 'al', '.', '[', '4', ']', 'proposed', 'a', 'method', 'to', 'summarize', '\\n', 'documents', 'by', 'extracting', 'important', 'sentences', 'from', 'combining', 'the', '\\n', 'specific', 'properties', '(', 'Local', 'Property', ')', 'and', 'the', 'overall', 'properties', '\\n', '(', 'Global', 'Property', ')', 'of', 'the', 'sentences', '.', 'The', 'overall', 'properties', 'were', '\\n', 'based', 'on', 'the', 'relationship', 'between', 'sentences', 'in', 'the', 'document', '.', 'From', '\\n', 'their', 'experiments', ',', 'the', 'summarization', 'of', 'the', 'industrial', 'news', 'got', '\\n', '60', '%', 'precision', ',', '44', '%', 'recall', ',', 'and', '50.9', '%', 'F', '-', 'measure', ',', 'the', 'general', 'news', '\\n', 'got', 'the', '51.8', '%', 'precision', ',', '38.5', '%', 'recall', ',', 'and', '43.1', '%', 'F', '-', 'measure', 'while', '\\n', 'the', 'fashion', 'magazines', 'got', '53.0', '%', 'precision', ',', '33.0', '%', 'recall', ',', 'and', '\\n', '40.4', '%', 'F', '-', 'measure', '.', '\\n']\n"
          ]
        }
      ],
      "source": [
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "Tn2Uv-F3HDpw",
        "outputId": "6325b5fd-cc77-4ebd-bf7f-43ca48ed905a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "punctuation = punctuation + '\\n'\n",
        "punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "huSfsmdrWK84"
      },
      "outputs": [],
      "source": [
        "word_frequencies = {}\n",
        "for word in doc:\n",
        "  if word.text.lower() not in stopwords:\n",
        "    if word.text.lower() not in punctuation:\n",
        "      if word.text not in word_frequencies.keys():\n",
        "        word_frequencies[word.text] = 1\n",
        "      else:\n",
        "        word_frequencies[word.text] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "EgiBcbxFXZj2",
        "outputId": "0e337628-198e-4ac5-fd31-3ac152800854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ABSTRACT': 1, 'recent': 2, 'years': 2, 'people': 1, 'seeking': 1, 'solution': 1, 'improve': 1, 'text': 8, 'summarization': 17, 'Thai': 16, 'language': 4, 'solutions': 1, 'PageRank': 2, 'Graph': 1, 'Rank': 1, 'Latent': 2, 'Semantic': 2, 'Analysis': 2, 'LSA': 4, 'models': 3, 'etc': 1, 'proposed': 5, 'research': 3, 'results': 2, 'restricted': 1, 'limited': 1, 'corpus': 3, 'complex': 1, 'grammar': 2, 'paper': 1, 'applied': 1, 'system': 1, 'travel': 3, 'news': 5, 'based': 8, 'keyword': 3, 'scored': 2, 'extracting': 3, 'relevant': 2, 'sentences': 7, 'original': 3, 'document': 6, 'compared': 3, 'Non': 2, 'negative': 3, 'Matrix': 2, 'Factorization': 2, 'NMF': 2, 'find': 1, 'algorithm': 3, 'suitable': 2, 'compression': 3, 'rates': 2, 'Generic': 2, 'Sentence': 2, 'Relevance': 2, 'score': 5, 'GRS': 3, 'K': 2, 'means': 2, 'clustering': 2, 'evaluated': 1, 'experiments': 2, 'concluded': 1, 'calculation': 2, 'sentence': 2, 'selection': 1, 'best': 3, 'summarizing': 3, 'Travel': 1, 'News': 1, 'human': 1, 'rate': 2, '20': 2, 'CCS': 1, 'Concepts': 1, '•': 1, 'Information': 2, 'systems': 1, '➝': 3, 'retrieval': 1, 'Retrieval': 1, 'tasks': 1, 'goals': 1, 'Summarization': 2, 'Keywords': 1, 'Text': 5, 'extractive': 4, 'non': 1, 'matrix': 1, 'factorization': 1, '1': 3, 'INTRODUCTION': 1, 'Daily': 1, 'newspaper': 1, 'abundant': 1, 'data': 1, 'users': 2, 'time': 1, 'reading': 1, 'difficult': 1, 'identify': 1, 'information': 3, 'satisfy': 1, 'needed': 1, 'Automatic': 1, 'reduce': 1, 'problem': 1, 'overloading': 1, 'previously': 1, 'English': 1, 'languages': 1, 'lack': 2, 'complicated': 1, 'technique': 1, 'content': 1, 'documents': 2, 'consists': 1, 'steps': 1, 'create': 1, 'intermediate': 1, 'representation': 1, 'input': 1, '2': 4, 'calculate': 1, 'concepts': 1, '3': 2, 'choose': 1, 'important': 3, 'included': 1, 'summary': 3, 'divided': 1, 'approaches': 1, 'approach': 4, 'relies': 1, 'method': 5, 'words': 2, 'searching': 1, 'keywords': 1, 'second': 1, 'abstractive': 1, 'analyzes': 1, 'linguistic': 1, 'principles': 1, 'transcription': 1, 'interpretation': 1, 'implies': 1, 'effective': 1, 'accurate': 1, 'methods': 1, 'chose': 1, 'apply': 1, 'focused': 1, 'extraction': 1, 'function': 1, 'selecting': 1, 'calculated': 1, 'tried': 1, 'experiment': 2, '5': 2, 'rounds': 1, '30': 1, '40': 1, 'reported': 1, 'produced': 1, 'result': 1, 'RELATED': 1, 'WORKS': 1, 'introduced': 1, 'Suwanno': 1, 'N.': 1, 'et': 3, 'al': 3, 'extracted': 1, 'paragraph': 1, 'compound': 1, 'nouns': 1, 'term': 1, 'frequency': 1, 'headline': 1, 'generating': 1, 'Chongsuntornsri': 1, 'A.': 1, 'new': 1, 'content-': 1, 'graph': 1, 'use': 1, 'Topic': 1, 'Sensitive': 1, 'ranking': 1, 'segments': 1, 'Jaruskulchai': 1, 'C.': 1, '4': 1, 'summarize': 1, 'combining': 1, 'specific': 1, 'properties': 3, 'Local': 1, 'Property': 2, 'overall': 2, 'Global': 1, 'relationship': 1, 'industrial': 1, 'got': 3, '60': 1, 'precision': 3, '44': 1, 'recall': 3, '50.9': 1, 'F': 3, 'measure': 3, 'general': 1, '51.8': 1, '38.5': 1, '43.1': 1, 'fashion': 1, 'magazines': 1, '53.0': 1, '33.0': 1, '40.4': 1}\n"
          ]
        }
      ],
      "source": [
        "print(word_frequencies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "59QpWTlkX6UC"
      },
      "outputs": [],
      "source": [
        "max_frequency = max(word_frequencies.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "oIQGF1vAYGoD",
        "outputId": "f72c0f9a-4d57-44bf-ca63-1a0fc8b87d3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Gx_S5rRXYX2H"
      },
      "outputs": [],
      "source": [
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word] = word_frequencies[word]/max_frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "H0QbAJA5YuG0",
        "outputId": "5816a67b-488e-43f5-c267-e51df1194828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ABSTRACT': 0.058823529411764705, 'recent': 0.11764705882352941, 'years': 0.11764705882352941, 'people': 0.058823529411764705, 'seeking': 0.058823529411764705, 'solution': 0.058823529411764705, 'improve': 0.058823529411764705, 'text': 0.47058823529411764, 'summarization': 1.0, 'Thai': 0.9411764705882353, 'language': 0.23529411764705882, 'solutions': 0.058823529411764705, 'PageRank': 0.11764705882352941, 'Graph': 0.058823529411764705, 'Rank': 0.058823529411764705, 'Latent': 0.11764705882352941, 'Semantic': 0.11764705882352941, 'Analysis': 0.11764705882352941, 'LSA': 0.23529411764705882, 'models': 0.17647058823529413, 'etc': 0.058823529411764705, 'proposed': 0.29411764705882354, 'research': 0.17647058823529413, 'results': 0.11764705882352941, 'restricted': 0.058823529411764705, 'limited': 0.058823529411764705, 'corpus': 0.17647058823529413, 'complex': 0.058823529411764705, 'grammar': 0.11764705882352941, 'paper': 0.058823529411764705, 'applied': 0.058823529411764705, 'system': 0.058823529411764705, 'travel': 0.17647058823529413, 'news': 0.29411764705882354, 'based': 0.47058823529411764, 'keyword': 0.17647058823529413, 'scored': 0.11764705882352941, 'extracting': 0.17647058823529413, 'relevant': 0.11764705882352941, 'sentences': 0.4117647058823529, 'original': 0.17647058823529413, 'document': 0.35294117647058826, 'compared': 0.17647058823529413, 'Non': 0.11764705882352941, 'negative': 0.17647058823529413, 'Matrix': 0.11764705882352941, 'Factorization': 0.11764705882352941, 'NMF': 0.11764705882352941, 'find': 0.058823529411764705, 'algorithm': 0.17647058823529413, 'suitable': 0.11764705882352941, 'compression': 0.17647058823529413, 'rates': 0.11764705882352941, 'Generic': 0.11764705882352941, 'Sentence': 0.11764705882352941, 'Relevance': 0.11764705882352941, 'score': 0.29411764705882354, 'GRS': 0.17647058823529413, 'K': 0.11764705882352941, 'means': 0.11764705882352941, 'clustering': 0.11764705882352941, 'evaluated': 0.058823529411764705, 'experiments': 0.11764705882352941, 'concluded': 0.058823529411764705, 'calculation': 0.11764705882352941, 'sentence': 0.11764705882352941, 'selection': 0.058823529411764705, 'best': 0.17647058823529413, 'summarizing': 0.17647058823529413, 'Travel': 0.058823529411764705, 'News': 0.058823529411764705, 'human': 0.058823529411764705, 'rate': 0.11764705882352941, '20': 0.11764705882352941, 'CCS': 0.058823529411764705, 'Concepts': 0.058823529411764705, '•': 0.058823529411764705, 'Information': 0.11764705882352941, 'systems': 0.058823529411764705, '➝': 0.17647058823529413, 'retrieval': 0.058823529411764705, 'Retrieval': 0.058823529411764705, 'tasks': 0.058823529411764705, 'goals': 0.058823529411764705, 'Summarization': 0.11764705882352941, 'Keywords': 0.058823529411764705, 'Text': 0.29411764705882354, 'extractive': 0.23529411764705882, 'non': 0.058823529411764705, 'matrix': 0.058823529411764705, 'factorization': 0.058823529411764705, '1': 0.17647058823529413, 'INTRODUCTION': 0.058823529411764705, 'Daily': 0.058823529411764705, 'newspaper': 0.058823529411764705, 'abundant': 0.058823529411764705, 'data': 0.058823529411764705, 'users': 0.11764705882352941, 'time': 0.058823529411764705, 'reading': 0.058823529411764705, 'difficult': 0.058823529411764705, 'identify': 0.058823529411764705, 'information': 0.17647058823529413, 'satisfy': 0.058823529411764705, 'needed': 0.058823529411764705, 'Automatic': 0.058823529411764705, 'reduce': 0.058823529411764705, 'problem': 0.058823529411764705, 'overloading': 0.058823529411764705, 'previously': 0.058823529411764705, 'English': 0.058823529411764705, 'languages': 0.058823529411764705, 'lack': 0.11764705882352941, 'complicated': 0.058823529411764705, 'technique': 0.058823529411764705, 'content': 0.058823529411764705, 'documents': 0.11764705882352941, 'consists': 0.058823529411764705, 'steps': 0.058823529411764705, 'create': 0.058823529411764705, 'intermediate': 0.058823529411764705, 'representation': 0.058823529411764705, 'input': 0.058823529411764705, '2': 0.23529411764705882, 'calculate': 0.058823529411764705, 'concepts': 0.058823529411764705, '3': 0.11764705882352941, 'choose': 0.058823529411764705, 'important': 0.17647058823529413, 'included': 0.058823529411764705, 'summary': 0.17647058823529413, 'divided': 0.058823529411764705, 'approaches': 0.058823529411764705, 'approach': 0.23529411764705882, 'relies': 0.058823529411764705, 'method': 0.29411764705882354, 'words': 0.11764705882352941, 'searching': 0.058823529411764705, 'keywords': 0.058823529411764705, 'second': 0.058823529411764705, 'abstractive': 0.058823529411764705, 'analyzes': 0.058823529411764705, 'linguistic': 0.058823529411764705, 'principles': 0.058823529411764705, 'transcription': 0.058823529411764705, 'interpretation': 0.058823529411764705, 'implies': 0.058823529411764705, 'effective': 0.058823529411764705, 'accurate': 0.058823529411764705, 'methods': 0.058823529411764705, 'chose': 0.058823529411764705, 'apply': 0.058823529411764705, 'focused': 0.058823529411764705, 'extraction': 0.058823529411764705, 'function': 0.058823529411764705, 'selecting': 0.058823529411764705, 'calculated': 0.058823529411764705, 'tried': 0.058823529411764705, 'experiment': 0.11764705882352941, '5': 0.11764705882352941, 'rounds': 0.058823529411764705, '30': 0.058823529411764705, '40': 0.058823529411764705, 'reported': 0.058823529411764705, 'produced': 0.058823529411764705, 'result': 0.058823529411764705, 'RELATED': 0.058823529411764705, 'WORKS': 0.058823529411764705, 'introduced': 0.058823529411764705, 'Suwanno': 0.058823529411764705, 'N.': 0.058823529411764705, 'et': 0.17647058823529413, 'al': 0.17647058823529413, 'extracted': 0.058823529411764705, 'paragraph': 0.058823529411764705, 'compound': 0.058823529411764705, 'nouns': 0.058823529411764705, 'term': 0.058823529411764705, 'frequency': 0.058823529411764705, 'headline': 0.058823529411764705, 'generating': 0.058823529411764705, 'Chongsuntornsri': 0.058823529411764705, 'A.': 0.058823529411764705, 'new': 0.058823529411764705, 'content-': 0.058823529411764705, 'graph': 0.058823529411764705, 'use': 0.058823529411764705, 'Topic': 0.058823529411764705, 'Sensitive': 0.058823529411764705, 'ranking': 0.058823529411764705, 'segments': 0.058823529411764705, 'Jaruskulchai': 0.058823529411764705, 'C.': 0.058823529411764705, '4': 0.058823529411764705, 'summarize': 0.058823529411764705, 'combining': 0.058823529411764705, 'specific': 0.058823529411764705, 'properties': 0.17647058823529413, 'Local': 0.058823529411764705, 'Property': 0.11764705882352941, 'overall': 0.11764705882352941, 'Global': 0.058823529411764705, 'relationship': 0.058823529411764705, 'industrial': 0.058823529411764705, 'got': 0.17647058823529413, '60': 0.058823529411764705, 'precision': 0.17647058823529413, '44': 0.058823529411764705, 'recall': 0.17647058823529413, '50.9': 0.058823529411764705, 'F': 0.17647058823529413, 'measure': 0.17647058823529413, 'general': 0.058823529411764705, '51.8': 0.058823529411764705, '38.5': 0.058823529411764705, '43.1': 0.058823529411764705, 'fashion': 0.058823529411764705, 'magazines': 0.058823529411764705, '53.0': 0.058823529411764705, '33.0': 0.058823529411764705, '40.4': 0.058823529411764705}\n"
          ]
        }
      ],
      "source": [
        "print(word_frequencies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "colab_type": "code",
        "id": "d9vbQAUDZCUV",
        "outputId": "f6586585-addb-46e3-8d4f-c8e38edb5baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "ABSTRACT\n",
            "In recent years, people are seeking for a solution to improve text\n",
            "summarization for Thai language., Although several solutions such\n",
            "as PageRank, Graph Rank, Latent Semantic Analysis (LSA)\n",
            "models, etc., have been proposed, research results in Thai text\n",
            "summarization were restricted due to limited corpus in Thai\n",
            "language with complex grammar., This paper applied a text\n",
            "summarization system for Thai travel news based on keyword\n",
            "scored in Thai language by extracting the most relevant sentences\n",
            "from the original document., We compared LSA and Non-negative\n",
            "Matrix Factorization (NMF) to find the algorithm that is suitable\n",
            "with Thai travel news., The suitable compression rates for Generic\n",
            "Sentence Relevance score (GRS) and K-means clustering were also\n",
            "evaluated., From these experiments, we concluded that keyword\n",
            "scored calculation by LSA with sentence selection by GRS is the\n",
            "best algorithm for summarizing Thai Travel News, compared with\n",
            "human with the best compression rate of 20%.\n",
            ", CCS Concepts\n",
            "• Information systems ➝ Information retrieval ➝ Retrieval\n",
            "tasks and goals➝ Summarization\n",
            "Keywords\n",
            "Text summarization; extractive summarization; non-negative\n",
            "matrix factorization\n",
            "1., INTRODUCTION\n",
            "Daily newspaper has abundant of data that users do not have\n",
            "enough time for reading them., It is difficult to identify the relevant\n",
            "information to satisfy the information needed by users., Automatic\n",
            "summarization can reduce the problem of information overloading\n",
            "and it has been proposed previously in English and other languages.\n",
            ", However, there were only a few research results in Thai text\n",
            "summarization due to the lack of corpus in Thai language and the\n",
            "complicated grammar.\n",
            ", Text Summarization, [1] is a technique for summarizing the content\n",
            "of the documents., It consists of three steps: 1) create an\n",
            "intermediate representation of the input text, 2) calculate score for\n",
            "the sentences based on the concepts, and 3) choose important\n",
            "sentences to be included in the summary., Text summarization can\n",
            "be divided into 2 approaches., The first approach is the extractive\n",
            "summarization, which relies on a method for extracting words and\n",
            "searching for keywords from the original document., The second\n",
            "approach is the abstractive summarization, which analyzes words\n",
            "by linguistic principles with transcription or interpretation from the\n",
            "original document., This approach implies more effective and\n",
            "accurate summary than the extractive methods., However, with the\n",
            "lack of Thai corpus, we chose to apply an extractive summarization\n",
            "method for Thai text summarization.\n",
            ", This research focused on the sentence extraction function based on\n",
            "keyword score calculation then selecting important sentences based\n",
            "on the Generic Sentence Relevance score (GRS), calculated from\n",
            "Latent Semantic Analysis (LSA) and Non-negative Matrix\n",
            "Factorization (NMF)., We also tried using K-means clustering for\n",
            "document summarization., In this experiment, we compared 5\n",
            "models for 5 rounds with Thai travel news using the compression\n",
            "rates of 20%, 30% and 40% and reported the rate and method that\n",
            "produced the best result from the experiment.\n",
            ", 2. RELATED WORKS\n",
            ", In recent years, several models in Thai Text summarization have\n",
            "been introduced., Suwanno, N. et al., [2] proposed a Thai text\n",
            "summarization that extracted a paragraph from a document based\n",
            "on Thai compound nouns, term frequency method, and headline\n",
            "score for generating a summary., Chongsuntornsri, A., et al., [3]\n",
            "proposed a new approach for Text summarization in Thai based on\n",
            "content- and graph-based with the use of Topic Sensitive PageRank\n",
            "algorithm for summarizing and ranking of text segments.\n",
            ", Jaruskulchai C., et al., [4] proposed a method to summarize\n",
            "documents by extracting important sentences from combining the\n",
            "specific properties (Local Property) and the overall properties\n",
            "(Global Property) of the sentences., The overall properties were\n",
            "based on the relationship between sentences in the document., From\n",
            "their experiments, the summarization of the industrial news got\n",
            "60% precision, 44% recall, and 50.9% F-measure, the general news\n",
            "got the 51.8% precision, 38.5% recall, and 43.1% F-measure while\n",
            "the fashion magazines got 53.0% precision, 33.0% recall, and\n",
            "40.4% F-measure.\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "print(sentence_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-3Ee54JWZk5G"
      },
      "outputs": [],
      "source": [
        "sentence_scores = {}\n",
        "for sent in sentence_tokens:\n",
        "  for word in sent:\n",
        "    if word.text.lower() in word_frequencies.keys():\n",
        "      if sent not in sentence_scores.keys():\n",
        "        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "      else:\n",
        "        sentence_scores[sent] += word_frequencies[word.text.lower()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "colab_type": "code",
        "id": "eHuAYodnIg5I",
        "outputId": "5ad12dd5-1e46-4fc4-ef01-d3fd682bd359"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              " ABSTRACT\n",
              " In recent years, people are seeking for a solution to improve text\n",
              " summarization for Thai language.: 2.176470588235294,\n",
              " Although several solutions such\n",
              " as PageRank, Graph Rank, Latent Semantic Analysis (LSA)\n",
              " models, etc., have been proposed, research results in Thai text\n",
              " summarization were restricted due to limited corpus in Thai\n",
              " language with complex grammar.: 3.117647058823529,\n",
              " This paper applied a text\n",
              " summarization system for Thai travel news based on keyword\n",
              " scored in Thai language by extracting the most relevant sentences\n",
              " from the original document.: 4.352941176470588,\n",
              " We compared LSA and Non-negative\n",
              " Matrix Factorization (NMF) to find the algorithm that is suitable\n",
              " with Thai travel news.: 1.3529411764705883,\n",
              " The suitable compression rates for Generic\n",
              " Sentence Relevance score (GRS) and K-means clustering were also\n",
              " evaluated.: 1.1176470588235294,\n",
              " From these experiments, we concluded that keyword\n",
              " scored calculation by LSA with sentence selection by GRS is the\n",
              " best algorithm for summarizing Thai Travel News, compared with\n",
              " human with the best compression rate of 20%.: 2.5882352941176467,\n",
              " CCS Concepts\n",
              " • Information systems ➝ Information retrieval ➝ Retrieval\n",
              " tasks and goals➝ Summarization\n",
              " Keywords\n",
              " Text summarization; extractive summarization; non-negative\n",
              " matrix factorization\n",
              " 1.: 5.588235294117647,\n",
              " INTRODUCTION\n",
              " Daily newspaper has abundant of data that users do not have\n",
              " enough time for reading them.: 0.4117647058823529,\n",
              " It is difficult to identify the relevant\n",
              " information to satisfy the information needed by users.: 0.823529411764706,\n",
              " Automatic\n",
              " summarization can reduce the problem of information overloading\n",
              " and it has been proposed previously in English and other languages.: 1.7647058823529413,\n",
              " However, there were only a few research results in Thai text\n",
              " summarization due to the lack of corpus in Thai language and the\n",
              " complicated grammar.: 2.4705882352941173,\n",
              " Text Summarization: 1.4705882352941178,\n",
              " [1] is a technique for summarizing the content\n",
              " of the documents.: 0.5882352941176471,\n",
              " It consists of three steps: 1) create an\n",
              " intermediate representation of the input text, 2) calculate score for\n",
              " the sentences based on the concepts, and 3) choose important\n",
              " sentences to be included in the summary.: 3.5294117647058814,\n",
              " Text summarization can\n",
              " be divided into 2 approaches.: 1.823529411764706,\n",
              " The first approach is the extractive\n",
              " summarization, which relies on a method for extracting words and\n",
              " searching for keywords from the original document.: 2.7647058823529407,\n",
              " The second\n",
              " approach is the abstractive summarization, which analyzes words\n",
              " by linguistic principles with transcription or interpretation from the\n",
              " original document.: 2.294117647058824,\n",
              " This approach implies more effective and\n",
              " accurate summary than the extractive methods.: 0.8823529411764706,\n",
              " However, with the\n",
              " lack of Thai corpus, we chose to apply an extractive summarization\n",
              " method for Thai text summarization.: 3.411764705882353,\n",
              " This research focused on the sentence extraction function based on\n",
              " keyword score calculation then selecting important sentences based\n",
              " on the Generic Sentence Relevance score (GRS), calculated from\n",
              " Latent Semantic Analysis (LSA) and Non-negative Matrix\n",
              " Factorization (NMF).: 3.470588235294117,\n",
              " We also tried using K-means clustering for\n",
              " document summarization.: 1.6470588235294117,\n",
              " In this experiment, we compared 5\n",
              " models for 5 rounds with Thai travel news using the compression\n",
              " rates of 20%, 30% and 40% and reported the rate and method that\n",
              " produced the best result from the experiment.: 2.6470588235294112,\n",
              " 2. RELATED WORKS: 0.23529411764705882,\n",
              " In recent years, several models in Thai Text summarization have\n",
              " been introduced.: 1.9411764705882353,\n",
              " Suwanno, N. et al.: 0.35294117647058826,\n",
              " [2] proposed a Thai text\n",
              " summarization that extracted a paragraph from a document based\n",
              " on Thai compound nouns, term frequency method, and headline\n",
              " score for generating a summary.: 4.058823529411763,\n",
              " Chongsuntornsri, A., et al.: 0.35294117647058826,\n",
              " [3]\n",
              " proposed a new approach for Text summarization in Thai based on\n",
              " content- and graph-based with the use of Topic Sensitive PageRank\n",
              " algorithm for summarizing and ranking of text segments.: 4.235294117647057,\n",
              " Jaruskulchai C., et al.: 0.35294117647058826,\n",
              " [4] proposed a method to summarize\n",
              " documents by extracting important sentences from combining the\n",
              " specific properties (Local Property) and the overall properties\n",
              " (Global Property) of the sentences.: 2.5882352941176467,\n",
              " The overall properties were\n",
              " based on the relationship between sentences in the document.: 1.5882352941176472,\n",
              " From\n",
              " their experiments, the summarization of the industrial news got\n",
              " 60% precision, 44% recall, and 50.9% F-measure, the general news\n",
              " got the 51.8% precision, 38.5% recall, and 43.1% F-measure while\n",
              " the fashion magazines got 53.0% precision, 33.0% recall, and\n",
              " 40.4% F-measure.: 4.588235294117644}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-8BICcjZJCpU"
      },
      "outputs": [],
      "source": [
        "from heapq import nlargest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "n7QOpoldJTcY",
        "outputId": "0c98ff90-aff9-4ad9-edc1-602b161a5b26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "select_length = int(len(sentence_tokens)*0.3)\n",
        "select_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0qYYWV82JygM"
      },
      "outputs": [],
      "source": [
        "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "colab_type": "code",
        "id": "TR5wQN6UKDrt",
        "outputId": "82a53ef6-31ab-400e-a51e-b80a7fcfb443"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[CCS Concepts\n",
              " • Information systems ➝ Information retrieval ➝ Retrieval\n",
              " tasks and goals➝ Summarization\n",
              " Keywords\n",
              " Text summarization; extractive summarization; non-negative\n",
              " matrix factorization\n",
              " 1.,\n",
              " From\n",
              " their experiments, the summarization of the industrial news got\n",
              " 60% precision, 44% recall, and 50.9% F-measure, the general news\n",
              " got the 51.8% precision, 38.5% recall, and 43.1% F-measure while\n",
              " the fashion magazines got 53.0% precision, 33.0% recall, and\n",
              " 40.4% F-measure.,\n",
              " This paper applied a text\n",
              " summarization system for Thai travel news based on keyword\n",
              " scored in Thai language by extracting the most relevant sentences\n",
              " from the original document.,\n",
              " [3]\n",
              " proposed a new approach for Text summarization in Thai based on\n",
              " content- and graph-based with the use of Topic Sensitive PageRank\n",
              " algorithm for summarizing and ranking of text segments.,\n",
              " [2] proposed a Thai text\n",
              " summarization that extracted a paragraph from a document based\n",
              " on Thai compound nouns, term frequency method, and headline\n",
              " score for generating a summary.,\n",
              " It consists of three steps: 1) create an\n",
              " intermediate representation of the input text, 2) calculate score for\n",
              " the sentences based on the concepts, and 3) choose important\n",
              " sentences to be included in the summary.,\n",
              " This research focused on the sentence extraction function based on\n",
              " keyword score calculation then selecting important sentences based\n",
              " on the Generic Sentence Relevance score (GRS), calculated from\n",
              " Latent Semantic Analysis (LSA) and Non-negative Matrix\n",
              " Factorization (NMF).,\n",
              " However, with the\n",
              " lack of Thai corpus, we chose to apply an extractive summarization\n",
              " method for Thai text summarization.,\n",
              " Although several solutions such\n",
              " as PageRank, Graph Rank, Latent Semantic Analysis (LSA)\n",
              " models, etc., have been proposed, research results in Thai text\n",
              " summarization were restricted due to limited corpus in Thai\n",
              " language with complex grammar.]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "k3cGqkqaKWnT"
      },
      "outputs": [],
      "source": [
        "final_summary = [word.text for word in summary]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1pw4ElbUKpMB"
      },
      "outputs": [],
      "source": [
        "summary = ' '.join(final_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "colab_type": "code",
        "id": "Wa66EgbzLIgR",
        "outputId": "a72e4c9e-697f-4ed1-d987-3e966a6ca086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ABSTRACT\n",
            "In recent years, people are seeking for a solution to improve text\n",
            "summarization for Thai language. Although several solutions such\n",
            "as PageRank, Graph Rank, Latent Semantic Analysis (LSA)\n",
            "models, etc., have been proposed, research results in Thai text\n",
            "summarization were restricted due to limited corpus in Thai\n",
            "language with complex grammar. This paper applied a text\n",
            "summarization system for Thai travel news based on keyword\n",
            "scored in Thai language by extracting the most relevant sentences\n",
            "from the original document. We compared LSA and Non-negative\n",
            "Matrix Factorization (NMF) to find the algorithm that is suitable\n",
            "with Thai travel news. The suitable compression rates for Generic\n",
            "Sentence Relevance score (GRS) and K-means clustering were also\n",
            "evaluated. From these experiments, we concluded that keyword\n",
            "scored calculation by LSA with sentence selection by GRS is the\n",
            "best algorithm for summarizing Thai Travel News, compared with\n",
            "human with the best compression rate of 20%.\n",
            "CCS Concepts\n",
            "• Information systems ➝ Information retrieval ➝ Retrieval\n",
            "tasks and goals➝ Summarization\n",
            "Keywords\n",
            "Text summarization; extractive summarization; non-negative\n",
            "matrix factorization\n",
            "1. INTRODUCTION\n",
            "Daily newspaper has abundant of data that users do not have\n",
            "enough time for reading them. It is difficult to identify the relevant\n",
            "information to satisfy the information needed by users. Automatic\n",
            "summarization can reduce the problem of information overloading\n",
            "and it has been proposed previously in English and other languages.\n",
            "However, there were only a few research results in Thai text\n",
            "summarization due to the lack of corpus in Thai language and the\n",
            "complicated grammar.\n",
            "Text Summarization [1] is a technique for summarizing the content\n",
            "of the documents. It consists of three steps: 1) create an\n",
            "intermediate representation of the input text, 2) calculate score for\n",
            "the sentences based on the concepts, and 3) choose important\n",
            "sentences to be included in the summary. Text summarization can\n",
            "be divided into 2 approaches. The first approach is the extractive\n",
            "summarization, which relies on a method for extracting words and\n",
            "searching for keywords from the original document. The second\n",
            "approach is the abstractive summarization, which analyzes words\n",
            "by linguistic principles with transcription or interpretation from the\n",
            "original document. This approach implies more effective and\n",
            "accurate summary than the extractive methods. However, with the\n",
            "lack of Thai corpus, we chose to apply an extractive summarization\n",
            "method for Thai text summarization.\n",
            "This research focused on the sentence extraction function based on\n",
            "keyword score calculation then selecting important sentences based\n",
            "on the Generic Sentence Relevance score (GRS), calculated from\n",
            "Latent Semantic Analysis (LSA) and Non-negative Matrix\n",
            "Factorization (NMF). We also tried using K-means clustering for\n",
            "document summarization. In this experiment, we compared 5\n",
            "models for 5 rounds with Thai travel news using the compression\n",
            "rates of 20%, 30% and 40% and reported the rate and method that\n",
            "produced the best result from the experiment.\n",
            "2. RELATED WORKS\n",
            "In recent years, several models in Thai Text summarization have\n",
            "been introduced. Suwanno, N. et al. [2] proposed a Thai text\n",
            "summarization that extracted a paragraph from a document based\n",
            "on Thai compound nouns, term frequency method, and headline\n",
            "score for generating a summary. Chongsuntornsri, A., et al. [3]\n",
            "proposed a new approach for Text summarization in Thai based on\n",
            "content- and graph-based with the use of Topic Sensitive PageRank\n",
            "algorithm for summarizing and ranking of text segments.\n",
            "Jaruskulchai C., et al. [4] proposed a method to summarize\n",
            "documents by extracting important sentences from combining the\n",
            "specific properties (Local Property) and the overall properties\n",
            "(Global Property) of the sentences. The overall properties were\n",
            "based on the relationship between sentences in the document. From\n",
            "their experiments, the summarization of the industrial news got\n",
            "60% precision, 44% recall, and 50.9% F-measure, the general news\n",
            "got the 51.8% precision, 38.5% recall, and 43.1% F-measure while\n",
            "the fashion magazines got 53.0% precision, 33.0% recall, and\n",
            "40.4% F-measure.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "id": "no_-dxurKz1c",
        "outputId": "c3207863-71b2-40f0-b613-2694811d7933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CCS Concepts\n",
            "• Information systems ➝ Information retrieval ➝ Retrieval\n",
            "tasks and goals➝ Summarization\n",
            "Keywords\n",
            "Text summarization; extractive summarization; non-negative\n",
            "matrix factorization\n",
            "1. From\n",
            "their experiments, the summarization of the industrial news got\n",
            "60% precision, 44% recall, and 50.9% F-measure, the general news\n",
            "got the 51.8% precision, 38.5% recall, and 43.1% F-measure while\n",
            "the fashion magazines got 53.0% precision, 33.0% recall, and\n",
            "40.4% F-measure.\n",
            " This paper applied a text\n",
            "summarization system for Thai travel news based on keyword\n",
            "scored in Thai language by extracting the most relevant sentences\n",
            "from the original document. [3]\n",
            "proposed a new approach for Text summarization in Thai based on\n",
            "content- and graph-based with the use of Topic Sensitive PageRank\n",
            "algorithm for summarizing and ranking of text segments.\n",
            " [2] proposed a Thai text\n",
            "summarization that extracted a paragraph from a document based\n",
            "on Thai compound nouns, term frequency method, and headline\n",
            "score for generating a summary. It consists of three steps: 1) create an\n",
            "intermediate representation of the input text, 2) calculate score for\n",
            "the sentences based on the concepts, and 3) choose important\n",
            "sentences to be included in the summary. This research focused on the sentence extraction function based on\n",
            "keyword score calculation then selecting important sentences based\n",
            "on the Generic Sentence Relevance score (GRS), calculated from\n",
            "Latent Semantic Analysis (LSA) and Non-negative Matrix\n",
            "Factorization (NMF). However, with the\n",
            "lack of Thai corpus, we chose to apply an extractive summarization\n",
            "method for Thai text summarization.\n",
            " Although several solutions such\n",
            "as PageRank, Graph Rank, Latent Semantic Analysis (LSA)\n",
            "models, etc., have been proposed, research results in Thai text\n",
            "summarization were restricted due to limited corpus in Thai\n",
            "language with complex grammar.\n"
          ]
        }
      ],
      "source": [
        "print(summary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Text_Summarization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
