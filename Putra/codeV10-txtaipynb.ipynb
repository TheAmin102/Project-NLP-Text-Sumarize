{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pjmz-RORV8E"
      },
      "source": [
        "# Building abstractive text summaries\n",
        "\n",
        "In the field of text summarization, there are two primary categories of summarization, extractive and abstractive summarization.\n",
        "\n",
        "Extractive summarization takes subsections of the text and joins them together to form a summary. This is commonly backed by graph algorithms like TextRank to find the sections/sentences with the most commonality. These summaries can be highly effective but they are unable to transform text and don't have a contextual understanding.\n",
        "\n",
        "Abstractive summarization uses Natural Language Processing (NLP) models to build transformative summaries of text. This is similar to having a human read an article and asking what was it about. A human wouldn't just give a verbose reading of the text. This notebook shows how blocks of text can be summarized using an abstractive summarization pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk31rbYjSTYm"
      },
      "source": [
        "# Install dependencies\n",
        "\n",
        "Install `txtai` and all dependencies. Since this notebook is using optional pipelines, we need to install the pipeline extras package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMQuuun2R06J"
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/neuml/txtai#egg=txtai[pipeline]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNPJ95cdTKSS"
      },
      "source": [
        "# Create a Summary instance\n",
        "\n",
        "The Summary instance is the main entrypoint for text summarization. This is a light-weight wrapper around the summarization pipeline in Hugging Face Transformers.\n",
        "\n",
        "In addition to the default model, additional models can be found on the [Hugging Face model hub](https://huggingface.co/models?pipeline_tag=summarization).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTDwXOUeTH2-"
      },
      "source": [
        "%%capture\n",
        "\n",
        "from txtai.pipeline import Summary\n",
        "\n",
        "# Create summary model\n",
        "summary = Summary()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vGR_piwZZO6"
      },
      "source": [
        "# Summarize text\n",
        "\n",
        "The example below shows how a large block of text can be distilled down into a smaller summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-K2YJJzsVtfq",
        "outputId": "71aaafbf-5fb8-4958-eaca-2a3c4abfb7c8"
      },
      "source": [
        "text = (\"Search is the base of many applications. Once data starts to pile up, users want to be able to find it. Itâ€™s the foundation \"\n",
        "       \"of the internet and an ever-growing challenge that is never solved or done. The field of Natural Language Processing (NLP) is \"\n",
        "       \"rapidly evolving with a number of new developments. Large-scale general language models are an exciting new capability \"\n",
        "       \"allowing us to add amazing functionality quickly with limited compute and people. Innovation continues with new models \"\n",
        "       \"and advancements coming in at what seems a weekly basis. This article introduces txtai, an AI-powered search engine \"\n",
        "       \"that enables Natural Language Understanding (NLU) based search in any application.\"\n",
        ")\n",
        "\n",
        "summary(text, maxlength=10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Search is the foundation of the internet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is by using our dataset, shorten down."
      ],
      "metadata": {
        "id": "fRn0glwjH8la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\"\"\"In recent years, people are seeking for a solution to improve text\n",
        "summarization for Thai language. Although several solutions such\n",
        "as PageRank, Graph Rank, Latent Semantic Analysis (LSA)\n",
        "models, etc., have been proposed, research results in Thai text\n",
        "summarization were restricted due to limited corpus in Thai\n",
        "language with complex grammar. This paper applied a text\n",
        "summarization system for Thai travel news based on keyword\n",
        "scored in Thai language by extracting the most relevant sentences\n",
        "from the original document. We compared LSA and Non-negative\n",
        "Matrix Factorization (NMF) to find the algorithm that is suitable\n",
        "with Thai travel news. The suitable compression rates for Generic\n",
        "Sentence Relevance score (GRS) and K-means clustering were also\n",
        "evaluated. From these experiments, we concluded that keyword\n",
        "scored calculation by LSA with sentence selection by GRS is the\n",
        "best algorithm for summarizing Thai Travel News, compared with\n",
        "human with the best compression rate of 20%.\"\"\"\n",
        ")\n",
        "\n",
        "summary(text, minlength = 30, maxlength=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "x8Yl6FscHVEQ",
        "outputId": "8cab0fd3-e0d3-442d-897c-e8a0d82bebb6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A paper applied a text-summarization system for Thai travel news based on keywordscored in Thai language by extracting the most relevant sentences from the original document. We compared LSA and NMF to find the algorithm that is suitable'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}