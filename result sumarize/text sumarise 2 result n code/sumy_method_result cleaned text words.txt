Chula ac th sentences to be included in the summary Text summarization can be divided into 2 approaches The first approach is the extractive summarization which relies on a method for extracting words and searching for keywords from the original document The second approach is the abstractive summarization which analyzes words by linguistic principles with transcription or interpretation from the original document This approach implies more effective and accurate summary than the extractive methods However with the lack of Thai corpus we chose to apply an extractive summarization method for Thai text summarization This research focused on the sentence extraction function based on keyword score calculation then selecting important sentences based on the Generic Sentence Relevance score ğ‘…ğ‘…ğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿ and both terms are non negative as shown in Eq 2 and Eq 3 4 ğ‘–ğ‘– 1 ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤â„ğ‘¡ğ‘¡ ğ»ğ»ğ‘–ğ‘– ğ‘›ğ‘›ğ‘ğ‘ 1 ğ»ğ»ğ‘–ğ‘–ğ‘–ğ‘– ğ‘Ÿğ‘Ÿ ğ‘ğ‘ 1 ğ‘›ğ‘›ğ‘ğ‘ 1 ğ»ğ»ğ‘ğ‘ğ‘ğ‘ 5 The ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤â„ğ‘¡ğ‘¡ ğ»ğ»ğ‘–ğ‘– is the relative relevance of the ith semantic feature ğ‘Šğ‘Šğ‘–ğ‘– where ğ»ğ»ğ‘–ğ‘–ğ‘–ğ‘– is the weight of the topic ğ‘–ğ‘– in the sentence ğ‘ğ‘ and ğ»ğ»ğ‘ğ‘ğ‘ğ‘ is the weight of the topic ğ‘ğ‘ in the sentence ğ‘ğ‘ The sentences can be ranked by Generic Relevance Sentence scores Sentences with the maximum score will be selected into the summary 3 5 Cosine Similarity Cosine similarity 18 is a widely used method to measure the similarity between vectors representing the documents The result of cosine similarity is ranging from 0 to 1 If it is closer to 1 that means both vectors are similar Eq 6 and Eq 7 represents the cosine similarity equation where cos Î¸ is the dot product between vectors of sentences